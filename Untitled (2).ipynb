{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "%matplotlib inline\n",
    "import gensim\n",
    "from sklearn import feature_extraction,ensemble,linear_model,svm,model_selection,metrics,neighbors,cluster,tree,externals\n",
    "import scipy\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import re\n",
    "import bayes_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=pd.read_csv(\"./X_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=X.reting\n",
    "X.drop(\"reting\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/statsmodels/nonparametric/kde.py:475: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "  grid,delta = np.linspace(a,b,gridsize,retstep=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe25f628ba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEGCAYAAACJnEVTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEYW+iIiP/H9c6FnZWQm0zwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe25f670390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.distplot(np.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/statsmodels/nonparametric/kde.py:475: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "  grid,delta = np.linspace(a,b,gridsize,retstep=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe25ecf4dd8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEGCAYAAABhMDI9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDCIiEqBgEBGRAAWDiIgEKBhERCTg/wPTpjG9zo19XQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe25f6709b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.distplot(X.brandId,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/statsmodels/nonparametric/kde.py:475: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "  grid,delta = np.linspace(a,b,gridsize,retstep=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe25f469fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEGCAYAAACevtWaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3EVEIkjlLiISQSp3EZEIUrmLiETQ/wcnoBGVSBX3uAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe25ecf4d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.distplot(X.categoryLevel1Id,bins=100)#-_- пики на сотнях, случайность? нормально так"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/statsmodels/nonparametric/kde.py:475: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "  grid,delta = np.linspace(a,b,gridsize,retstep=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe25f2c2e48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcFfWZ7/FPr9ArNM1h3xEeJYAo4hJcUNDERJMblzHR\nZKJxJonxzmhmJpPlzpiJRnMnMTpjxpm5JmY0JlFjErfElSgq4oJEwAUeBESxWbppml7ovfvcP6oa\nD02f7lO90Kf1+369eB266ldVzyma8z1Vv6pfZcTjcURERFKVOdgFiIjI0KLgEBGRSBQcIiISiYJD\nREQiUXCIiEgk2YNdwECrqKhN28vGSkryqaqqH+wyejRU6gTVOlBU68BI51pjsaKMZPN0xDGIsrOz\nBruElAyVOkG1DhTVOjCGUq2JFBwiIhKJgkNERCJRcIiISCQKDhERiUTBISIikSg4REQkEgWHiIhE\nouAQEZFIFBwiIhKJgkNkEK1YW8aKtWWDXYZIJAoOERGJRMEhIiKRKDhERCQSBYeIiESi4BARkUgU\nHCIiEomCQ0REIlFwiIhIJAoOERGJRMEhIiKRKDhERCQSBYeIiESi4BARkUgUHCIiEomCQ0REIlFw\niIhIJNmpNDKzm4ETgThwlbuvTpi3DLgBaAMecffrki1jZpOBu4AsYCfwBXdvMrNLgKuBduA2d7/d\nzHKAO4Cp4bovc/etZrYCKAD2hyX8vbuv6cM+EBGRCHo84jCz04BZ7n4ScDlwS6cmtwDnA4uBs8xs\nTjfLXAvc6u6nAJuBL5lZAXANsAxYAnzdzEYBFwP73P1k4HrgBwnbvMzdl4R/FBoiIodRKqeqlgIP\nALj7BqDEzIoBzGwGsNfdt7t7O/BI2D7ZMkuAh8L1PkwQFicAq9292t0bgOcJQmgpcH/Ydnk4TURE\nBlkqp6rGAYnf6ivCaTXha0XCvHJgJjA6yTIF7t6U0HZ8knUcNN3d280sbma5YZtrzWw0sAG4Ogyc\nLpWU5JOdnZXC2xwcsVjRYJeQkqFSJwytWosKhwNDo+ahUGMH1TqwUurj6CSjF/O6mh6lbeL0fwfW\nu/sWM/sv4ErgxmQFVVXVJ5s16GKxIioqage7jB4NlTph6NVaW9cIkPY1D7X9qlr7rrtASyU4dhB8\n++8wgaBju6t5E8NpzUmWqTOzvPAIoaNtV+t4MWH6urCjPMPdm3n/9BUEp7suSuE9iIhIP0mlj+MJ\n4AIAMzsW2OHutQDuvg0oNrNpZpYNnBO2T7bMcoKOdMLXx4CXgEVmNtLMCgn6Mp4L13Fh2PZc4Gkz\nyzCz5WY2Mpy+BHi9l+9dRER6ocfgcPdVwBozW0VwddSVZnapmX0mbHIFcDfBh/297r6pq2XCtt8F\nvmhmzwGjgDvDo49vAY8TBMv33L0auBfIMrOV4fLfdvc4cBvwJzN7FpgM3Nr33SAiIqnKiMfjg13D\ngKqoqE3bN5jO5zcTDZU6YejVet+TGwFYsmDiIFfTvaG2X1Vr38ViRUn7s3XnuIiIRKLgEBGRSBQc\nIiISiYJDREQiUXCIiEgkCg4REYlEwSEiIpEoOEREJBIFh4iIRKLgEBGRSBQcIiISiYJDREQiUXCI\niEgkCg4REYlEwSEiIpEoOEREJBIFh4iIRKLgEBGRSBQcIiISiYJDREQiUXCIiEgkCg4REYlEwSEi\nIpEoOEREJBIFh4iIRKLgEBGRSBQcIiISiYJDREQiyU6lkZndDJwIxIGr3H11wrxlwA1AG/CIu1+X\nbBkzmwzcBWQBO4EvuHuTmV0CXA20A7e5++1mlgPcAUwN132Zu29N2O5XgG+7+7Q+vH8REYmoxyMO\nMzsNmOXuJwGXA7d0anILcD6wGDjLzOZ0s8y1wK3ufgqwGfiSmRUA1wDLgCXA181sFHAxsM/dTwau\nB36QUNMY4LzevWUREemLVE5VLQUeAHD3DUCJmRUDmNkMYK+7b3f3duCRsH2yZZYAD4XrfZggLE4A\nVrt7tbs3AM8ThNBS4P6w7fJwWocfEoSNiIgcZqmcqhoHrEn4uSKcVhO+ViTMKwdmAqOTLFPg7k0J\nbccnWcdB09293cziZpYLfBRocPeXzKzH4ktK8snOzkrhbQ6OWKxosEtIyVCpE4ZWrUWFw4GhUfNQ\nqLGDah1YKfVxdJLRi3ldTY/SNnH6tcCnu6nhIFVV9ak2PexisSIqKmoHu4weDZU6YejVWlvXCJD2\nNQ+1/apa+667QEvlVNUOgm//HSYQdGx3NW9iOC3ZMnVmltdD20Omhx3lGcAxwFjgUTN7ERhvZvek\n8B5ERKSfpBIcTwAXAJjZscAOd68FcPdtQLGZTTOzbOCcsH2yZZYTdKQTvj4GvAQsMrORZlZI0Jfx\nXLiOC8O25wJPu/tL7m7ufqK7nwjsdPfP9mkPiIhIJD2eqnL3VWa2xsxWEVwue6WZXQpUu/v9wBXA\n3WHze919E7Cp8zLh/O8CvwgvpX0HuNPdW8zsW8DjBJfufs/dq83sXuBMM1sJNAGX9tN7FhGRPsiI\nx+ODXcOAqqioTds3mM7nNxMNlTph6NV635MbAViyYOIgV9O9obZfVWvfxWJFSfuzdee4iIhEouAQ\nEZFIFBwiIhKJgkNERCJRcIiISCQKDhERiUTBISIikSg4REQkEgWHiIhEouAQEZFIFBwiIhKJgkNE\nRCJRcIiISCQKDhERiUTBISIikSg4REQkEgWHiIhEouAQEZFIFBwiIhKJgkNERCJRcIiISCQKDhER\niUTBISIikSg4REQkEgWHiIhEouAQEZFIFBwiIhKJgkNERCLJTqWRmd0MnAjEgavcfXXCvGXADUAb\n8Ii7X5dsGTObDNwFZAE7gS+4e5OZXQJcDbQDt7n77WaWA9wBTA3XfZm7bzWzTwHfBpqB8nAdjX3c\nDyIikqIejzjM7DRglrufBFwO3NKpyS3A+cBi4Cwzm9PNMtcCt7r7KcBm4EtmVgBcAywDlgBfN7NR\nwMXAPnc/Gbge+EG4jquAj7v7aUAdcF6v3rmIiPRKKqeqlgIPALj7BqDEzIoBzGwGsNfdt7t7O/BI\n2D7ZMkuAh8L1PkwQFicAq9292t0bgOcJQmgpcH/Ydnk4DXdf6u7VZpYNjAPKev/2RUQkqlSCYxxQ\nkfBzRTitq3nlwPhulilw96Ye2h4yPQyluJnlApjZpcBWYIu7P5PCexARkX6SUh9HJxm9mNfV9Cht\nD5ru7neY2S+BO83sYnf/dbKCSkryyc7OSjZ70MViRYNdQkqGSp0wtGotKhwODI2ah0KNHVTrwEol\nOHbw/hEGwASCju2u5k0MpzUnWabOzPLCU1Idbbtax4sJ09eFHeUZQKaZfdzdH3P3VjN7kOD0V9Lg\nqKqqT+EtDo5YrIiKitrBLqNHQ6VOGHq11tYF13Wke81Dbb+q1r7rLtBSOVX1BHABgJkdC+xw91oA\nd98GFJvZtLDP4ZywfbJllhN0pBO+Pga8BCwys5FmVkjQl/FcuI4Lw7bnAk8DrcBPzWxCOP0EwFN4\nDyIi0k96DA53XwWsMbNVBFdHXWlml5rZZ8ImVwB3E3zY3+vum7paJmz7XeCLZvYcMAq4Mzz6+Bbw\nOEGwfM/dq4F7gSwzWxku/213bwW+DDwQrmMq8NO+7wYREUlVRjweH+waBlRFRW3avsF0PkxNNFTq\nhKFX631PbgRgyYKJg1xN94baflWtfReLFSXtz9ad4yIiEomCQ0REIlFwSMpWrC1jxVrdbynyYafg\nEBGRSBQcIiISiYJDREQiUXCIiEgkCg4REYlEwSEiIpEoOEREJBIFh4iIRKLgEBGRSBQcIiISiYJD\nREQiUXCIiEgkvXnmuIj0s8TBI9P92RwiOuIQEZFIFBwiIhKJgkNERCJRcIiISCQKDhERiUTBISIi\nkSg4REQkEgWHiIhEouAQEZFIFBwiIhKJgkNERCJRcIiISCQKDhERiSSl0XHN7GbgRCAOXOXuqxPm\nLQNuANqAR9z9umTLmNlk4C4gC9gJfMHdm8zsEuBqoB24zd1vN7Mc4A5garjuy9x9q5nNB24N21YB\nF7t7fR/3g4iIpKjHIw4zOw2Y5e4nAZcDt3RqcgtwPrAYOMvM5nSzzLXAre5+CrAZ+JKZFQDXAMuA\nJcDXzWwUcDGwz91PBq4HfhCu4yfA37v7acBbwKW9eeMiItI7qZyqWgo8AODuG4ASMysGMLMZwF53\n3+7u7cAjYftkyywBHgrX+zBBWJwArHb3andvAJ4nCKGlwP1h2+XhNIBz3f3l8O8VQGkv3reIiPRS\nKqeqxgFrEn6uCKfVhK8VCfPKgZnA6CTLFLh7U0Lb8UnWcdB0d283s7iZ5bp7DUB4pPKXwIXdFV9S\nkk92dlYKb3NwxGJFg11CSmKxIooKhx/4ezpL9/oSdezTROlaf7rW1RXVOrB68wTAjF7M62p6lLYH\nTQ9D4yHgxvCIJqmqqvTt/ojFiqioqB3sMnrUUWdtXSNAWtc8VPYpBLV27NNE6Vj/UNuvqrXvugu0\nVE5V7SD49t9hAkHHdlfzJobTki1TZ2Z5PbQ9ZHrYUZ7h7s1mlg08CPza3e9IoX4REelHqQTHE8AF\nAGZ2LLDD3WsB3H0bUGxm08IP9HPC9smWWU7QkU74+hjwErDIzEaaWSFBX8Zz4To6TkOdCzwd/v2b\nwAp3v723b1pERHqvx1NV7r7KzNaY2SqCS2CvNLNLgWp3vx+4Arg7bH6vu28CNnVeJpz/XeAXZvYV\n4B3gTndvMbNvAY8TXLr7PXevNrN7gTPNbCXQxPtXT10JbAsvAwZ4yt2v7ctOEBGR1GXE4/HBrmFA\nVVTUpu0bTOfzm4k66lyxtgyAJQsmDnJFyQ2VfQpBrfc9ufGQ6em4f4faflWtfReLFSXtz9ad4yIi\nEomCQ0REIlFwiIhIJAoOERGJRMEhIiKRKDhERCQSBYeIiESi4BARkUgUHCJpZsXasgM3W4qkIwWH\niIhEouAQEZFIFBwiIhKJgkNERCJRcIiISCQKDhERiUTBISIikSg4REQkEgWHiIhEouAQEZFIFBwi\nIhKJgkNERCLJHuwCRD7s6hpaKK+qp7G5jSOnlJCZmTHYJYl0S8EhMkja2tp5cvV2dlbWH5jW3NLO\nglmjB7EqkZ7pVJXIIPnTK0FolI4YznEWo2B4Nq9tqaS8qr7nhUUGkYJDZBA0tbTxq8c2kpWZwenH\nTGDO9FGcfPR4AJ5bt5PmlrZBrlAkOQWHyCB4cvV29tY0MmdaCfnDcwAYW5LPvJml7G9sZd3mykGu\nUCQ5BYfIYVZb38wjL75DcUEuH5k+6qB582eWMjw3i607amhtax+kCkW6p+AQOcxWvraTxuY2Llw6\nm9ycrIPmZWZmMH18MU0tbazfoqMOSU8pXVVlZjcDJwJx4Cp3X50wbxlwA9AGPOLu1yVbxswmA3cB\nWcBO4Avu3mRmlwBXA+3Abe5+u5nlAHcAU8N1X+buW80sM9ze5e4e6/MeEDnMVm8oJzMjgzOOm8zj\nq7YeMn/mxGI2vFPFqtd3cexs/YpL+unxiMPMTgNmuftJwOXALZ2a3AKcDywGzjKzOd0scy1wq7uf\nAmwGvmRmBcA1wDJgCfB1MxsFXAzsc/eTgeuBH4Tr+BbwLqCL3WXIKd/XwLZdtcyZVkJxQW6XbUqK\nhjGyMJd1m/dQ19BymCsU6Vkqp6qWAg8AuPsGoMTMigHMbAaw1923u3s78EjYPtkyS4CHwvU+TBAW\nJwCr3b3a3RuA5wlCaClwf9h2eTgN4Cfu/p+9fsdpasXaMlasLRvsMmSAvbKxHIBFR45J2iYjI4OZ\nE0fQ1h7npTd3H67SRFKWyqmqccCahJ8rwmk14WtFwrxyYCYwOskyBe7elNB2fJJ1HDTd3dvNLG5m\nue5em9pbC5SU5JOdndVzw0ESixUBUFQ4/KCf000sVpT2NXZI5/rWbt5DVmYGZ350OvD+v3tn846I\n8eqmCl7eWM5nP37U4SwxqXTer52p1oHVmzvHuztFlGxeV9OjtO1pu0lVpfHNVLFYERUVQQ7W1jUC\nHPg5nXTUmc41dkjcp+mmvKqeze9VM29GKY37myjKzz2wT7ty1LRRvPH2XjZurqB0RNcBc7ik837t\nTLX2j+4CLZVTVTsIvv13mEDQsd3VvInhtGTL1JlZXg9tD5kedpRnuHtzCvWKpKXVKZymSrTgiGDo\nkfVbdXWVpJdUguMJ4AIAMzsW2NFxusjdtwHFZjbNzLKBc8L2yZZZTtCRTvj6GPASsMjMRppZIUFf\nxnPhOi4M254LPN23tyoyuNZ4BVmZGRwzO7WxqObPLAVg/eY9A1mWSGQ9nqpy91VmtsbMVhFcLnul\nmV0KVLv7/cAVwN1h83vdfROwqfMy4fzvAr8ws68A7wB3unuLmX0LeJzg0t3vuXu1md0LnGlmK4Em\n4FIAM/sJMA8YYWYrgIfc/aY+7wmRAVRd18S2XbUcNbWEgvBO8Z7ERuYxvjSfDe9U0dzSdsg9HyKD\nJaU+Dnf/VqdJ6xLmPQuclMIyuPtO4Mwupv8W+G2naW3AZV20/ZtUahZJJx038x0dHkWk6ugjRvPY\nS++y8d0q5s/UqLmSHnTnuHygPPbCtrS8tLkjOOYfEe3DvyNo1ukuckkjCg6RAdbS2s7r2/YypiSP\ncaPyIy07c+II8oZls35zJfF4fIAqFIlGwSEywDa9t4+m5jaO7sWppuysTOZOH0VlTSM79uwfgOpE\nolNwiAyw9Zs7TlNF69/oMF+nqyTNKDhEBti6LXsYlpuFTR7Zq+XnzSwlA12WK+lDwSEygHbtrae8\nqoG500aRndW7/27F+bnMmFDM5rIa9jdq0EMZfAoOkQG0LjxKmB/xMtzO5s8spT0e5/Wte/ujLJE+\nUXCIDKADl+H2OTjC4Ue26HSVDD4Fh8gAqW9sZdP2fUwbV8SIwmF9WteUsYWMLMzlta17aW/XZbky\nuBQcIgPkzW17aWuP9/loA4JndMyfWUpdQwtbd9T0Q3UivdebYdWlnzz2wrZuh9WWoa2jf+PoiHeL\nJzN/5mieXbeTdVv2cMSkEf2yzt5KvDN/yYKJg1iJDAYdcYgMgPZ4nNe2VlJckMvUcf3zoJ4500rI\nzspg7Vvq55DBpeAQGQDbdtZSU9/C/JmlZGb06hlkhxiem83c6aWU7dlPme4il0Gk4BAZAGs3B09D\njjoabk+OPyp4CNTqDXoWuQweBYdIP2uPx3nxjd0My8li7vT+DY6jjxhNTnYmL28o16CHMmgUHCL9\nbPN71eypbmShxRiW278PX8obls38maXs2lvP9vK6fl23SKoUHNKjeDzOu7trqaxppK6+hda29sEu\nKa2ten0XACfNHTcg6z/+qLHA+88wFzncdDmuJNXW3s7qjeUsX1PG1rLqA9OXv7Kd806bycnzxpOZ\n2T8dvx8ULa1trN5YzsjCXI6aUjIg25g/s5RhOVm8vGE35506g4x+6nwXSZWCQ7pU19DCrb9/Dd++\nj8wMWGgx6htbaWxupWzPfu54dCNPrXmPK/7XXMZGfDjRB9m6zZU0NLVy2oIpAxaqw3KyWDBrNC+9\nuZu33qtmdi9H3RXpLQWHHKK8qp6b71vP7r31HDNrNF+7cAFZ7e0Hbvo6euZofvfMFla9vosf/HIN\nf3fRAqaM7Z97FYa6jtNUHx2g01QdliyYwEtv7uaJ1dsVHHLYqY9DDrKzcj833LWG3XvrOfuEKVx5\n3jzGlRYc1KakaBh/dc4cPn/WbGrrW/jXX7/K5veqk6zxw2N3VT3rt1QyZWwhk2KFA7qt2ZNHMm1c\nEa9uqmB3Vf2Abqsn6fiMdxlYCg45YM++Bm68Zy019S1cvGwWF55+RLc3r51x7CT++tw5NDW3cdNv\n1vL2zg/3GEp/WLWN9nicT5w4dcC3lZGRwcdPmEIceHL19gHfnkgiBccgaW1rZ8eeOrbtrGHjO1W8\nvbOGuvqWQbs2f19dEzfes5aq2iYuPH0my46bnNJyJ35kHF/59EdoamnjpnvX8l7Fh/MS0d1V9bzw\n+m4mjC7guCPHHJZtLrQYpcXDWbl+J3UNesCTHD7q4zjMduzZz4pXy3jxzd1d/mdfsbaMM46dxJIF\nE8kffnj+eeoaWvjxvWsp39fAOR+dytknRPvGvOjIMTQ1H8XPH9nAjfes5duXHPuh6zDvONr41OJp\n/TbESE+yMjM5c9Fk7vnTWzyx+l3OO3XmgG5Pp6Okg4LjMKlvbOXBlW/zpzXv0R6PU5Sfw7yZpeTl\nZjEsN4v6xlb27Gtgd1UDv12xhT++sI2PHT+Fjx8/hdyc/r2JLFFDUys3/2YtZRX7WbpwEp85ZUav\n1nPy/PE0tbTxqyc38aN7XuXblyykdMTwfq42Pe2s3B/paKPjA7iosO/755T543n85Xd59MV3Oc7G\n6CIFOSwUHAOsPR7nhdd3cd/Tm6mpb2HMyDwuWDKTBbNGs+7tqkOGVT/+yDE8/WoZT67ezgPPvc3K\n9Tu56IxZHDt7dL9fr1/X0MItv1vP2ztrWTx3HJ9bNqtP21i6cBKNza387pmt/OieV/nmxcdSUtS3\nBxilu+aWNv77wTdoj8f5zCkzDtvRRoe8YdlcevaR3Pybddz+xw388xeP6/WzzXtSs7+Zsj37qahq\nYG9tE62t7bS2tzM8J4sRhcOormvmmFmjmTymUPeWfMApOAbQO7tq+eWTzpayGnKzMznv1Bl87PjJ\n5GQnP4J4eWM5BXk5fOKjU9lX08yTr2zn1vtfY860Ej63bDYTRxckXTaKyupGbvrNWnZW1nP8UWO4\n9BNHpvyh192zGD550jQam9v44wvvcP1dr/C3588/LN+CW9va2b23nu27a6ncV09mRgalxcMZWTiM\n8aX5A/JhGo/HuesJZ3t5HUsWTGChxfp9G6mYN6OUU4+ewLPrdvDQ89s479TeHTV2pbWtnT9vqmDV\nb9ezfvP7w7nnZmcyLDeL3Jxs6ptaqSmvY3t5HQ+ufJsxJXksnjuOU46ewMg+PvlQ0pOCYwDUNbTw\n+2e38syrZcSB444cw0WnHxHp1E1udhZ/ccYRnHL0eO7+01u8vnUv3739ZZYunMSnT55G/vCcXtf3\n2tZKfv7IBqrrmjlr0WT+4ozur56K6rxTZzA8N4vfPbOVG365hss/OYdF/dxhHI/H2VFZz6ubKtjw\nThVbdlTT3HLwUCjPrd8JBB9yU8YVMXf6KI6ZFWNSrKBfvhEvf+U9nn9tF9PGFfG5ZbP6vL6+uOiM\nI3jj7Ur+sGobw3OzOPuEKX16j7ur6nl27Q5WvraT2vqgL27sqDxmTChmbEk+Rfk5B9Yfj8dpbG5j\n9Ig81ng56zZXcv9zb/PQ89s4ZtZolhwzkaOmlugo5AMk44M+wmZFRe1he4M1+4MjhKf+/B4NTW2M\nL83nkjNnM2faqC7br9lc2e0TADu+zcfjcdZtqeSe5W9Rvq+BovwcPnnSNBbPG0dBhACprmvivhXB\njXtZmRlcePoRnLWo56unYrEiKipqu+wc7e7pb2u8gp/+4Q2aW9o5emYpn1s2izElve80b2tvZ0tZ\nDWvf2sOrb1Wwu6rhwLyJowuYMaGYptZ2MjOCfTYpVkjFvgbe3llLWcV+2sPf9dEjhrNg1miOmRVj\n9uQRZGVGOxppam7jriecVa/vojAvh2u+eByjR+alvHxiH0cq//6pKquo46bfrKOqtokzjp3IZ5fO\ninSk1dTcxrote3h23Q7e3FYFQMHwbBbPG89nzpjFC+tS6xxvaW0nOyuTp/9cduAqu7Gj8lmyYAKL\n542nMK/3X3pS0fH7OhSkc62xWFHSpE8pOMzsZuBEIA5c5e6rE+YtA24A2oBH3P26ZMuY2WTgLiAL\n2Al8wd2bzOwS4GqgHbjN3W83sxzgDmBquO7L3H2rmR0N/Fe43vXufkV3tQ90cDQ2t/L61r28vGE3\n67ZU0tLaTnF+Dp84cSpnLJzU7X/cVIOjQ0trO0+sfpc/rHqHppY2crIzOc5izJ1eypFTS7rsTwie\nUV3N86/t4s+bKmhrjzN1XBGXnX1kyqeQehscAGV79vOrJ5yN7+4jKzODY2bHWDx3HB+ZPqrHD7V4\nPE5lTSNbd9Swfksl67dUHrgSbVhOFnNnjOLY2THmzSg98GGUuE8Ta6tvbOW1rZW8+lYFr22tpKGp\nDQg+GOfPLGXOtFHMnDiCsSV5Sb8ZV+9v5qU3dvHUq2WUVzUwfXwRX/30XGIRQgMGLjgA9tY08m/3\nreO9iv2UFA3jzOMmc9LccYwoyD2kbTweZ9feejZt38cb26pYv2XPgaO22ZNHHjj9lpOdRSxWxH1P\nbky5jiULJhKPx9m6o4anXy3j5Q3ltLYFgXL0zFLmzSxl7vRRlBQN6/cjkXT+MO4snWvtU3CY2WnA\nN9z9HDM7Cvi5u5+UMP9N4GNAGfAM8BUg1tUyZvY/BOFyn5ndAGwHfgH8GTgeaAZWA6cC5wLHu/uV\nZnYWcLm7X2RmTwP/GAbRr4G73P3RZPX3JThq6pup3d9MY0sbzc1tNLa0Ud/YSmV1IxXVDbyzq5ay\nPfvp2IVjR+WzbOEkTpk/PqUroaIGR2Jdz7+2k2de3UH5vve/decNy6KkaDh5uVk0t7ZT39hCZU3T\ngfkTRxdwxsJJnHr0+EjfsvsSHBB8QK3eWM6DK99mZ2Vwl3NWZgaTYoVMGJ1PQV4OebnZtMfjNLe0\nU9vQzJ7qRnbvrT9wmgRgZGEuC44YzYJZMY6aOrLLvqKu9mnnGlvb2vF39/HntypY+9Yeqmrf30fD\nc7MYPSKP0SOGk5uTSVZmBrUNLVRUNVCxr5H2eJyszAyWLpzEBUtm9qrvZCCDA4KQfOj5t3lm7Q6a\nWoKAHFGQy9hR+WSF42ftq2tiT3UjLa3vn94bW5LHoqPGcuKcsUzo1JfWm+BIVNfQwqrXdvLMuh0H\nfgcAigtymTK2kLEl+ZQWD2dEYS7Dc7MYnpsdvmaRlZlBRkYGGRmQQfia0ek1YVulpYVUVqZ2P1Gv\nPxx6uWDnxUpLC6isTOFpjr08M1RckNvrYO4uOFLp41gKPADg7hvMrMTMit29xsxmAHvdfTuAmT0S\nto91tQzbuu1OAAALC0lEQVSwBPhquN6HgX8AHFjt7tXhOp4HFofr+UXYdjnwczPLBaYnHPE8DCwD\nkgZHb23bVcN1d77S7b9Xbk4msyaOYPaUkRxnYw7b1STF+bmcfcJUPnb8FLbvrmPDO1Vs2r6PPdUN\n7K1pYndLG7k5mcGjRmeMYtq4YuZOH8WsSSMG5TxzRkYGxx81lkVHjmHbrlpeeH0XW3ZUs718P+/s\n7vrbVmZGBqOKh2E2kunjizlyaglTxxX1S19MdlYmH5k+io9MH8Xnz5zNu7vr2FxWzZayarZX1FGx\nr+GQGxkL83KYObGYRUeO4YQ5YynKP/QbfLrIH57NZ5fO4tzF03h23Q7e2l7N9vJaNm3fd6BNwfBs\nJpQWML40n1mTRzJ78kgmlOZ3+fuxYm1Zny8dLszL4azjp3Dmosnsrmpg/ZZK/N0q3t1dy+tb9/I6\ne/u0funa4nnjuPyTc/p9vakExzhgTcLPFeG0mvC1ImFeOTATGJ1kmQJ3b0poOz7JOg6a7u7tZhYP\np1V10Tap7lKzh+V46MbefeNL1cdjfb/aaOyYYo6bN6EfquleLFbEhWce2ef1jBlTzPHzB26/9maf\njjlM+7BDf+zHVMSAaZO77l+Lor/rHTOmmHk2tl/XKYdXb65R7O6DONm8rqZHaRt1HSIiMkBSCY4d\nBN/0O0wg6Njuat7EcFqyZerMLK+HtodMDzvKM8J1lHbRVkREDpNUguMJ4AIAMzsW2OHutQDuvg0o\nNrNpZpYNnBO2T7bMcuD8cL3nA48BLwGLzGykmRUS9G88F67jwrDtucDT7t4CbDSzk8Pp54XrEBGR\nwyTVy3H/L8GVTu3AlcAxQLW7329mpwL/Gjb9nbvf2NUy7r7OzMYTdHgPB94huMS2xcwuAL5BcNHB\nT9z9V2aWBfwMmAU0AZe6+3YzmwP8P4LQe8nd/65f9oSIiKTkA38DoIiI9C89j0NERCJRcIiISCQa\n5LAXzGwu8CBws7v/x0AOpWJm3yC4SCAOfM/dHzGzEcCvgRFAHXCxux9yB5WZ/RA4heDf+QcEd+Wn\nY5354bbGEvR/XQesS8daE2rOA14Pa/1TOtZqZkuA+4A3wkmvAT9Mx1rD5S8B/hFoBa4B1qdjrWZ2\nOfCFhEnHEVzU06ft9MfwTV3t14GgI46IzKwA+AnBh0WHa4Fb3f0UYDPwpbDdNQR3ti8Bvm5mo4CL\ngX3ufjJwPcEHOsC/EfxSLAZGmNnZZjYd+CxwMsEVazeFFw1cDawI1/F74Jtd1Hk6MDccHubj4frT\nrs7QucAr7n4a8BfATWlca4d/ggO3O6dzrc+4+5Lwz9+ka61mVgp8N2H5T6drre5+e8c+DWu+s5+2\ncwvB1aaLgbPMbE445NOs8P/x5WEbuto3XdU6UBQc0TUBn+Dg+0eWAA+Ff+8YBuUEwqFU3L0BSBxK\n5f6w7XJgcTdDqZwOPOruze5eQXAl2pxO6+ho29mzvH858z6gIE3rxN3vdfcfhj9OBt5L11oBzOzI\ncJk/hpPSttYupGuty4Dl7l7r7jvd/ctpXGuiawiuKu3TdhKHb3L3dqBj+KaDhnwCEodv6rxvDhsF\nR0Tu3hr+wibq9VAqBIefyYZS6XEdJBl2xd3b3L1j9LTLCX4R067ORGa2iuAQ/uo0r/XHQOJl4Olc\n6xwze8jMVprZmWlc6zQgP6z1OTNbmsa1AmBmiwgGam3th+2k0ha6H77psFFw9L+BHEol8rArZvZp\nguD4333YRtRt92p4GHf/KPAp4Jed2qdNrWb2l8AL7v52P9QUdftR9+tbwPcITvt8Ebidg/s106nW\nDIJRIc4DLgX+hzT9HUjwVwT9KoerpqjrGDAKjv4xUEOppDKkS9JhV8zsY8D/Ac72YPThdK1zYdjZ\nh7uvJfhwq03HWoFPAp82sxcJPjj+mTTdr+5eFp4GjLv7FmAXwamOtKsV2A2sCo/otwC1pO/vQIcl\nwCqCo4C+bqc/hm86bBQc/WOghlJ5CvikmeWa2QSCX5A3O62jY3sHCa/c+BFwTsKVIWlXZ+hU4O/D\nuscChelaq7tf5O6L3P1EgpENrkvXWs3sEjP7h/Dv4wiuWvufdKw1bHeGmWWGHeVp+zsQ7s8JQF3Y\nf9Hn7Xj/DN902OjO8YjMbCHBOe5pQAvBA6wuIThk7fehVMzsb8L1x4F/cvc/hf9hfknwLWcf8Pnw\niCKxzi8D/wJsSpj8xXDbaVNnuGwewWmUyUAewemVVxig4Wn6Umunuv8F2AY8no61mlkRQZ/RSCA3\n3K+vpmOt4fJfITitCvB9gsvH07XWhcD33f3s8Oc+b8f6YfimrmodCAoOERGJRKeqREQkEgWHiIhE\nouAQEZFIFBwiIhKJgkNERCLR6LjyoRdeY3+kuz81CNu+A1jp7j8boPVvIxjH6B2C0VuPIrjk+W53\n/5GZTQu3P6mLZVcSXEK6YiBqk6FLRxwiwWB0Zwx2EQPsy8AwD0ZvXQz8bRgaIpHpiEM+sMzsnwjG\naWoneHbBWoIbrJqAfOBrBIPTXQ9kmNle4D+AW4EjgCKCb+Y/NrPhBMNnTyMYvbcVeNLdf2ZmXwK+\nCtQTDJ3x1+5eY2Y1BDc2ZgELgf/T8e3dzB4lGJ4/We0lwH8DMYLnNvwYeJTghs5JHjyXIg94l+Cm\nt2MIhvjOILgx9a87jaf1U+DnAO7eYGb7CW5Aq0zYZj5wT7jNtwhuLhM5hI445APJzE4hGLbhRILn\nIZwFjAaucPczgH8HvhN+uN4B3OXuNwFXEQzrcDrBEN6fNbP5wOeBHHc/AbgyXB9mNoXgjuylHjyf\nYTvw9bCMQoIH8vwtwV3Fl4bLjAKM7oeJ+D7BUBRnENw1fC3BF73ngY+FbT4BPAM0E4TMeR480+Qn\nwI2JKwuHxmgIt38eQci92mmbnwcaPHj2wzeBud3UJx9iOuKQD6oTgOfcvY3giWqfMrMTgRvDo4cR\nHDwUdofTgUkWPEAHgm/dRwALgBUA7r4rPP8PcCywJhw/iLDNV8O/ZxB80AP8Bvh+ONzEZ4BfuXu7\nmSWr/3SCMZm+GP7cAkwHfkUwdtFDwEUEQ1fMJRhW+/fh+rIIhrg4RDhcx/XAx7rY/jxgZfged5rZ\nxmTFyYebgkM+qOIcekR9F/AVd3/KzM4B/qGL5ZqAa939t4kTLXisZ3vCpLaE7STK6DStGcDdG83s\n9wShcQHBabLuNAFfc/dXOtWxHvhxeCrrJIKjhKOAd8MjnqTM7HME73mJu+/sokkGB7/HrB5qlA8p\nnaqSD6pVwFIzyzGzbDN7mqB/4o1wQLwLgWFh23YgJ/z7SoLH1xKO1HpTeGppI/DRcPoYgtNfAGuA\nheGAghBcwfRikppuIwiMjG6e59EhsY48M/tPM8t290aCUVevBx5292aCfo/RZjY3bH9qOMjlAWY2\nG/gOsCxJaEAwcutJYfvJBKfTRA6hIw75QHL3F8zsdwRDbgPcTTAU9VMEl6b+CLjLzK4O29xrZs0E\nH8gfMbMXCL5x/8Hd94aXzZ4TTn87XKbV3d8zs38GlptZE0HH+XeS1PRmGFp3dJr1DTP7fMLPXyMY\n2fhn4SmxYcBt7t4azv8VQUf5qeF6G8LlbzezxrDNQcFB0HdTBNyfcHrqR8AbCW3uIjil91z4Hl/u\n6n2IaHRckRSY2UTgo+5+n5llAn8m6Gh/IcI6phE8wvfowzkEtkh/06kqkdTsI7jC6mXgBeDRiKHx\nHeBBgstkFRoypOmIQ0REItERh4iIRKLgEBGRSBQcIiISiYJDREQiUXCIiEgk/x9Koc6tGkpsCQAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe25f4fb240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.distplot(X.categoryLevel2Id,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.66666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e6/1.5e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/statsmodels/nonparametric/kde.py:475: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "  grid,delta = np.linspace(a,b,gridsize,retstep=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe25f0c39b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAEGCAYAAACn2WTBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4h4mEJaRMTDFNIiIh72/wFTHtGO5WckVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe25f14bc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.distplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_int=y.apply(lambda x:int(round( x)))#Ну и про классификацию не забудем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Начнем инженирить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp=pd.DataFrame(X.categoryLevel1Id/100)\n",
    "X[\"cat_norm?\"]=np.array(temp.apply(lambda x:round( x)),dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"year\"]=np.array(X.date.apply(lambda x: x[:4]),dtype=\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"month\"]=np.array(X.date.apply(lambda x: x[5:7]),dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"days\"]=np.array(X.date.apply(lambda x: x[8:10]),dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"count\"]=X.year*365.25+X.month*(365.25/12)+X.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"count\"]=X[\"count\"]-min(X[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.drop(\"date\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"userName\"]=pd.factorize(X.userName)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.fillna(value=\"милад\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"additional_comment\"]=pd.factorize(X.commentNegative.apply(lambda x:x==\"милад\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"full_com\"]=X.comment+\" \"+X.commentNegative+\" \"+X.commentPositive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.drop([\"comment\",\"commentNegative\",\"commentPositive\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/statsmodels/nonparametric/kde.py:475: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "  grid,delta = np.linspace(a,b,gridsize,retstep=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe25cc61860>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAERCAYAAAC5ClbiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe25cc5d898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.distplot(X.sku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"comment\"]=X.full_com.apply(lambda x: re.sub('\\W', ' ', x).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"ww_prop\"]=X.property.apply(lambda a:re.sub(\"\\W\",\" \",a).split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"ww_prop_hz_malo\"]=X.loc[:,\"ww_prop\"].apply(lambda x:x[::2])\n",
    "X[\"ww_prop_hz_mnogo\"]=X.loc[:,\"ww_prop\"].apply(lambda x:x[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.drop(\"ww_prop\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X.drop(\"full_com\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.drop(\"property\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=\"алтухов\tбольшой\tбы быть\tв\tвесь вот\tвсе\tвсей вы\tговорить\tгод да\tдля\tдо еще\tже\tзнать и\tиз\tк как\tкоторый\tмочь мы\tна\tнаш не\tнего\tнее нет\tних\tно о\tодин\tона они\tоно\tоный от\tото\tпо с\tсвой\tсебя сказать\tта\tтакой только\tтот\tты у\tчто\tэто этот\tя\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b=\"\"\" ах, ух, ну, уж, ой;\n",
    " я, мы, мой, вы, ваш;\n",
    " скажем, допустим, например, в общем, на самом деле;\n",
    " всего, примерно, около, где-то, порядка;\n",
    " очень, максимально, абсолютно, предельно, сильно, наиболее, самый;\n",
    " красивый, дорогой, уютный, роскошный, активный;\n",
    " пески времени, в лучших традициях, царила атмосфера, ударными темпами;\n",
    " шаг за шагом, мало-помалу, так или иначе, сплошь и рядом, направо и налево;\n",
    " завоевать доверие клиентов, решать задачи бизнеса, расширить географию продаж;\n",
    " в настоящее время, в наши дни, в современной России;\n",
    " осуществлять деятельность, производить ремонт, оказывать услуги по ремонту;\n",
    " можете авторизоваться, должны завершить заказ, нужно пройти процедуру.\n",
    " мне бы хотелось поговорить, было бы здорово созвониться;\n",
    " школа построена по заказу мэрии, леса вырубают;\n",
    " данный сайт, этот документ, меню ниже, на этой странице, форма внизу страницы, нажмите на кнопку, кликните здесь;\n",
    " что-то, какой-то, где-то, как-то, зачем-то.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words=list(set(list(set(b.split()))+list(set(a.split()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaner(a):\n",
    "    l3 = [x for x in a if x not in stop_words]\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '5',\n",
       " 'года',\n",
       " 'работала',\n",
       " 'устала',\n",
       " 'Лампочка',\n",
       " 'горит',\n",
       " 'больше',\n",
       " 'ничего',\n",
       " 'милад',\n",
       " 'милад']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner(X.comment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gladmean(X,test,base,target,alf):\n",
    "    #alf=25\n",
    "    for i in base:\n",
    "        for j in (X[i].unique()):\n",
    "            mean_likehood=(X.loc[X[i]==j,target].mean()*len(X.loc[X[i]==j,target])+alf*X[target].mean())/(len(X.loc[X[i]==j,target])+alf)\n",
    "            X.loc[X[i]==j,\"{}_glad_mean\".format(i)]=mean_likehood\n",
    "            test.loc[test[i]==j,\"{}_glad_mean\".format(i)]=mean_likehood\n",
    "        \n",
    "        \n",
    "    return \"I_love_trains\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 16.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#gladmean(train,test,base=[\"categoryLevel1Id\",'categoryLevel2Id','brandId','userName','cat_norm?','year','month','additional_comment',\"sku\"],target=\"y\",alf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##data prep has finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_df=feature_extraction.text.TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_full=tf_df.fit_transform(X.full_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=scipy.sparse.coo_matrix(X.iloc[:,:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15587, 474332)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_data=scipy.sparse.hstack((a,tf_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"./tf_data\",tf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##data to sparce under tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 35s, sys: 2.79 s, total: 16min 38s\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = gensim.models.word2vec.Word2Vec(X.comment,alpha=0.017, size=50, iter=400,window=9, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"./ww_com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mean_vectorizer(object):#класс который усредняет вектора\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(next(iter(w2v.values())))\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)#если слова нет, то меняем на нули и все хорошо)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_test=mean_vectorizer(w2v).fit(X.comment).transform(X.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=scipy.sparse.coo_matrix(new_test,dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=scipy.sparse.hstack((a,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15587, 474393)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 15s, sys: 1.67 s, total: 9min 16s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model1 = gensim.models.word2vec.Word2Vec(X.ww_prop_hz_malo,alpha=0.017, size=25, iter=400,window=9, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.save(\"./ww_malo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = dict(zip(model1.wv.index2word, model1.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_test=mean_vectorizer(w2v).fit(X.ww_prop_hz_malo).transform(X.ww_prop_hz_malo)\n",
    "a=scipy.sparse.coo_matrix(new_test,dtype=\"float64\")\n",
    "data=scipy.sparse.hstack((a,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15587, 474418)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 52s, sys: 496 ms, total: 1min 52s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model2 = gensim.models.word2vec.Word2Vec(X.ww_prop_hz_mnogo,alpha=0.017, size=25, iter=100,window=9, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.save(\"./ww_mnogo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = dict(zip(model2.wv.index2word, model2.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_test=mean_vectorizer(w2v).fit(X.ww_prop_hz_mnogo).transform(X.ww_prop_hz_mnogo)\n",
    "a=scipy.sparse.coo_matrix(new_test,dtype=\"float64\")\n",
    "data=scipy.sparse.hstack((a,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ram_ww=gensim.models.Word2Vec.load(\"./5000iter7win50size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = dict(zip(ram_ww.wv.index2word, ram_ww.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_test=mean_vectorizer(w2v).fit(X.comment).transform(X.comment)\n",
    "a=scipy.sparse.coo_matrix(new_test,dtype=\"float64\")\n",
    "data=scipy.sparse.hstack((a,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##training gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ww_ready=np.array(X.iloc[:,:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ram_ww=gensim.models.Word2Vec.load(\"./5000iter7win50size\")\n",
    "w2v = dict(zip(ram_ww.wv.index2word, ram_ww.wv.syn0))\n",
    "new_test=mean_vectorizer(w2v).fit(X.comment).transform(X.comment)\n",
    "ww_ready=np.hstack((ww_ready,new_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ram_ww=gensim.models.Word2Vec.load(\"./ww_com\")\n",
    "w2v = dict(zip(ram_ww.wv.index2word, ram_ww.wv.syn0))\n",
    "new_test=mean_vectorizer(w2v).fit(X.comment).transform(X.comment)\n",
    "ww_ready=np.hstack((ww_ready,new_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ram_ww=gensim.models.Word2Vec.load(\"./ww_malo\")\n",
    "w2v = dict(zip(ram_ww.wv.index2word, ram_ww.wv.syn0))\n",
    "new_test=mean_vectorizer(w2v).fit(X.ww_prop_hz_malo).transform(X.ww_prop_hz_malo)\n",
    "ww_ready=np.hstack((ww_ready,new_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ram_ww=gensim.models.Word2Vec.load(\"./ww_mnogo\")\n",
    "w2v = dict(zip(ram_ww.wv.index2word, ram_ww.wv.syn0))\n",
    "new_test=mean_vectorizer(w2v).fit(X.ww_prop_hz_mnogo).transform(X.ww_prop_hz_mnogo)\n",
    "ww_ready=np.hstack((ww_ready,new_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15587, 211)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww_ready.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"./ww_full_data.txt\",ww_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### data prep  using word to vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ww=np.loadtxt(\"./ww_full_data.txt\")\n",
    "data_tf=scipy.sparse.load_npz(\"./tf_data.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tf, X_test_tf, y_train, y_test = model_selection.train_test_split(\n",
    "    data_tf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_ww, X_test_ww, y_train1, y_test1 = model_selection.train_test_split(\n",
    "    data_ww, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.118766541021734, 1.3155674546503022, 4.1174150096215518, 1.322753707559432)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean(),y_train.std(),y_test.mean(),y_test.std()#какой огромный стд:("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.410377445071\n",
      "CPU times: user 540 ms, sys: 388 ms, total: 928 ms\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lin_clf = svm.LinearSVC(random_state=42)\n",
    "lin_clf_an=model_selection.cross_val_predict(lin_clf,X_train_ww,np.array(y_train,dtype=\"int8\"),cv=5,n_jobs=-1)\n",
    "print(metrics.f1_score(np.array(y_train,dtype=\"int8\"),lin_clf_an,average=\"weighted\"))\n",
    "np.savetxt(\"./lin_clf_an_stack_clf\",lin_clf_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.410377445071\n",
      "CPU times: user 1.18 s, sys: 564 ms, total: 1.74 s\n",
      "Wall time: 4min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lin_clf = svm.LinearSVC(random_state=42)\n",
    "lin_clf_an=model_selection.cross_val_predict(lin_clf,X_train_tf,np.array(y_train,dtype=\"int8\"),cv=5,n_jobs=-1)\n",
    "print(metrics.f1_score(np.array(y_train,dtype=\"int8\"),lin_clf_an,average=\"weighted\"))\n",
    "np.savetxt(\"./lin_clf_an_tf_stack_clf\",lin_clf_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 15s, sys: 860 ms, total: 45min 16s\n",
      "Wall time: 5min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf=ensemble.RandomForestRegressor(n_estimators=125,n_jobs=-1,random_state=42)\n",
    "rf_an=model_selection.cross_val_predict(rf,X_train_ww,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1108329577159357"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_train,rf_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"./rf_for_stack\",rf_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.8 s, sys: 20 ms, total: 42.9 s\n",
      "Wall time: 43.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr    = linear_model.LogisticRegression(solver=\"sag\",multi_class = 'multinomial' , n_jobs=-1,random_state=42)\n",
    "lr_an = model_selection.cross_val_predict(lr,X_train_ww,np.array(y_train,dtype=\"int8\"),cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "metrics.f1_score(np.array(y_train,dtype=\"int8\"),lr_an,average=\"weighted\")\n",
    "np.savetxt(\"./lr_wv_for_stack_clf\",lr_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.438568583885\n",
      "CPU times: user 59.4 s, sys: 124 ms, total: 59.5 s\n",
      "Wall time: 59.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr    = linear_model.LogisticRegression(solver=\"sag\",multi_class = 'multinomial' , n_jobs=-1,random_state=42)\n",
    "lr_an = model_selection.cross_val_predict(lr,X_train_tf,np.array(y_train,dtype=\"int8\"),cv=5)\n",
    "print(metrics.f1_score(np.array(y_train,dtype=\"int8\"),lr_an,average=\"weighted\"))\n",
    "np.savetxt(\"./lr_tf_for_stack_clf\",lr_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.80749456069\n",
      "CPU times: user 5.18 s, sys: 4.44 s, total: 9.62 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kn    = neighbors.KNeighborsRegressor(n_neighbors=7,weights=\"distance\",n_jobs=-1)\n",
    "kn_an = model_selection.cross_val_predict(kn,X_train_tf,y_train,cv=5)\n",
    "print(metrics.mean_squared_error(y_train,kn_an))\n",
    "np.savetxt(\"./kn_tf_for_stack_clf\",kn_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.79382348988\n",
      "CPU times: user 5.72 s, sys: 8 ms, total: 5.73 s\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kn    = neighbors.KNeighborsRegressor(n_neighbors=7,weights=\"distance\",n_jobs=-1)\n",
    "kn_an = model_selection.cross_val_predict(kn,X_train_ww,y_train,cv=5)\n",
    "print(metrics.mean_squared_error(y_train,kn_an))\n",
    "np.savetxt(\"./kn_ww_for_stack_clf\",kn_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15587, 211)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.7641567086\n"
     ]
    }
   ],
   "source": [
    "ms=cluster.MeanShift(n_jobs=-1)\n",
    "ms_an = model_selection.cross_val_predict(ms,X_train_ww,y_train,cv=5,n_jobs=-1)\n",
    "print(metrics.mean_squared_error(y_train,ms_an))\n",
    "np.savetxt(\"./db_ww_for_stack_clf\",ms_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99932873526\n",
      "CPU times: user 424 ms, sys: 604 ms, total: 1.03 s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tr    = tree.DecisionTreeRegressor(random_state=42)\n",
    "tr_an = model_selection.cross_val_predict(tr,X_train_tf,y_train,cv=5,n_jobs=-1)\n",
    "print(metrics.mean_squared_error(y_train,tr_an))\n",
    "np.savetxt(\"./tr_tf_for_stack_clf\",tr_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.94850990456\n",
      "CPU times: user 576 ms, sys: 588 ms, total: 1.16 s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "etr    = tree.ExtraTreeRegressor(random_state=42)\n",
    "etr_an = model_selection.cross_val_predict(etr,X_train_tf,y_train,cv=5,n_jobs=-1)\n",
    "print(metrics.mean_squared_error(y_train,etr_an))\n",
    "np.savetxt(\"./etr_tf_for_stack_clf\",etr_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "\n",
    "    cv_result = xgboost.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,\n",
    "             seed=random_state,\n",
    "             callbacks=[xgboost.callback.early_stop(5)])\n",
    "\n",
    "    return -cv_result['test-rmse-mean'].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain=xgboost.DMatrix(X_train_ww,label=y_train)\n",
    "num_rounds = 3000\n",
    "random_state = 42\n",
    "num_iter = 300\n",
    "init_points = 25\n",
    "params = {\n",
    "        'eta': 0.1,\n",
    "        'silent': 1,\n",
    "        'eval_metric': 'rmse',\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state\n",
    "    }\n",
    "\n",
    "xgbBO = bayes_opt.BayesianOptimization(xgb_evaluate, {'min_child_weight': (1, 20),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'max_depth': (5, 15),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'gamma': (0, 10),\n",
    "                                                'alpha': (0, 10),\n",
    "                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[126]\ttrain-rmse:0.731027+0.00215038\ttest-rmse:1.00624+0.0120391\n",
      "\n",
      "    1 | 00m52s | \u001b[35m  -1.00624\u001b[0m | \u001b[32m   6.0141\u001b[0m | \u001b[32m            0.3223\u001b[0m | \u001b[32m   8.4318\u001b[0m | \u001b[32m     8.4851\u001b[0m | \u001b[32m           13.2340\u001b[0m | \u001b[32m     0.5157\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[141]\ttrain-rmse:0.690149+0.00203189\ttest-rmse:0.995192+0.0110829\n",
      "\n",
      "    2 | 00m58s | \u001b[35m  -0.99519\u001b[0m | \u001b[32m   8.7382\u001b[0m | \u001b[32m            0.8109\u001b[0m | \u001b[32m   4.8098\u001b[0m | \u001b[32m     6.3207\u001b[0m | \u001b[32m           11.4617\u001b[0m | \u001b[32m     0.5851\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[147]\ttrain-rmse:0.402259+0.00398663\ttest-rmse:1.00707+0.00959597\n",
      "\n",
      "    3 | 01m29s |   -1.00707 |    1.1982 |             0.6711 |    2.0602 |      7.6590 |             5.7610 |      0.8165 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[174]\ttrain-rmse:0.655645+0.00228882\ttest-rmse:1.00606+0.0113181\n",
      "\n",
      "    4 | 02m04s |   -1.00606 |    4.5109 |             0.5794 |    8.2844 |      9.3844 |             8.5569 |      0.7099 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[172]\ttrain-rmse:0.716502+0.00207272\ttest-rmse:0.995294+0.011458\n",
      "\n",
      "    5 | 01m08s |   -0.99529 |    9.1088 |             0.4533 |    5.3777 |      5.3029 |             9.1342 |      0.7541 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-rmse:0.522452+0.00236303\ttest-rmse:1.00832+0.00972894\n",
      "\n",
      "    6 | 01m08s |   -1.00832 |    8.1430 |             0.3622 |    1.5304 |     12.7064 |            17.7247 |      0.5315 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[152]\ttrain-rmse:0.550701+0.00213516\ttest-rmse:1.00024+0.00783041\n",
      "\n",
      "    7 | 02m23s |   -1.00024 |    5.1967 |             0.8405 |    5.0559 |     11.2182 |            19.2572 |      0.9171 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[174]\ttrain-rmse:0.537513+0.00288267\ttest-rmse:0.998282+0.00968931\n",
      "\n",
      "    8 | 02m41s |   -0.99828 |    7.7157 |             0.5063 |    4.1320 |     11.0136 |            17.9670 |      0.8923 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[115]\ttrain-rmse:0.710397+0.00394105\ttest-rmse:1.0065+0.0134298\n",
      "\n",
      "    9 | 01m17s |   -1.00650 |    5.2269 |             0.5513 |    8.7684 |     10.4605 |            14.6644 |      0.5927 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[111]\ttrain-rmse:0.313002+0.00181122\ttest-rmse:1.01374+0.00779033\n",
      "\n",
      "   10 | 01m38s |   -1.01374 |    1.5809 |             0.5687 |    1.2606 |     10.9031 |            12.1149 |      0.8172 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[180]\ttrain-rmse:0.580995+0.00256318\ttest-rmse:1.00742+0.00975384\n",
      "\n",
      "   11 | 03m20s |   -1.00742 |    1.2474 |             0.5035 |    8.7521 |     14.3465 |            14.0960 |      0.9092 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[144]\ttrain-rmse:0.684341+0.00423478\ttest-rmse:0.998447+0.0128286\n",
      "\n",
      "   12 | 01m04s |   -0.99845 |    1.8837 |             0.3305 |    5.1221 |      5.0857 |            18.8431 |      0.8204 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[175]\ttrain-rmse:0.642273+0.0028483\ttest-rmse:1.00036+0.0101609\n",
      "\n",
      "   13 | 01m06s |   -1.00036 |    3.5092 |             0.2083 |    4.0436 |      5.4780 |             5.7500 |      0.6552 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[181]\ttrain-rmse:0.5293+0.00246915\ttest-rmse:0.994254+0.0122324\n",
      "\n",
      "   14 | 01m35s | \u001b[35m  -0.99425\u001b[0m | \u001b[32m   9.3053\u001b[0m | \u001b[32m            0.1887\u001b[0m | \u001b[32m   1.6197\u001b[0m | \u001b[32m     6.9149\u001b[0m | \u001b[32m           11.1673\u001b[0m | \u001b[32m     0.8281\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[165]\ttrain-rmse:0.724556+0.00234152\ttest-rmse:0.999256+0.0142099\n",
      "\n",
      "   15 | 01m10s |   -0.99926 |    7.9968 |             0.7817 |    7.0082 |      6.6730 |            14.1026 |      0.6052 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[205]\ttrain-rmse:0.722883+0.00396641\ttest-rmse:0.998583+0.0108257\n",
      "\n",
      "   16 | 01m31s |   -0.99858 |    4.3280 |             0.3012 |    9.2681 |      6.8119 |            13.9057 |      0.6591 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[133]\ttrain-rmse:0.51804+0.00276866\ttest-rmse:1.01711+0.00751358\n",
      "\n",
      "   17 | 01m48s |   -1.01711 |    4.9308 |             0.1501 |    3.7538 |     11.7194 |             5.7933 |      0.6200 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[131]\ttrain-rmse:0.414367+0.00162927\ttest-rmse:1.00626+0.0127961\n",
      "\n",
      "   18 | 01m42s |   -1.00626 |    2.6561 |             0.8178 |    2.4159 |      9.5948 |            12.1479 |      0.7785 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[177]\ttrain-rmse:0.621358+0.00132243\ttest-rmse:1.0013+0.00960022\n",
      "\n",
      "   19 | 02m14s |   -1.00130 |    7.0435 |             0.2387 |    5.5487 |     14.9178 |            16.1223 |      0.5541 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[131]\ttrain-rmse:0.702787+0.00169505\ttest-rmse:1.00206+0.0129357\n",
      "\n",
      "   20 | 01m29s |   -1.00206 |    8.0277 |             0.6626 |    7.9619 |      7.2689 |            10.0265 |      0.9667 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[99]\ttrain-rmse:0.430075+0.00594745\ttest-rmse:1.00994+0.0112326\n",
      "\n",
      "   21 | 00m59s |   -1.00994 |    2.3890 |             0.4048 |    0.0377 |      8.1083 |            16.0727 |      0.6668 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[121]\ttrain-rmse:0.526853+0.00312814\ttest-rmse:1.02154+0.0137331\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 | 01m58s |   -1.02154 |    0.4182 |             0.2138 |    6.3138 |     14.8424 |             7.8378 |      0.6095 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[113]\ttrain-rmse:0.620671+0.00307578\ttest-rmse:1.00183+0.0111278\n",
      "\n",
      "   23 | 01m43s |   -1.00183 |    6.2389 |             0.4730 |    5.9652 |     13.3176 |            18.8364 |      0.7483 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[134]\ttrain-rmse:0.516529+0.000502267\ttest-rmse:1.00107+0.0142647\n",
      "\n",
      "   24 | 01m28s |   -1.00107 |    5.6251 |             0.1133 |    3.1815 |      9.6980 |            11.1446 |      0.6385 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[149]\ttrain-rmse:0.524282+0.00163087\ttest-rmse:1.0045+0.0111818\n",
      "\n",
      "   25 | 02m01s |   -1.00450 |    4.0213 |             0.8569 |    4.5142 |     10.5460 |            12.3230 |      0.7675 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[145]\ttrain-rmse:0.735291+0.0101335\ttest-rmse:1.00571+0.0109549\n",
      "\n",
      "   26 | 02m26s |   -1.00571 |    0.0610 |             0.7006 |    9.1900 |      5.0397 |             1.9661 |      0.9965 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[169]\ttrain-rmse:0.807116+0.00227194\ttest-rmse:0.999309+0.0132529\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'nit': 5, 'grad': array([ -2.09860045e-05]), 'funcalls': 52, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH'}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   27 | 01m43s |   -0.99931 |    9.9188 |             0.2273 |    9.1642 |      5.0138 |            19.6316 |      0.6626 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[134]\ttrain-rmse:0.704962+0.00212807\ttest-rmse:1.00089+0.0128469\n",
      "\n",
      "   28 | 01m31s |   -1.00089 |    9.6934 |             0.9151 |    0.1714 |      5.2191 |             1.2936 |      0.5884 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[166]\ttrain-rmse:0.739724+0.00315561\ttest-rmse:1.00318+0.011376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/gaussian_process/gpr.py:308: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 | 01m53s |   -1.00318 |    0.1988 |             0.7927 |    9.8255 |      5.9803 |            19.8340 |      0.8921 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[158]\ttrain-rmse:0.662274+0.00268775\ttest-rmse:0.992683+0.0107973\n",
      "\n",
      "   30 | 01m55s | \u001b[35m  -0.99268\u001b[0m | \u001b[32m   9.8891\u001b[0m | \u001b[32m            0.5972\u001b[0m | \u001b[32m   1.5452\u001b[0m | \u001b[32m     5.1422\u001b[0m | \u001b[32m           19.7022\u001b[0m | \u001b[32m     0.9671\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[166]\ttrain-rmse:0.621035+0.00438246\ttest-rmse:0.995326+0.011771\n",
      "\n",
      "   31 | 02m08s |   -0.99533 |    5.7284 |             0.9836 |    1.0074 |      5.0395 |            11.5383 |      0.9868 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[187]\ttrain-rmse:0.722418+0.00403151\ttest-rmse:1.00171+0.0103437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'nit': 4, 'grad': array([ -7.40149579e-05]), 'funcalls': 52, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH'}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 | 02m07s |   -1.00171 |    0.0247 |             0.2612 |    9.5660 |      5.2515 |             9.3262 |      0.9453 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[226]\ttrain-rmse:0.775181+0.00293267\ttest-rmse:0.999263+0.0150626\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'nit': 4, 'grad': array([ -7.26232652e-05]), 'funcalls': 52, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH'}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 | 02m37s |   -0.99926 |    8.6174 |             0.2617 |    9.3502 |      5.0804 |             1.0845 |      0.9703 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-8c3fea47c1d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgbBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;31m# Append most recently generated values to X and Y arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Updating the GP.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-5009a420071c>\u001b[0m in \u001b[0;36mxgb_evaluate\u001b[0;34m(min_child_weight, colsample_bytree, max_depth, subsample, gamma, alpha)\u001b[0m\n\u001b[1;32m     16\u001b[0m     cv_result = xgboost.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,\n\u001b[1;32m     17\u001b[0m              \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m              callbacks=[xgboost.callback.early_stop(5)])\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test-rmse-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    405\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 827\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    828\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.438568583885\n",
      "CPU times: user 3min 59s, sys: 480 ms, total: 3min 59s\n",
      "Wall time: 33.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf=ensemble.RandomForestClassifier(n_estimators=250,n_jobs=-1,random_state=42)\n",
    "rf_an=model_selection.cross_val_predict(rf,X_train_ww,np.array(y_train,dtype=\"int8\"),cv=5)\n",
    "print(metrics.f1_score(np.array(y_train,dtype=\"int8\"),lr_an,average=\"weighted\"))\n",
    "np.savetxt(\"./rf_for_stack_clf\",rf_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 700 ms, sys: 120 ms, total: 820 ms\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm=svm.SVR()\n",
    "sm_an=model_selection.cross_val_predict(sm,X_train_tf,y_train,cv=5,n_jobs=-1)\n",
    "np.savetxt(\"./sm_for_stack\",sm_an)\n",
    "metrics.mean_squared_error(y_train,sm_an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 12.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "        'learning_rate': 0.05,\n",
    "        'metric': 'mse',\n",
    "        \"min_data_in_leaf\":5\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldata=lightgbm.Dataset(X_train_tf,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83236803941598647"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg[\"l2-mean\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 48s, sys: 1.08 s, total: 10min 49s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg=lightgbm.cv(params,ldata,num_boost_round=10000,early_stopping_rounds=5,stratified=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 8s, sys: 3.16 s, total: 18min 11s\n",
      "Wall time: 4min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg1=lightgbm.cv(params,ldata,num_boost_round=10000,early_stopping_rounds=5,stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack=np.vstack((np.loadtxt(\"./db_ww_for_stack_clf\"),\n",
    "                np.loadtxt(\"./etr_tf_for_stack_clf\"),\n",
    "                np.loadtxt(\"./etr_ww_for_stack_clf\"),\n",
    "                np.loadtxt(\"./kn_tf_for_stack_clf\"),\n",
    "                np.loadtxt(\"./kn_ww_for_stack_clf\"),\n",
    "                np.loadtxt(\"./lin_clf_an_stack_clf\"),\n",
    "                np.loadtxt(\"./lin_clf_an_tf_stack_clf\"),\n",
    "                np.loadtxt(\"./lr_tf_for_stack_clf\"),\n",
    "                np.loadtxt(\"./lr_wv_for_stack_clf\"),\n",
    "                np.loadtxt(\"./rf_for_stack\"),\n",
    "                np.loadtxt(\"./rf_for_stack_clf\"),\n",
    "                np.loadtxt(\"./tr_tf_for_stack_clf\"),\n",
    "                np.loadtxt(\"./tr_ww_for_stack_clf\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 12469)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.07648219 -1.09787218 -1.11281419 -0.98331232 -1.01797048]\n"
     ]
    }
   ],
   "source": [
    "a=ensemble.RandomForestRegressor(n_estimators=1000,random_state=42,n_jobs=-1)\n",
    "print(model_selection.cross_val_score(a,stack.T,y=y_train,cv=5,scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 28s, sys: 2.58 s, total: 8min 31s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "        'learning_rate': 0.001,\n",
    "        'metric': 'mse',\n",
    "        \"min_data_in_leaf\":5,\n",
    "        \"num_leaves\":20\n",
    "    }\n",
    "ldata=lightgbm.Dataset(stack.T,label=y_train)\n",
    "lg=lightgbm.cv(params,ldata,num_boost_round=10000,early_stopping_rounds=5,stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lg_tuning(min_data,num_leafs,max_depth,min_sum_hessian_in_leaf,lambda_l1,lambda_l2):\n",
    "    params = {\n",
    "        'learning_rate': 0.1,\n",
    "        'metric': 'mse',\n",
    "        \"min_data_in_leaf\":int(round(min_data)),\n",
    "        \"num_leaves\":int(round(num_leafs)),\n",
    "        \"max_depth\":int(round(max_depth)),\n",
    "        \"min_sum_hessian_in_leaf\":np.float(\"1e{}\".format(int(round(min_sum_hessian_in_leaf)))),\n",
    "        \"lambda_l1\":lambda_l1,\n",
    "        \"lambda_l2\":lambda_l2\n",
    "        \n",
    "    }\n",
    "    lg=lightgbm.cv(params,ldata,num_boost_round=10000,early_stopping_rounds=5)\n",
    "    return -lg[\"l2-mean\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgBO = bayes_opt.BayesianOptimization(lg_tuning, {\"min_data\":(1,100),\n",
    "                                                 \"num_leafs\":(5,85),\n",
    "                                                \"max_depth\":(2,30),\n",
    "                                                \"min_sum_hessian_in_leaf\":(-6,5),\n",
    "                                                \"lambda_l1\":(0.001,30),\n",
    "                                                \"lambda_l2\":(0.001,30)\n",
    "        \n",
    "    })\n",
    "ldata=lightgbm.Dataset(stack_ww,label=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f55486bd70a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1e{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for o in range(-20,10,0.5):\n",
    "    print(np.float(\"1e{}\".format(o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-d92f25ed733c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-d92f25ed733c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1e4.5\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-390cc5365295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"l2-mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lg' is not defined"
     ]
    }
   ],
   "source": [
    "lg[\"l2-mean\"][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   lambda_l1 |   lambda_l2 |   max_depth |   min_data |   min_sum_hessian_in_leaf |   num_leafs | \n",
      "    1 | 00m19s | \u001b[35m  -0.89406\u001b[0m | \u001b[32m    21.4672\u001b[0m | \u001b[32m    15.9324\u001b[0m | \u001b[32m    13.5212\u001b[0m | \u001b[32m   93.1145\u001b[0m | \u001b[32m                  -1.9460\u001b[0m | \u001b[32m    31.2119\u001b[0m | \n",
      "    2 | 00m17s |   -0.91565 |      3.6592 |      0.3870 |      6.9836 |    43.3863 |                   -5.5979 |     59.1314 | \n",
      "    3 | 00m09s |   -0.92081 |     17.2925 |     18.2270 |     14.3236 |    71.6284 |                    2.5599 |     22.1258 | \n",
      "    4 | 00m23s |   -0.89979 |     17.8187 |     20.6539 |     10.3950 |    59.6476 |                   -4.8808 |     59.6822 | \n",
      "    5 | 00m17s |   -0.90268 |     11.8084 |     14.1218 |     10.2307 |    35.0372 |                   -4.2750 |      9.2450 | \n",
      "    6 | 00m28s |   -0.89946 |     28.4426 |      3.4913 |     26.6091 |    28.1361 |                   -2.5283 |     43.1698 | \n",
      "    7 | 00m23s |   -0.89607 |     27.8053 |     23.0370 |      4.7142 |    46.2210 |                   -3.8984 |     84.1460 | \n",
      "    8 | 00m19s |   -0.89868 |     28.3578 |     15.1085 |      7.0222 |    61.5509 |                    0.2180 |     12.5672 | \n",
      "    9 | 00m10s |   -0.90801 |      0.5099 |      7.5232 |      4.3375 |    93.2927 |                   -3.2367 |      6.5851 | \n",
      "   10 | 00m20s |   -0.92339 |     21.6542 |     24.5898 |      4.2898 |    59.9458 |                    3.3419 |     11.1944 | \n",
      "   11 | 00m25s |   -0.89901 |     21.7407 |     17.1533 |     24.4336 |    92.5711 |                   -3.1883 |     55.9725 | \n",
      "   12 | 00m27s |   -0.90093 |      9.5406 |     11.5359 |      4.5881 |    70.8138 |                    1.4502 |     53.4642 | \n",
      "   13 | 00m21s |   -0.90093 |     20.3170 |     17.6898 |     25.2014 |    65.0773 |                    0.3264 |     10.6185 | \n",
      "   14 | 00m20s |   -0.89473 |      7.7647 |     27.6565 |      5.5385 |    93.3633 |                   -0.6008 |     54.2577 | \n",
      "   15 | 00m29s |   -0.89411 |     10.9632 |     27.1131 |      4.6467 |     7.9110 |                   -3.9965 |     83.3330 | \n",
      "   16 | 00m19s |   -0.89831 |      4.2246 |     14.9685 |      5.2845 |    89.8628 |                    2.2919 |     20.5879 | \n",
      "   17 | 01m04s |   -0.90379 |     20.1997 |     25.9010 |     28.9452 |    13.8393 |                   -4.6653 |     79.7847 | \n",
      "   18 | 00m38s | \u001b[35m  -0.89283\u001b[0m | \u001b[32m    25.4213\u001b[0m | \u001b[32m    25.8819\u001b[0m | \u001b[32m    24.3964\u001b[0m | \u001b[32m   74.1748\u001b[0m | \u001b[32m                  -4.9796\u001b[0m | \u001b[32m    80.3434\u001b[0m | \n",
      "   19 | 00m31s |   -0.90297 |     12.8321 |     27.6714 |     13.0942 |    19.2669 |                   -2.3167 |     13.4437 | \n",
      "   20 | 00m28s |   -0.90760 |      0.2787 |      8.0222 |     17.9702 |    65.5473 |                   -3.5466 |     18.6608 | \n",
      "   21 | 00m39s |   -0.90032 |      6.9679 |     28.0120 |     10.8747 |    95.2653 |                   -1.8644 |     72.8130 | \n",
      "   22 | 00m25s |   -0.89452 |     19.7681 |     21.1722 |     11.7335 |    47.9566 |                   -4.6523 |     77.6450 | \n",
      "   23 | 00m00s |   -1.73119 |     21.1308 |     16.6836 |      9.0549 |    59.9787 |                    3.9588 |      6.6341 | \n",
      "   24 | 00m11s |   -0.90260 |      7.8012 |      2.1483 |      3.7607 |    55.2722 |                    0.5438 |     43.9706 | \n",
      "   25 | 00m00s |   -1.73119 |     16.3533 |     27.4637 |     10.5098 |    47.8837 |                    4.9347 |     36.2428 | \n",
      "   26 | 00m00s |   -1.73119 |     29.7032 |     13.6274 |     15.5775 |    95.6263 |                    4.8779 |     44.7797 | \n",
      "   27 | 00m06s |   -0.90263 |      4.9835 |      6.7431 |      3.8280 |    54.2618 |                   -5.0235 |     70.8309 | \n",
      "   28 | 00m16s |   -0.90359 |      2.2204 |      2.7148 |     23.7905 |    52.9995 |                   -2.5785 |     16.3003 | \n",
      "   29 | 00m24s |   -0.89442 |     14.6088 |      1.1411 |     26.6355 |    87.2231 |                   -1.8191 |     77.9864 | \n",
      "   30 | 00m00s |   -1.73119 |      6.6335 |     22.0330 |      3.3768 |    35.6085 |                    4.0962 |     29.2615 | \n",
      "   31 | 00m10s |   -0.92154 |      5.0475 |      5.7539 |      5.3329 |    31.0545 |                    2.8685 |     79.7363 | \n",
      "   32 | 00m21s |   -0.89347 |     14.6403 |     13.5509 |     13.7257 |    77.0061 |                   -3.7282 |     67.0726 | \n",
      "   33 | 00m00s |   -1.73119 |      5.1564 |      3.4320 |     29.0071 |    52.4837 |                    3.5214 |     41.2884 | \n",
      "   34 | 00m17s |   -0.91900 |     12.5237 |     10.4899 |      8.7895 |    66.2499 |                    2.9839 |     44.1559 | \n",
      "   35 | 00m19s |   -0.89867 |      5.1404 |      9.5462 |     15.9680 |    66.2694 |                   -3.1458 |     37.9535 | \n",
      "   36 | 00m28s |   -0.91273 |     27.5290 |     15.9929 |     16.3011 |     1.6834 |                   -3.5359 |     80.0879 | \n",
      "   37 | 00m20s |   -0.90464 |      5.4048 |      3.7454 |     26.2030 |    74.3144 |                   -5.4359 |     66.7593 | \n",
      "   38 | 00m17s |   -0.89635 |     13.1436 |     10.3821 |      5.3250 |    33.3540 |                   -1.8796 |     35.6338 | \n",
      "   39 | 00m10s |   -0.89733 |      1.0788 |      4.1470 |      6.5300 |    80.9618 |                    2.3231 |     14.3699 | \n",
      "   40 | 00m24s |   -0.89721 |      8.3795 |     16.0837 |     14.8297 |    89.1904 |                   -3.2990 |     83.8404 | \n",
      "   41 | 00m00s |   -1.73119 |     20.4002 |     20.5944 |      3.4611 |    85.9647 |                    4.7652 |     84.1095 | \n",
      "   42 | 00m00s |   -1.73119 |      6.9299 |      3.0887 |     18.2332 |    28.7039 |                    4.9100 |     14.4219 | \n",
      "   43 | 00m10s |   -0.90465 |     13.5976 |      7.7811 |      3.5146 |    13.0076 |                   -2.4338 |     20.0862 | \n",
      "   44 | 00m10s |   -0.92392 |      3.2193 |      8.0770 |     18.2059 |    42.5538 |                    3.1786 |     78.0995 | \n",
      "   45 | 00m16s |   -0.90307 |      9.5757 |     14.7708 |      8.6688 |     9.4732 |                    0.3494 |      8.9412 | \n",
      "   46 | 00m10s |   -0.92038 |     22.1223 |     14.2452 |     13.8909 |    47.5991 |                    2.7659 |     75.1245 | \n",
      "   47 | 00m16s |   -0.91874 |     10.5911 |      8.1105 |      7.2924 |    72.5346 |                    2.8707 |     40.3565 | \n",
      "   48 | 00m12s |   -0.89303 |      7.6453 |      6.4002 |     22.4185 |    81.2687 |                   -2.9723 |     23.4154 | \n",
      "   49 | 00m16s |   -0.90480 |      8.4766 |     26.7981 |     18.5764 |    31.8320 |                   -2.0490 |      6.7240 | \n",
      "   50 | 00m12s |   -0.92479 |     20.1773 |      1.1887 |     17.3215 |    73.3212 |                    2.5567 |     38.9201 | \n",
      "   51 | 00m00s |   -1.73119 |      8.9701 |     18.5888 |     26.3633 |    18.0717 |                    4.3241 |     78.0237 | \n",
      "   52 | 00m00s |   -1.73119 |      2.8986 |     11.8923 |      7.1618 |    71.5121 |                    4.7433 |     67.1525 | \n",
      "   53 | 00m00s |   -1.73119 |     12.4904 |     14.6760 |     11.4820 |    14.5001 |                    4.6803 |     20.6578 | \n",
      "   54 | 00m11s |   -0.90258 |     10.1903 |     27.0964 |      7.2534 |    45.0106 |                    1.9267 |      9.1544 | \n",
      "   55 | 00m26s |   -0.90860 |      4.9401 |      4.6423 |     22.3590 |    32.5793 |                   -4.2295 |     75.1381 | \n",
      "   56 | 00m21s |   -0.89295 |     26.0894 |     20.5348 |     17.1900 |    82.3652 |                    0.2411 |     16.4905 | \n",
      "   57 | 00m09s |   -0.90456 |     26.0608 |     23.9029 |      3.1100 |    58.3623 |                   -5.6884 |     73.7018 | \n",
      "   58 | 00m13s |   -0.90052 |     26.9346 |     11.7531 |     23.6141 |    99.9638 |                   -4.3504 |     25.2540 | \n",
      "   59 | 00m31s |   -0.90114 |      4.8396 |     23.4376 |     15.2944 |    44.1619 |                   -2.6888 |     77.4383 | \n",
      "   60 | 00m18s |   -0.89875 |      3.4280 |     13.0432 |      6.2438 |     7.9598 |                   -3.7483 |     24.6187 | \n",
      "   61 | 00m27s |   -0.89378 |     10.1468 |     23.5019 |     12.0548 |    55.4691 |                   -4.9480 |     79.8799 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   62 | 00m20s |   -0.89876 |      3.5568 |     26.4165 |      9.5929 |    89.9144 |                    2.0422 |     82.8769 | \n",
      "   63 | 00m00s |   -1.73119 |     21.3640 |     21.8855 |     29.1110 |    72.5869 |                    4.2495 |     23.7720 | \n",
      "   64 | 00m18s |   -0.91770 |     22.1390 |     18.7795 |      8.8741 |    15.9406 |                    3.0913 |     34.5630 | \n",
      "   65 | 00m19s |   -0.90261 |     11.6114 |      3.1869 |      6.8975 |    47.8515 |                   -1.2005 |     58.3319 | \n",
      "   66 | 00m00s |   -1.73119 |      8.4853 |      7.6211 |     14.5150 |    78.5856 |                    4.3446 |     63.8303 | \n",
      "   67 | 00m13s |   -0.89357 |     12.0256 |      3.7142 |     24.8644 |    89.7853 |                   -3.1136 |     59.0786 | \n",
      "   68 | 00m13s |   -0.92603 |      6.2405 |     28.5407 |     21.0009 |     1.2797 |                    3.0413 |     79.9322 | \n",
      "   69 | 00m24s |   -0.90593 |      1.6518 |     28.9359 |     10.7780 |    47.1449 |                   -2.8374 |     84.7509 | \n",
      "   70 | 00m00s |   -1.73119 |      9.2708 |     14.9523 |      5.5557 |     4.5681 |                    4.8048 |     74.3401 | \n",
      "   71 | 00m00s |   -1.73119 |      6.4756 |      2.2979 |      7.2921 |    78.8714 |                    4.0362 |     16.2163 | \n",
      "   72 | 00m31s |   -0.90434 |      9.2098 |     26.5968 |     17.4464 |    24.8337 |                    0.0875 |     83.6369 | \n",
      "   73 | 00m18s |   -0.89372 |      8.8431 |      8.7071 |      4.7892 |    10.2549 |                    2.2962 |     53.4268 | \n",
      "   74 | 00m23s |   -0.90005 |     15.6522 |     21.0884 |     29.0226 |    38.7746 |                    1.6138 |     78.6809 | \n",
      "   75 | 00m07s |   -0.90312 |     23.5268 |      1.0801 |      2.6380 |    17.9596 |                   -1.6300 |     40.0384 | \n",
      "   76 | 00m19s |   -0.89760 |     20.1185 |      1.1316 |     15.1144 |    46.3453 |                   -2.9489 |     39.3540 | \n",
      "   77 | 00m10s |   -0.92050 |      9.5224 |     10.3049 |     27.0756 |    70.4531 |                    2.8803 |     46.9568 | \n",
      "   78 | 00m21s |   -0.89574 |      6.9502 |     19.7089 |      8.7925 |    57.5240 |                   -0.8129 |     58.7702 | \n",
      "   79 | 00m00s |   -1.73119 |     10.0312 |      1.9544 |      5.0387 |    18.9321 |                    4.2990 |     18.4248 | \n",
      "   80 | 00m20s |   -0.89577 |     21.6305 |      7.5952 |     17.0484 |    67.2759 |                   -1.7185 |     32.1677 | \n",
      "   81 | 00m28s |   -0.89607 |     10.9797 |     27.3878 |     11.7042 |    65.0032 |                   -1.2791 |     62.9025 | \n",
      "   82 | 00m14s |   -0.90343 |     17.6288 |     27.9240 |      4.1041 |    26.5120 |                   -3.4793 |      6.3309 | \n",
      "   83 | 00m06s |   -0.90493 |      0.9925 |     17.7784 |      4.2261 |    35.9180 |                   -5.0007 |     58.9866 | \n",
      "   84 | 00m14s |   -0.90328 |     22.2975 |     19.9187 |      3.8306 |    94.3692 |                   -1.9612 |     71.6649 | \n",
      "   85 | 00m22s |   -0.91686 |      2.2517 |      0.7800 |     29.2461 |    58.5010 |                   -0.1162 |     83.9573 | \n",
      "   86 | 00m34s |   -0.89911 |     13.2025 |     20.2436 |     11.2584 |     5.5108 |                   -2.2378 |     64.5905 | \n",
      "   87 | 00m00s |   -1.73119 |     20.9370 |     10.0126 |      8.0639 |    22.7115 |                    3.6540 |     13.4456 | \n",
      "   88 | 00m32s |   -0.90826 |     24.0927 |      2.5309 |     27.5634 |     5.2215 |                   -5.3035 |     64.6810 | \n",
      "   89 | 00m14s |   -0.90943 |      4.2645 |      2.6184 |     28.4316 |    32.5159 |                   -2.7719 |     33.3120 | \n",
      "   90 | 00m18s |   -0.89715 |      8.0978 |     14.7077 |      5.1475 |    27.6693 |                   -5.0346 |     57.0847 | \n",
      "   91 | 00m33s |   -0.91160 |      0.8625 |     13.7376 |     14.1597 |    14.6319 |                   -5.5843 |     77.7422 | \n",
      "   92 | 00m20s |   -0.89539 |     25.0823 |     19.5801 |     29.0975 |    35.7164 |                    2.2228 |     36.1456 | \n",
      "   93 | 00m13s |   -0.90374 |      7.2204 |     15.2012 |      3.8143 |     2.1241 |                    1.6117 |     30.7013 | \n",
      "   94 | 00m21s |   -0.90490 |      2.8857 |     28.6803 |     25.3374 |    92.2957 |                   -2.2136 |     60.3272 | \n",
      "   95 | 00m26s |   -0.89538 |     29.0554 |     21.7102 |      5.8912 |    20.9391 |                    0.2647 |     26.0589 | \n",
      "   96 | 00m07s |   -0.90592 |     28.1146 |     17.3285 |      3.6640 |    21.0542 |                    1.8582 |     50.2248 | \n",
      "   97 | 00m11s |   -0.90193 |     18.9128 |     15.6738 |      3.2100 |    74.7307 |                   -0.7936 |     54.1821 | \n",
      "   98 | 00m12s |   -0.90188 |      2.4045 |     19.2818 |      9.8953 |    60.5660 |                   -3.4358 |     19.4417 | \n",
      "   99 | 00m16s |   -0.91693 |     24.5846 |      9.0878 |     23.5563 |    98.5327 |                    2.7979 |     49.6386 | \n",
      "  100 | 00m16s |   -0.89846 |      7.5843 |      2.2303 |     19.1911 |    41.9689 |                   -2.5341 |     40.1866 | \n",
      "  101 | 00m00s |   -1.73119 |     19.7189 |     27.8350 |     27.7824 |    46.0264 |                    4.8840 |     35.5594 | \n",
      "  102 | 00m12s |   -0.92525 |      2.2670 |     19.0221 |     21.0604 |    93.7263 |                    3.3383 |     28.9701 | \n",
      "  103 | 00m24s |   -0.89797 |     22.4183 |     26.3035 |     27.5287 |    22.0359 |                   -0.5604 |     61.9415 | \n",
      "  104 | 00m19s |   -0.89898 |     12.7955 |     26.5144 |     23.8780 |    38.4086 |                    2.1609 |     42.8404 | \n",
      "  105 | 00m11s |   -0.90076 |     26.0161 |     21.4508 |     18.6535 |    54.7265 |                   -0.9351 |     56.3242 | \n",
      "  106 | 00m35s |   -0.90849 |      8.6436 |      8.8448 |     25.3158 |     5.8688 |                   -4.8514 |     79.1828 | \n",
      "  107 | 00m00s |   -1.73119 |     14.0184 |      3.4853 |     18.7646 |    13.3356 |                    4.1448 |     30.5087 | \n",
      "  108 | 00m24s |   -0.89567 |     12.7062 |      1.9950 |      8.0036 |     4.1992 |                   -4.8990 |     39.7643 | \n",
      "  109 | 00m33s |   -0.90363 |     19.4346 |      9.0589 |     11.2823 |     4.5101 |                   -4.6895 |     70.3248 | \n",
      "  110 | 00m19s |   -0.89961 |      2.4921 |     28.3622 |      9.5402 |    82.5360 |                    2.1201 |     36.6839 | \n",
      "  111 | 00m16s |   -0.90563 |      4.5771 |     21.0360 |      6.0445 |    39.7057 |                   -5.8403 |     59.5072 | \n",
      "  112 | 00m09s |   -0.90439 |     23.4355 |     12.8631 |     22.9624 |    16.7319 |                   -5.2440 |     26.1982 | \n",
      "  113 | 00m18s |   -0.89679 |     12.2716 |     28.8359 |     21.7771 |    24.6553 |                    0.6803 |     12.1314 | \n",
      "  114 | 00m16s |   -0.89687 |      4.4272 |     27.5753 |     15.9223 |    45.6695 |                    2.2785 |     27.7613 | \n",
      "  115 | 00m13s | \u001b[35m  -0.89280\u001b[0m | \u001b[32m    24.4009\u001b[0m | \u001b[32m     3.4569\u001b[0m | \u001b[32m    29.2765\u001b[0m | \u001b[32m   58.8355\u001b[0m | \u001b[32m                  -2.8425\u001b[0m | \u001b[32m    23.9276\u001b[0m | \n",
      "  116 | 00m14s |   -0.90092 |      8.4723 |     26.0924 |      4.7225 |    81.7893 |                    2.0771 |     36.1293 | \n",
      "  117 | 00m09s |   -0.90319 |      7.8943 |     13.5986 |     28.8398 |    93.4668 |                    2.0612 |     40.8711 | \n",
      "  118 | 00m13s |   -0.90362 |      9.4631 |     15.8829 |      4.2854 |    55.3215 |                   -4.7254 |      9.2556 | \n",
      "  119 | 00m20s |   -0.89419 |     15.2755 |     19.8662 |     15.1935 |    29.8666 |                   -5.6693 |     15.3958 | \n",
      "  120 | 00m10s |   -0.89442 |     29.6917 |     19.9127 |      9.3552 |    97.1912 |                   -2.7556 |     33.6924 | \n",
      "  121 | 00m16s |   -0.90283 |     13.4111 |     19.5002 |      7.6746 |    82.4912 |                    1.9805 |     36.5507 | \n",
      "  122 | 00m25s |   -0.89583 |     19.3275 |      6.9129 |     23.9161 |    45.9986 |                   -0.7147 |     82.9608 | \n",
      "  123 | 00m21s |   -0.90066 |     14.4926 |      5.2476 |     24.1283 |    72.4453 |                   -2.7155 |     73.7993 | \n",
      "  124 | 00m15s |   -0.89785 |     22.6731 |     17.0218 |     21.2129 |    85.8028 |                    1.8164 |     82.7649 | \n",
      "  125 | 00m15s |   -0.89844 |      8.7529 |     20.8987 |     29.1600 |    18.6438 |                   -4.4528 |     17.3960 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  126 | 00m00s |   -1.73119 |     15.8160 |      3.3599 |     23.8557 |    57.6614 |                    3.5990 |     35.2160 | \n",
      "  127 | 00m19s |   -0.89993 |      7.7017 |     13.1010 |      5.1097 |    50.8203 |                    0.3792 |     83.1096 | \n",
      "  128 | 00m25s |   -0.89700 |      6.6212 |      8.5509 |     19.1187 |    87.6510 |                   -1.8829 |     26.9412 | \n",
      "  129 | 00m32s |   -0.89978 |      7.8092 |     27.2557 |      7.7945 |     7.6969 |                    1.4280 |     66.6028 | \n",
      "  130 | 00m18s |   -0.90472 |     18.2221 |      0.1306 |      6.2932 |    29.1154 |                    0.7517 |     66.9785 | \n",
      "  131 | 00m05s |   -0.90503 |     14.3398 |     18.9201 |      4.0290 |    85.9209 |                   -4.7015 |     18.2165 | \n",
      "  132 | 00m22s |   -0.90176 |     17.8895 |     12.3418 |     13.0406 |    26.1509 |                   -2.1155 |     82.2803 | \n",
      "  133 | 00m14s |   -0.92260 |     14.6577 |     17.2321 |     21.5667 |    47.5793 |                    2.5088 |     38.1039 | \n",
      "  134 | 00m19s |   -0.89356 |     17.2443 |      6.0687 |      6.0907 |    40.0397 |                   -3.5063 |     62.1753 | \n",
      "  135 | 00m12s |   -0.89894 |     28.2399 |     19.8728 |     20.4888 |    12.7313 |                   -5.3301 |     22.9809 | \n",
      "  136 | 00m15s |   -0.89721 |     20.8851 |     26.9933 |     28.4213 |    84.7840 |                   -3.6814 |     24.9558 | \n",
      "  137 | 00m16s |   -0.89890 |     15.3588 |     29.0056 |     16.9675 |     4.4854 |                    2.2182 |     80.9557 | \n",
      "  138 | 00m11s |   -0.90055 |     15.3113 |      7.4780 |     11.3696 |    63.1904 |                   -1.6357 |     28.7779 | \n",
      "  139 | 00m15s |   -0.89621 |     22.1122 |     15.6860 |     18.4325 |    89.9820 |                   -5.2513 |     11.0491 | \n",
      "  140 | 00m00s |   -1.73119 |     11.6592 |     16.9268 |     29.1471 |    53.9818 |                    4.4700 |     68.4202 | \n",
      "  141 | 00m17s |   -0.89934 |     11.1413 |     12.4588 |      9.9752 |    73.4602 |                    0.0527 |     51.8154 | \n",
      "  142 | 00m18s |   -0.90353 |      5.5974 |     13.1326 |     27.6682 |    39.9694 |                   -1.9569 |     50.9244 | \n",
      "  143 | 00m13s |   -0.90709 |      0.8769 |      2.9414 |      5.2851 |    52.5154 |                   -3.6644 |     42.4379 | \n",
      "  144 | 00m08s |   -0.89957 |     28.1326 |      3.6672 |     26.4849 |    78.8884 |                   -0.5508 |      9.8201 | \n",
      "  145 | 00m19s |   -0.89856 |     21.6428 |      4.9380 |     13.0664 |    50.6480 |                    0.5093 |     51.5853 | \n",
      "  146 | 00m18s |   -0.89605 |     12.5275 |     26.1753 |     26.6319 |    70.6965 |                   -4.4383 |     34.6909 | \n",
      "  147 | 00m24s | \u001b[35m  -0.89258\u001b[0m | \u001b[32m    25.0565\u001b[0m | \u001b[32m    25.6814\u001b[0m | \u001b[32m    24.1069\u001b[0m | \u001b[32m   83.8793\u001b[0m | \u001b[32m                   1.5861\u001b[0m | \u001b[32m    50.7808\u001b[0m | \n",
      "  148 | 00m27s |   -0.89316 |      7.0697 |     16.4140 |     26.6453 |     4.2451 |                   -3.9276 |     38.7428 | \n",
      "  149 | 00m22s |   -0.90182 |     18.8511 |     20.2130 |     13.5696 |    37.4072 |                   -5.8688 |     62.5354 | \n",
      "  150 | 00m30s | \u001b[35m  -0.89082\u001b[0m | \u001b[32m    17.5881\u001b[0m | \u001b[32m    21.1738\u001b[0m | \u001b[32m    29.6100\u001b[0m | \u001b[32m   51.4148\u001b[0m | \u001b[32m                  -5.2335\u001b[0m | \u001b[32m    41.2563\u001b[0m | \n",
      "  151 | 00m00s |   -1.73119 |     19.4428 |     18.4157 |     23.7656 |    33.7833 |                    4.2360 |     35.4334 | \n",
      "  152 | 01m02s |   -0.89748 |      8.6184 |     25.4046 |     13.5996 |    52.5529 |                   -3.3591 |     17.1393 | \n",
      "  153 | 00m30s |   -0.89894 |     29.7863 |     23.7518 |     20.0505 |    33.3757 |                   -3.1985 |     47.1522 | \n",
      "  154 | 00m00s |   -1.73119 |     14.1020 |     25.8799 |      8.3935 |    92.3176 |                    4.4540 |     46.8831 | \n",
      "  155 | 00m45s |   -0.89998 |      9.8419 |     16.5823 |     11.1161 |    25.6209 |                    0.6659 |     41.2621 | \n",
      "  156 | 00m38s |   -0.90115 |      8.0197 |     20.7059 |     11.7253 |    10.4294 |                    0.4412 |     28.3495 | \n",
      "  157 | 00m18s |   -0.92400 |     14.8183 |     16.5537 |      7.5343 |    43.1178 |                    2.6338 |     42.7443 | \n",
      "  158 | 00m59s |   -0.89929 |      8.5253 |      0.1715 |     21.6371 |    81.5945 |                   -3.6567 |     69.7712 | \n",
      "  159 | 00m30s |   -0.89885 |     28.1764 |     16.0629 |     26.5286 |     8.4547 |                    1.6397 |     65.2183 | \n",
      "  160 | 00m18s |   -0.92262 |     27.7629 |      0.3224 |      9.5361 |    27.3838 |                    2.7657 |     67.9273 | \n",
      "  161 | 00m26s |   -0.90133 |     19.5982 |      2.0552 |      4.3755 |    68.4184 |                   -3.1897 |     59.3610 | \n",
      "  162 | 00m24s |   -0.91907 |     10.8460 |     29.9581 |     17.8508 |    43.3841 |                    2.8569 |     13.1099 | \n",
      "  163 | 00m00s |   -1.73119 |     11.2666 |     14.9773 |      4.7461 |    69.1501 |                    4.3177 |     35.1886 | \n",
      "  164 | 00m22s |   -0.89962 |     28.3522 |     29.7633 |      6.3005 |    85.3222 |                    0.1313 |      9.2499 | \n",
      "  165 | 00m00s |   -1.73119 |      4.5056 |     27.0461 |     10.4502 |    42.7331 |                    3.7883 |     81.9833 | \n",
      "  166 | 00m37s |   -0.92267 |      2.7902 |     20.4300 |     12.6558 |     2.1871 |                    3.1085 |     25.8023 | \n",
      "  167 | 00m00s |   -1.73119 |     10.8457 |     16.0408 |     17.5946 |    41.5572 |                    4.3506 |     41.6107 | \n",
      "  168 | 00m13s |   -0.90629 |      1.4211 |     25.5659 |     23.1120 |    98.9252 |                    2.3269 |     10.0677 | \n",
      "  169 | 00m26s |   -0.91181 |      1.3863 |      1.6732 |     15.0518 |    14.3295 |                   -4.0083 |     23.1300 | \n",
      "  170 | 00m29s |   -0.92581 |     23.0594 |     21.5001 |      5.2449 |    45.2236 |                    2.7607 |     44.5114 | \n",
      "  171 | 00m27s |   -0.89835 |      7.7109 |      6.8828 |     14.3013 |    77.5540 |                   -5.4824 |     41.2536 | \n",
      "  172 | 00m35s |   -0.90120 |      3.0407 |     13.8273 |     21.3278 |    21.3875 |                   -0.7213 |     37.0023 | \n",
      "  173 | 00m32s |   -0.90047 |     16.5872 |     12.8427 |     19.2415 |    33.0433 |                   -4.4221 |     61.8362 | \n",
      "  174 | 00m00s |   -1.73119 |     15.9033 |      6.3167 |     13.4888 |    54.0421 |                    3.8244 |     73.6138 | \n",
      "  175 | 00m22s |   -0.89738 |     23.6531 |      0.9108 |     17.6617 |    62.4935 |                   -0.8459 |     15.6413 | \n",
      "  176 | 00m29s |   -0.89383 |     27.1531 |     12.8710 |     15.4225 |    96.8172 |                   -5.0257 |     70.6311 | \n",
      "  177 | 00m48s |   -0.89468 |     24.4054 |     24.5367 |     13.8699 |    83.6281 |                   -5.7129 |     78.4763 | \n",
      "  178 | 00m43s |   -0.90342 |      1.6524 |     25.1947 |     25.3994 |    32.3375 |                   -3.5082 |     58.1166 | \n",
      "  179 | 00m49s |   -0.89304 |     22.9356 |     27.4420 |      9.5910 |    78.1709 |                   -4.8936 |     32.0127 | \n",
      "  180 | 00m46s |   -0.90151 |     17.4601 |      0.1232 |     27.9749 |    16.9238 |                   -5.7759 |     49.6627 | \n",
      "  181 | 00m37s |   -0.89890 |      6.7652 |     23.3504 |     25.9526 |    34.7946 |                   -3.7742 |     27.6144 | \n",
      "  182 | 00m57s |   -0.89517 |     10.3731 |     11.6990 |     11.5250 |    60.2750 |                   -1.8057 |     44.9852 | \n",
      "  183 | 00m36s |   -0.89551 |      8.9175 |      8.1353 |     23.3592 |    51.0745 |                   -4.3863 |     23.1444 | \n",
      "  184 | 00m28s |   -0.90018 |     22.8013 |     12.4927 |     28.7821 |    46.5582 |                   -2.0198 |     61.8129 | \n",
      "  185 | 00m25s |   -0.89850 |     20.5514 |      0.5699 |     17.2319 |    20.3548 |                   -2.1376 |     26.1200 | \n",
      "  186 | 00m21s |   -0.89833 |     12.0386 |     26.4762 |      3.8722 |    98.3220 |                   -5.7118 |     81.9069 | \n",
      "  187 | 00m20s |   -0.90170 |     16.8576 |     21.5245 |      4.0094 |    53.7937 |                    0.1009 |     84.0903 | \n",
      "  188 | 00m21s |   -0.90146 |     18.6416 |      6.6876 |     29.8562 |    46.0017 |                   -2.8490 |     21.4308 | \n",
      "  189 | 00m44s |   -0.89578 |      9.8070 |     14.2149 |     22.1268 |    61.4893 |                   -2.7215 |     83.5949 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  190 | 00m29s |   -0.90590 |      9.3921 |      0.8072 |     25.9592 |    65.6827 |                   -3.2775 |     56.1159 | \n",
      "  191 | 00m25s |   -0.89945 |      2.1994 |     15.0785 |      5.6086 |     8.7030 |                    2.2857 |     25.3072 | \n",
      "  192 | 00m27s |   -0.89613 |     24.5898 |     18.5531 |     19.7523 |    39.6525 |                    1.9899 |     40.9438 | \n",
      "  193 | 00m26s |   -0.90189 |      7.7434 |      0.9770 |      7.9555 |    31.8918 |                   -0.4069 |     38.1393 | \n",
      "  194 | 00m17s |   -0.92023 |     10.2660 |      0.6271 |     28.7569 |    58.4600 |                    3.4262 |     47.3472 | \n",
      "  195 | 00m24s |   -0.89515 |     15.6268 |     28.5676 |     23.9322 |     4.7360 |                    1.5203 |     43.6618 | \n",
      "  196 | 00m44s |   -0.89832 |      4.6575 |     13.3811 |     20.3602 |    73.5267 |                    1.1505 |     54.1908 | \n",
      "  197 | 00m14s |   -0.90200 |      7.6363 |     26.0419 |     28.5026 |    66.1613 |                   -1.7928 |     13.2221 | \n",
      "  198 | 00m17s |   -0.89998 |     26.7713 |      5.9128 |      3.9551 |    87.0776 |                    2.3547 |     15.1345 | \n",
      "  199 | 00m24s |   -0.92009 |     18.4154 |     27.6833 |     29.9373 |    26.1363 |                    3.1319 |     10.6874 | \n",
      "  200 | 00m23s |   -0.90329 |      6.9534 |      0.3503 |     28.2175 |    22.7445 |                    1.4866 |     27.4893 | \n",
      "  201 | 00m21s |   -0.89387 |     17.9877 |     11.1692 |      6.0388 |    53.6927 |                   -4.6184 |     58.7570 | \n",
      "  202 | 00m19s |   -0.91321 |     14.3241 |     19.8821 |      2.2704 |     2.1298 |                   -1.6814 |     81.0109 | \n",
      "  203 | 00m29s |   -0.90325 |     16.2847 |      4.8857 |     12.4708 |     3.4493 |                   -2.8844 |     51.7903 | \n",
      "  204 | 00m31s |   -0.90028 |      8.6635 |     16.4610 |     16.7102 |    55.4062 |                   -4.1275 |     41.5826 | \n",
      "  205 | 00m26s |   -0.89942 |      6.4261 |      9.8129 |     11.7988 |    54.2387 |                   -1.0900 |     37.5849 | \n",
      "  206 | 00m14s |   -0.90108 |     29.4451 |     19.9953 |      3.5277 |     8.3019 |                    1.3458 |     31.2691 | \n",
      "  207 | 00m30s |   -0.90092 |      5.4684 |     15.2497 |     10.8875 |    64.1722 |                   -1.3115 |     44.9961 | \n",
      "  208 | 00m21s |   -0.89581 |     11.5896 |     22.0320 |     16.1859 |    57.3951 |                   -3.4624 |     12.6367 | \n",
      "  209 | 00m22s |   -0.89990 |      1.6941 |     13.9062 |     24.2878 |    91.6056 |                    0.4807 |     35.1701 | \n",
      "  210 | 00m20s |   -0.89678 |     13.7949 |     13.5145 |     24.1409 |    24.4527 |                    1.6669 |     33.8479 | \n",
      "  211 | 01m46s |   -0.89500 |     27.1610 |     27.5779 |     22.7071 |    56.1464 |                   -1.4981 |     77.2549 | \n",
      "  212 | 01m15s |   -0.90117 |      6.4913 |      8.4807 |     20.8946 |    22.0050 |                   -0.0356 |     53.5277 | \n",
      "  213 | 02m01s |   -0.90694 |      4.4065 |      7.2721 |     26.7698 |    10.7752 |                   -4.4418 |     71.2140 | \n",
      "  214 | 01m12s |   -0.90056 |     28.6961 |      2.3367 |     22.2684 |     2.5410 |                   -1.0747 |     31.8251 | \n",
      "  215 | 00m29s |   -0.89967 |     18.3490 |      3.4102 |      9.4289 |    40.0009 |                   -2.1073 |     53.3802 | \n",
      "  216 | 00m18s |   -0.90009 |     12.8712 |     16.8250 |      4.6118 |    85.7702 |                   -2.0986 |     51.0160 | \n",
      "  217 | 00m26s |   -0.89917 |     12.7803 |      0.6090 |      9.7124 |    69.5296 |                   -1.9071 |     25.1037 | \n",
      "  218 | 00m48s |   -0.89515 |     23.0541 |     14.3634 |     26.4718 |    70.0081 |                   -5.5800 |     65.9876 | \n",
      "  219 | 01m12s |   -0.90265 |     16.0013 |      9.9880 |     14.0427 |     5.0873 |                    0.6386 |     41.7423 | \n",
      "  220 | 00m30s |   -0.89601 |     24.2296 |     18.3339 |     14.8161 |    90.6753 |                   -0.4329 |     57.5520 | \n",
      "  221 | 00m30s |   -0.89517 |      9.0446 |     14.2169 |     16.3492 |    57.9753 |                   -1.6705 |     29.7075 | \n",
      "  222 | 00m38s |   -0.89822 |      1.0883 |     18.5259 |      9.4994 |    91.9930 |                   -1.1083 |     59.8123 | \n",
      "  223 | 00m10s |   -0.90399 |     16.8535 |      6.2858 |     13.2340 |    63.2113 |                    0.4103 |     14.9972 | \n",
      "  224 | 00m24s |   -0.90334 |      1.9740 |      5.1978 |     20.0369 |    94.1518 |                   -2.7292 |     36.5689 | \n",
      "  225 | 00m19s |   -0.91978 |     23.6947 |      5.1337 |     11.7115 |    23.5011 |                    3.0040 |     46.0167 | \n",
      "  226 | 00m19s |   -0.89787 |     10.7703 |     24.6532 |      5.3193 |    78.8334 |                    0.4549 |     37.4586 | \n",
      "  227 | 00m24s |   -0.89753 |      8.3561 |      8.4581 |     28.9657 |    83.9645 |                   -3.1301 |     30.0903 | \n",
      "  228 | 00m23s |   -0.91901 |     11.6145 |      1.6766 |     23.0789 |    93.7203 |                    3.0130 |     69.2960 | \n",
      "  229 | 00m49s |   -0.89414 |     29.3191 |      7.6336 |     13.3483 |    88.3058 |                    2.0199 |     53.3413 | \n",
      "  230 | 00m42s |   -0.92094 |      0.0345 |     26.0819 |     19.5955 |    33.6477 |                    3.4477 |     22.7620 | \n",
      "  231 | 00m19s |   -0.90150 |     13.9278 |     20.5652 |      8.1089 |    69.9354 |                   -3.9762 |     12.0648 | \n",
      "  232 | 00m34s | \u001b[35m  -0.89024\u001b[0m | \u001b[32m    13.0263\u001b[0m | \u001b[32m    26.6062\u001b[0m | \u001b[32m    10.9383\u001b[0m | \u001b[32m   78.7818\u001b[0m | \u001b[32m                  -1.1079\u001b[0m | \u001b[32m    50.1203\u001b[0m | \n",
      "  233 | 00m00s |   -1.73119 |     14.2485 |     21.3958 |     10.2664 |    58.0666 |                    4.1485 |     25.0979 | \n",
      "  234 | 00m46s |   -0.89403 |     13.0947 |     28.8759 |     16.2603 |    68.1442 |                   -5.9151 |     79.8729 | \n",
      "  235 | 00m07s |   -0.92834 |      7.2427 |     15.9509 |      4.4317 |    40.1855 |                    2.5771 |     35.1086 | \n",
      "  236 | 00m19s |   -0.90420 |     11.8932 |      8.0020 |      5.3011 |    27.4063 |                   -5.2214 |     48.8491 | \n",
      "  237 | 00m18s |   -0.91317 |      8.7946 |     17.2860 |      2.0055 |    70.5190 |                   -3.0293 |     64.0824 | \n",
      "  238 | 00m49s |   -0.90079 |     13.3726 |      8.0951 |     10.4173 |    46.0862 |                    0.1088 |     60.5565 | \n",
      "  239 | 00m28s |   -0.92029 |     28.8223 |      9.8154 |     12.3501 |    12.7827 |                    2.8834 |     12.3192 | \n",
      "  240 | 00m15s |   -0.91306 |     15.2102 |      2.4466 |      6.6357 |    89.1400 |                   -2.6462 |      5.5584 | \n",
      "  241 | 00m12s |   -0.91137 |      0.8654 |      8.4316 |      3.1485 |    70.8515 |                    1.0577 |     80.4373 | \n",
      "  242 | 00m38s |   -0.89703 |      5.0613 |     17.5141 |     16.2528 |    19.1552 |                    2.4697 |     64.7966 | \n",
      "  243 | 00m52s |   -0.89168 |      7.9787 |     22.8945 |      8.9236 |    20.6155 |                   -2.4649 |     43.5918 | \n",
      "  244 | 00m43s |   -0.89460 |     29.5859 |     22.4549 |     16.0577 |    55.0227 |                   -2.6563 |     74.4420 | \n",
      "  245 | 00m27s |   -0.89382 |     28.8220 |      2.8070 |     19.2100 |    51.2139 |                   -4.4220 |     16.7821 | \n",
      "  246 | 00m26s |   -0.91870 |     24.1456 |     29.7350 |      3.7447 |    48.4350 |                    3.0396 |     66.5617 | \n",
      "  247 | 00m47s | \u001b[35m  -0.88894\u001b[0m | \u001b[32m    26.2411\u001b[0m | \u001b[32m    20.2778\u001b[0m | \u001b[32m    18.2361\u001b[0m | \u001b[32m   61.9828\u001b[0m | \u001b[32m                  -0.3046\u001b[0m | \u001b[32m    61.8345\u001b[0m | \n",
      "  248 | 00m31s |   -0.89796 |     17.6482 |     14.7228 |      9.4889 |    35.2382 |                   -5.3135 |     69.2473 | \n",
      "  249 | 00m18s |   -0.89432 |     14.5045 |      6.8559 |     18.2886 |    93.5260 |                   -5.6680 |     18.5127 | \n",
      "  250 | 00m20s |   -0.89048 |     27.1369 |     29.1343 |     20.4231 |    74.5720 |                    0.6170 |     81.0106 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   lambda_l1 |   lambda_l2 |   max_depth |   min_data |   min_sum_hessian_in_leaf |   num_leafs | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  251 | 04m47s |   -0.91480 |     30.0000 |      0.0010 |      2.0000 |     1.0000 |                   -6.0000 |      5.0000 | \n",
      "  252 | 02m28s |   -0.91030 |     30.0000 |     30.0000 |     30.0000 |     1.0000 |                   -6.0000 |      5.0000 | \n",
      "  253 | 02m42s |   -0.89435 |     14.3370 |     23.6833 |      5.6380 |    63.3684 |                   -0.8024 |     83.6456 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  254 | 02m37s |   -0.90064 |     10.7114 |      4.8727 |      2.9043 |    11.3299 |                   -1.7627 |     61.5347 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  255 | 02m29s |   -0.92767 |     11.5609 |     19.7784 |     11.9099 |    59.8009 |                    2.5312 |     19.2557 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  256 | 02m54s |   -0.89102 |     21.5906 |     22.2438 |      8.2311 |    89.7691 |                   -0.1346 |     81.4454 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  257 | 03m00s |   -0.89502 |     21.8316 |     12.4177 |     16.7637 |    73.3592 |                   -3.9283 |     73.5406 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  258 | 02m42s |   -0.89870 |     14.2677 |      6.0369 |     24.3399 |    29.2795 |                   -1.1072 |     42.0619 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  259 | 02m39s |   -0.89844 |     14.8960 |     28.4857 |     24.0409 |     4.1213 |                   -3.4045 |     23.2647 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  260 | 02m36s |   -0.92187 |      5.2042 |     17.6729 |     16.0488 |    82.2756 |                    3.4162 |     31.0135 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  261 | 02m29s |   -1.73119 |     27.4238 |     19.6661 |     22.6509 |    13.8470 |                    3.8977 |     56.9936 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  262 | 02m42s |   -0.89886 |      4.8239 |     18.1700 |      3.7867 |     3.1389 |                   -5.9831 |     69.4837 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  263 | 02m44s |   -0.90359 |     10.6945 |      8.5868 |     22.9474 |    97.6745 |                   -1.6303 |     28.2319 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  264 | 02m52s |   -0.90261 |      9.4456 |      3.3217 |     13.1829 |    14.3098 |                   -2.3431 |     77.5218 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  265 | 03m04s |   -0.89936 |      7.6284 |     29.3929 |     15.9641 |     9.5089 |                   -4.2270 |     68.2527 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  266 | 02m35s |   -0.91746 |      0.0010 |     30.0000 |      2.0000 |     1.0000 |                   -6.0000 |      5.0000 | \n",
      "  267 | 02m35s |   -0.92247 |      0.0010 |      0.0010 |     30.0000 |     1.0000 |                   -6.0000 |      5.0000 | \n",
      "  268 | 02m39s |   -1.73119 |     30.0000 |     30.0000 |     30.0000 |   100.0000 |                    5.0000 |     85.0000 | \n",
      "  269 | 02m46s |   -0.92167 |      0.0010 |      0.0010 |      2.0000 |   100.0000 |                   -6.0000 |     85.0000 | \n",
      "  270 | 03m05s |   -0.91660 |     30.0000 |      0.0010 |      2.0000 |   100.0000 |                   -6.0000 |      5.0000 | \n",
      "  271 | 02m56s |   -0.91528 |      0.0010 |      0.0010 |     30.0000 |   100.0000 |                   -6.0000 |      5.0000 | \n",
      "  272 | 03m22s |   -0.90991 |     30.0000 |      0.0010 |     30.0000 |    21.4312 |                   -6.0000 |      5.0000 | \n",
      "  273 | 02m59s |   -0.91480 |     30.0000 |      0.0010 |      2.0000 |     1.0000 |                   -6.0000 |     85.0000 | \n",
      "  274 | 02m56s |   -0.92181 |     30.0000 |     30.0000 |      2.0000 |     1.0000 |                   -6.0000 |     85.0000 | \n",
      "  275 | 02m59s |   -0.92181 |     30.0000 |     30.0000 |      2.0000 |     1.0000 |                   -6.0000 |      5.0000 | \n",
      "  276 | 03m09s |   -0.91378 |     30.0000 |      0.0010 |      2.0000 |    76.1770 |                   -6.0000 |     34.7977 | \n",
      "  277 | 03m13s |   -0.91200 |      0.0010 |      0.0010 |     30.0000 |   100.0000 |                   -6.0000 |     85.0000 | \n",
      "  278 | 03m00s |   -0.90892 |     30.0000 |     30.0000 |     30.0000 |   100.0000 |                   -6.0000 |      5.0000 | \n",
      "  279 | 03m05s |   -0.91680 |     30.0000 |     30.0000 |      2.0000 |    50.5650 |                   -6.0000 |      5.0000 | \n",
      "  280 | 03m16s |   -0.89477 |     30.0000 |     30.0000 |     30.0000 |    34.5211 |                   -6.0000 |     85.0000 | \n",
      "  281 | 03m09s |   -0.91743 |      0.0010 |     30.0000 |      2.0000 |   100.0000 |                   -6.0000 |     30.9068 | \n",
      "  282 | 02m59s |   -1.73119 |      0.0010 |     30.0000 |     30.0000 |     1.0000 |                    5.0000 |      5.0000 | \n",
      "  283 | 03m14s |   -0.92947 |      0.0010 |      0.0010 |      2.0000 |     1.0000 |                   -6.0000 |      5.0000 | \n",
      "  284 | 03m11s |   -0.92222 |      0.0010 |      0.0010 |      2.0000 |    44.8596 |                   -6.0000 |     85.0000 | \n",
      "  285 | 03m05s |   -0.91774 |      0.0010 |     30.0000 |      2.0000 |    71.6701 |                   -6.0000 |     85.0000 | \n",
      "  286 | 03m18s |   -0.89493 |     30.0000 |      0.0010 |     30.0000 |   100.0000 |                   -6.0000 |     52.5212 | \n",
      "  287 | 03m41s |   -0.91278 |     30.0000 |     30.0000 |     30.0000 |     1.0000 |                   -6.0000 |     67.9239 | \n",
      "  288 | 03m20s |   -0.91746 |      0.0010 |     30.0000 |      2.0000 |     1.0000 |                   -6.0000 |     45.6561 | \n",
      "  289 | 03m05s |   -1.73119 |     30.0000 |      0.0010 |     30.0000 |     1.0000 |                    5.0000 |     85.0000 | \n",
      "  290 | 03m52s |   -0.90059 |      0.0010 |     30.0000 |     30.0000 |    45.1285 |                   -6.0000 |     85.0000 | \n",
      "  291 | 03m32s |   -0.89240 |     30.0000 |      0.0010 |     30.0000 |    68.9513 |                   -6.0000 |     85.0000 | \n",
      "  292 | 03m20s |   -0.92947 |      0.0010 |      0.0010 |      2.0000 |     1.0000 |                   -6.0000 |     85.0000 | \n",
      "  293 | 03m16s |   -0.92167 |      0.0010 |      0.0010 |      2.0000 |   100.0000 |                   -6.0000 |     48.6887 | \n",
      "  294 | 03m24s |   -0.92126 |      0.0010 |      0.0010 |      2.0000 |    42.9545 |                   -6.0000 |      5.0000 | \n",
      "  295 | 03m46s |   -0.91660 |     30.0000 |      0.0010 |      2.0000 |   100.0000 |                   -6.0000 |     85.0000 | \n",
      "  296 | 03m04s |   -1.73119 |      0.0010 |     30.0000 |      2.0000 |    78.2427 |                    5.0000 |      5.0000 | \n",
      "  297 | 03m51s |   -0.90459 |      0.0010 |     30.0000 |     30.0000 |   100.0000 |                   -6.0000 |     31.2541 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([  1.55040210e-05]), 'nit': 5, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'warnflag': 2, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  298 | 03m37s |   -0.90339 |     30.0000 |     30.0000 |     30.0000 |    38.9695 |                   -6.0000 |      5.0000 | \n",
      "  299 | 03m46s |   -0.90613 |      0.0010 |     30.0000 |     30.0000 |   100.0000 |                   -6.0000 |     85.0000 | \n",
      "  300 | 03m31s |   -0.91950 |      0.0010 |      0.0010 |     30.0000 |    34.7976 |                   -6.0000 |      5.0000 | \n",
      "  301 | 03m43s |   -0.91296 |     30.0000 |      0.0010 |     30.0000 |     1.0000 |                   -6.0000 |      5.0000 | \n",
      "  302 | 04m08s |   -0.89991 |      0.0010 |     30.0000 |     30.0000 |     1.0000 |                   -6.0000 |     55.5127 | \n",
      "  303 | 03m33s |   -0.91590 |      0.0010 |      0.0010 |     30.0000 |    72.0203 |                   -6.0000 |      5.0000 | \n",
      "  304 | 04m09s |   -0.89104 |     30.0000 |      0.0010 |     30.0000 |    70.0612 |                   -6.0000 |     49.8438 | \n",
      "  305 | 03m38s |   -0.91769 |     30.0000 |      0.0010 |     30.0000 |   100.0000 |                   -6.0000 |      5.0000 | \n",
      "  306 | 04m44s |   -0.90838 |      0.0010 |     30.0000 |     30.0000 |     1.0000 |                   -6.0000 |     85.0000 | \n",
      "  307 | 03m42s |   -0.91612 |      0.0010 |     30.0000 |      2.0000 |    79.3268 |                   -6.0000 |     54.2956 | \n",
      "  308 | 03m31s |   -0.91853 |     30.0000 |      0.0010 |      2.0000 |    36.3665 |                   -6.0000 |     85.0000 | \n",
      "  309 | 03m44s |   -0.91508 |     30.0000 |     30.0000 |      2.0000 |   100.0000 |                   -6.0000 |     18.0928 | \n",
      "  310 | 03m59s |   -0.91464 |      0.0010 |     30.0000 |     30.0000 |    45.6049 |                   -6.0000 |      5.0000 | \n",
      "  311 | 04m27s |   -0.93423 |      0.0010 |      0.0010 |     30.0000 |     1.0000 |                   -6.0000 |     52.9827 | \n",
      "  312 | 03m57s |   -0.91660 |     30.0000 |      0.0010 |      2.0000 |   100.0000 |                   -6.0000 |     55.9746 | \n",
      "  313 | 04m07s |   -0.89694 |     12.4806 |     30.0000 |     30.0000 |    24.2904 |                   -6.0000 |     42.1279 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([  2.97758492e-05]), 'nit': 5, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'warnflag': 2, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  314 | 04m33s |   -0.92167 |      0.0010 |      0.0010 |      2.0000 |   100.0000 |                   -6.0000 |     22.7547 | \n",
      "  315 | 03m54s |   -0.91883 |     30.0000 |      0.0010 |      2.0000 |    74.1613 |                   -6.0000 |      5.0000 | \n",
      "  316 | 04m10s |   -0.92181 |     30.0000 |     30.0000 |      2.0000 |     1.0000 |                   -6.0000 |     50.8809 | \n",
      "  317 | 03m58s |   -1.73119 |      0.0010 |      0.0010 |     30.0000 |   100.0000 |                    5.0000 |     53.1791 | \n",
      "  318 | 04m50s |   -0.89593 |      0.0010 |     30.0000 |     30.0000 |    75.6856 |                   -6.0000 |     85.0000 | \n",
      "  319 | 04m32s |   -0.91635 |      0.0010 |     30.0000 |      2.0000 |    34.0456 |                   -6.0000 |      5.0000 | \n",
      "  320 | 04m44s |   -0.89225 |     30.0000 |     12.4986 |     30.0000 |    40.6176 |                   -6.0000 |     34.3394 | \n",
      "  321 | 04m56s |   -0.90008 |      0.0010 |     30.0000 |     30.0000 |    72.5812 |                   -6.0000 |     50.0817 | \n",
      "  322 | 04m36s |   -0.91047 |     30.0000 |      0.0010 |     30.0000 |    60.5415 |                   -6.0000 |      5.0000 | \n",
      "  323 | 04m36s |   -0.91478 |     30.0000 |      0.0010 |      2.0000 |    40.9776 |                   -6.0000 |     29.1740 | \n",
      "  324 | 04m49s |   -0.89600 |     30.0000 |      0.0010 |     30.0000 |    32.5296 |                   -6.0000 |     85.0000 | \n",
      "  325 | 04m30s |   -0.91480 |     30.0000 |      0.0010 |      2.0000 |     1.0000 |                   -6.0000 |     29.4562 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([  3.85086627e-05]), 'nit': 5, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'warnflag': 2, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  326 | 04m57s |   -0.92259 |      0.0010 |      0.0010 |     14.3540 |    72.1492 |                   -6.0000 |     85.0000 | \n",
      "  327 | 05m42s |   -0.89629 |     17.7229 |      7.7248 |     18.1327 |    48.9933 |                    0.3797 |     77.6637 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  328 | 04m34s |   -1.73119 |     30.0000 |      0.0010 |     30.0000 |   100.0000 |                    5.0000 |     85.0000 | \n",
      "  329 | 04m54s |   -0.91494 |      0.0010 |     30.0000 |     30.0000 |    85.3321 |                   -6.0000 |      5.0000 | \n",
      "  330 | 05m25s |   -0.91089 |     30.0000 |     30.0000 |      2.0000 |    68.6833 |                   -6.0000 |     15.6449 | \n",
      "  331 | 05m04s |   -1.73119 |     18.9338 |     25.0068 |     17.7744 |    67.1584 |                    4.6677 |      5.8237 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  332 | 04m50s |   -1.73119 |      5.6376 |      5.4861 |      6.7248 |    16.1062 |                    3.8479 |     70.3348 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  333 | 05m10s |   -0.89465 |     18.2344 |     10.1780 |     26.8342 |    56.3013 |                   -4.8315 |     60.4930 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  334 | 05m11s |   -0.91480 |     30.0000 |      0.0010 |      2.0000 |     1.0000 |                   -6.0000 |     58.1271 | \n",
      "  335 | 05m01s |   -0.91306 |     23.6736 |     26.8824 |      2.1645 |    39.2789 |                    1.1141 |     72.9046 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([  1.73087573e-05]), 'nit': 5, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'warnflag': 2, 'funcalls': 58}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  336 | 06m15s |   -0.94022 |      0.0010 |      0.0010 |     30.0000 |     1.0000 |                   -6.0000 |     85.0000 | \n",
      "  337 | 05m20s |   -0.89479 |     30.0000 |     30.0000 |     30.0000 |   100.0000 |                   -6.0000 |     37.0059 | \n",
      "  338 | 05m33s |   -0.89559 |     22.0996 |     21.8465 |     11.6558 |    53.6710 |                   -2.6448 |     30.6471 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  339 | 05m41s |   -0.89980 |     21.0881 |     21.2798 |      3.5354 |    58.9876 |                   -2.0907 |     64.2415 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  340 | 05m48s |   -0.91743 |      0.0010 |     30.0000 |      2.0000 |   100.0000 |                   -6.0000 |     61.2468 | \n",
      "  341 | 05m09s |   -0.91840 |      0.0010 |      0.0010 |      2.0000 |    75.9339 |                   -6.0000 |      5.0000 | \n",
      "  342 | 05m29s |   -0.89642 |     30.0000 |     10.8974 |     15.0288 |    72.0571 |                   -6.0000 |     18.9958 | \n",
      "  343 | 05m26s |   -0.92149 |      0.0010 |      0.0010 |      2.0000 |    41.0973 |                   -6.0000 |     26.4842 | \n",
      "  344 | 05m57s |   -1.73119 |      4.2835 |     11.1933 |      7.8453 |    66.9091 |                    4.3481 |      9.9595 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  345 | 06m10s |   -0.90963 |      0.0010 |     12.2747 |     18.1299 |    43.6439 |                   -6.0000 |     85.0000 | \n",
      "  346 | 05m38s |   -0.92947 |      0.0010 |      0.0010 |      2.0000 |     1.0000 |                   -6.0000 |     51.4777 | \n",
      "  347 | 06m43s |   -0.89200 |     24.1591 |     25.0323 |     25.2978 |    72.7299 |                    2.3639 |     53.2747 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  348 | 06m02s |   -0.90071 |     30.0000 |     30.0000 |     30.0000 |     1.0000 |                   -6.0000 |     34.2220 | \n",
      "  349 | 06m04s |   -0.89120 |     16.2461 |     16.2386 |     21.7792 |    63.9114 |                   -4.9780 |     22.1084 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  350 | 06m01s |   -0.91094 |     30.0000 |     30.0000 |      2.0000 |    36.6811 |                   -6.0000 |     36.4262 | \n",
      "  351 | 06m30s |   -0.89733 |      9.5210 |     20.8408 |      6.2050 |    46.1053 |                    0.1581 |     61.4344 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  352 | 06m28s |   -0.90347 |      0.0010 |     30.0000 |     23.1072 |    44.9661 |                   -6.0000 |     37.6375 | \n",
      "  353 | 05m57s |   -0.90361 |     11.5002 |      1.1211 |     28.9503 |    58.1052 |                   -1.2722 |     51.3538 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  354 | 06m32s |   -0.89862 |     21.5726 |     29.1054 |     25.0560 |    11.4716 |                   -0.5919 |     60.7852 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  355 | 06m33s |   -0.91271 |     30.0000 |      0.0010 |      2.0000 |    69.9664 |                   -6.0000 |     85.0000 | \n",
      "  356 | 05m59s |   -0.89930 |      4.9565 |     16.9347 |     15.7773 |    75.7669 |                    2.3870 |     20.5918 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  357 | 06m01s |   -0.91657 |     30.0000 |     30.0000 |      2.0000 |    78.4581 |                   -6.0000 |     58.3207 | \n",
      "  358 | 06m15s |   -0.89373 |     26.9477 |     24.4933 |      9.9105 |    84.9453 |                   -1.7539 |     20.5230 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  359 | 06m21s |   -0.90027 |     27.2123 |     10.4037 |     13.9131 |    55.6865 |                   -3.8688 |     13.5263 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([  3.05245228e-05]), 'nit': 5, 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'warnflag': 2, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  360 | 06m23s |   -0.91882 |     12.5664 |      7.9582 |     25.4659 |    79.7555 |                    3.0018 |     37.7309 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  361 | 07m09s |   -0.89368 |     21.7902 |     19.2297 |     19.8567 |    54.5070 |                   -2.3042 |     69.3022 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  362 | 06m36s |   -0.89840 |      6.3276 |     16.0919 |      8.0747 |    86.6765 |                   -5.7271 |     17.8341 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  363 | 06m26s |   -1.73119 |     30.0000 |     19.4838 |      2.0000 |   100.0000 |                    5.0000 |      5.0000 | \n",
      "  364 | 06m43s |   -0.91660 |     30.0000 |      0.0010 |      2.0000 |   100.0000 |                   -6.0000 |     27.8765 | \n",
      "  365 | 07m03s |   -0.90106 |      5.4269 |     12.1365 |     13.0989 |    11.4196 |                   -3.5861 |     46.5694 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  366 | 06m39s |   -0.89510 |     19.0261 |      8.1873 |     21.9489 |    23.1051 |                    1.1318 |     10.5680 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  367 | 07m09s |   -0.89989 |     28.7548 |      9.4421 |      8.2686 |    72.0682 |                   -0.0726 |     10.7939 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  368 | 06m55s |   -1.73119 |      9.9344 |     10.0732 |     18.9272 |    40.4527 |                    4.4550 |     38.6034 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  369 | 06m51s |   -0.89968 |     29.2463 |      5.6214 |      9.0011 |    55.1654 |                   -5.0104 |     44.5071 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  370 | 06m55s |   -0.89783 |      4.2740 |     28.3679 |     11.3686 |    42.9815 |                   -1.5142 |     24.1670 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  371 | 07m03s |   -0.89376 |     26.6817 |      6.9874 |     10.7960 |    83.4508 |                   -2.0988 |     75.3585 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  372 | 06m57s |   -0.90854 |     10.5297 |      1.0482 |     13.8125 |    55.5457 |                   -5.4861 |      5.8742 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  373 | 06m33s |   -0.89590 |      8.6415 |      6.3672 |      7.4879 |    86.8547 |                   -1.0397 |     17.8611 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  374 | 07m21s |   -0.90317 |     19.5911 |     16.7511 |     21.8923 |     1.7273 |                   -5.6127 |     56.4512 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  375 | 06m51s |   -1.73119 |      7.5692 |     23.7399 |      7.6895 |     3.3174 |                    4.6298 |     31.4042 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  376 | 07m29s |   -0.90253 |      2.0071 |     28.2480 |     18.1094 |    65.6490 |                    1.2841 |     10.7944 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  377 | 07m07s |   -0.91213 |     30.0000 |     30.0000 |     17.5158 |    20.1490 |                   -6.0000 |      5.0000 | \n",
      "  378 | 06m58s |   -1.73119 |     19.1258 |     23.1091 |     17.0481 |    23.1106 |                    3.7891 |     62.9219 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  379 | 07m36s |   -0.89483 |     17.2116 |      8.4568 |     14.0955 |    60.3882 |                   -3.9150 |     41.8410 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  380 | 07m36s |   -0.90986 |      0.7887 |      3.4002 |     18.2955 |    77.5208 |                   -4.5790 |     55.4564 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  381 | 07m34s |   -0.91649 |      0.0010 |     30.0000 |      2.0000 |    25.3718 |                   -6.0000 |     85.0000 | \n",
      "  382 | 07m09s |   -1.73119 |      9.8839 |     15.4783 |     12.4012 |     4.4945 |                    4.1171 |     15.2352 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  383 | 07m59s |   -0.91721 |      0.0010 |     14.0512 |      2.0000 |    16.6756 |                   -6.0000 |      5.0000 | \n",
      "  384 | 07m54s |   -0.92252 |     11.1655 |      9.7345 |     25.4585 |    23.3041 |                    2.5347 |     41.0684 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  385 | 08m28s |   -0.90301 |     13.1936 |      8.2704 |     23.8127 |    12.8412 |                   -2.8170 |     29.3041 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  386 | 08m28s |   -0.90582 |     14.7476 |     20.8740 |     15.6108 |     5.6866 |                   -3.9806 |     84.4623 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n",
      "  387 | 07m44s |   -0.91882 |     17.8301 |     10.5623 |     24.4103 |    49.9313 |                    3.2503 |     34.7322 | \u001b[31mWarning: Test point chose at random due to repeated sample.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    301\u001b[0m                             \u001b[0mgp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                             \u001b[0my_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m                             bounds=self.bounds)\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;31m# Print stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/bayes_opt/helpers.py\u001b[0m in \u001b[0;36macq_max\u001b[0;34m(ac, gp, y_max, bounds)\u001b[0m\n\u001b[1;32m     50\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                        method=\"L-BFGS-B\")\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Store it if better than previous minimum(maximum).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 450\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/bayes_opt/helpers.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_try\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_seeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Find the minimum of minus the acquisition function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         res = minimize(lambda x: -ac(x.reshape(1, -1), gp=gp, y_max=y_max),\n\u001b[0m\u001b[1;32m     50\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/bayes_opt/helpers.py\u001b[0m in \u001b[0;36mutility\u001b[0;34m(self, x, gp, y_max)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ucb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ucb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ei'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/bayes_opt/helpers.py\u001b[0m in \u001b[0;36m_ucb\u001b[0;34m(x, gp, kappa)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ucb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkappa\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0;31m# decomposition L and its inverse L_inv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mL_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_triangular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                 \u001b[0mK_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_inv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_inv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;31m# Compute variance of predictive distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgBO.maximize(init_points=250, n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_ww=np.hstack((X_train_ww,stack.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "     26.2411 |     20.2778 |     18.2361 |    61.9828 |                   -0.3046 |     61.8345 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params= {                                       \"min_data_in_leaf\":62,\n",
    "                                                'learning_rate': 0.001,\n",
    "                                                'metric': 'mse',\n",
    "                                                \"num_leaves\":62,\n",
    "                                                \"max_depth\":18,\n",
    "                                                \"min_sum_hessian_in_leaf\":1,\n",
    "                                                \"lambda_l1\": 26.2411,\n",
    "                                                \"lambda_l2\":20.2778}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ms         =    cluster.MeanShift(n_jobs=-1)\n",
    "etr_tf     =    tree.ExtraTreeRegressor(random_state=42)\n",
    "etr_ww     =    tree.ExtraTreeRegressor(random_state=42)\n",
    "kn_tf      =    neighbors.KNeighborsRegressor(n_neighbors=7,weights=\"distance\",n_jobs=-1)\n",
    "kn_ww      =    neighbors.KNeighborsRegressor(n_neighbors=7,weights=\"distance\",n_jobs=-1)\n",
    "lin_clf_ww =    svm.LinearSVC(random_state=42)\n",
    "lin_clf_tf =    svm.LinearSVC(random_state=42)\n",
    "lr_tf      =    linear_model.LogisticRegression(solver=\"sag\",multi_class = 'multinomial' , n_jobs=-1,random_state=42)\n",
    "lr_ww      =    linear_model.LogisticRegression(solver=\"sag\",multi_class = 'multinomial' , n_jobs=-1,random_state=42)\n",
    "rf_clf     =    ensemble.RandomForestClassifier(n_estimators=250,n_jobs=-1,random_state=42)\n",
    "rf         =    ensemble.RandomForestRegressor(n_estimators=125,n_jobs=-1,random_state=42)\n",
    "tr_tf      =    tree.DecisionTreeRegressor(random_state=42)\n",
    "tr_ww      =    tree.DecisionTreeRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 4s, sys: 5.47 s, total: 23min 9s\n",
      "Wall time: 9min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ms.fit(X_train_ww,y_train)\n",
    "etr_tf.fit(X_train_tf,y_train)     \n",
    "etr_ww.fit(X_train_ww,y_train)\n",
    "kn_tf.fit(X_train_tf,y_train)  \n",
    "kn_ww.fit(X_train_ww,y_train) \n",
    "lin_clf_ww.fit(X_train_ww,np.array(y_train,dtype=\"int8\"))\n",
    "lin_clf_tf.fit(X_train_tf,np.array(y_train,dtype=\"int8\")) \n",
    "lr_tf.fit(X_train_tf,np.array(y_train,dtype=\"int8\"))     \n",
    "lr_ww.fit(X_train_ww,np.array(y_train,dtype=\"int8\"))\n",
    "rf_clf.fit(X_train_ww,np.array(y_train,dtype=\"int8\"))     \n",
    "rf.fit(X_train_ww,y_train)        \n",
    "tr_tf.fit(X_train_tf,y_train)      \n",
    "tr_ww.fit(X_train_ww,y_train)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tr_ww.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "externals.joblib.dump(ms, 'ms.pkl') \n",
    "externals.joblib.dump(etr_tf, 'etr_tf.pkl') \n",
    "externals.joblib.dump(etr_ww, 'etr_ww.pkl') \n",
    "externals.joblib.dump(kn_tf, 'kn_tf.pkl') \n",
    "externals.joblib.dump(kn_ww, 'kn_ww.pkl') \n",
    "externals.joblib.dump(lin_clf_ww, 'lin_clf_ww.pkl') \n",
    "externals.joblib.dump(lin_clf_tf, 'lin_clf_tf.pkl') \n",
    "externals.joblib.dump(lr_tf, 'lr_tf.pkl')\n",
    "externals.joblib.dump(lr_ww, 'lr_ww.pkl')\n",
    "externals.joblib.dump(rf_clf, 'rf_clf.pkl')\n",
    "externals.joblib.dump(rf, 'rf.pkl')\n",
    "externals.joblib.dump(tr_tf, 'tr_tf.pkl')\n",
    "externals.joblib.dump(tr_ww, 'tr_ww.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.95 s, sys: 1.17 s, total: 4.12 s\n",
      "Wall time: 4.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ans=(\n",
    "ms.predict(X_test_ww)         ,\n",
    "etr_tf.predict(X_test_tf)     ,\n",
    "etr_ww.predict(X_test_ww)     ,\n",
    "kn_tf.predict(X_test_tf)      ,\n",
    "kn_ww.predict(X_test_ww)      ,\n",
    "lin_clf_ww.predict(X_test_ww) ,\n",
    "lin_clf_tf.predict(X_test_tf) ,\n",
    "lr_tf.predict(X_test_tf)      ,\n",
    "lr_ww.predict(X_test_ww)      ,\n",
    "rf_clf.predict(X_test_ww)     ,\n",
    "rf.predict(X_test_ww)         ,\n",
    "tr_tf.predict(X_test_tf)      ,\n",
    "tr_ww.predict(X_test_ww))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"first_level.txt\",np.array(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_test=np.loadtxt(\"./first_level.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 12469)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12469, 211)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ww.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FIRST_LEVEL_TRAIN=np.hstack((X_train_ww,stack.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params= {                                       \"min_data_in_leaf\":62,\n",
    "                                                'learning_rate': 0.01,\n",
    "                                                'metric': 'mse',\n",
    "                                                \"num_leaves\":62,\n",
    "                                                \"max_depth\":18,\n",
    "                                                \"min_sum_hessian_in_leaf\":1,\n",
    "                                                \"lambda_l1\": 26.2411,\n",
    "                                                \"lambda_l2\":20.2778}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldata=lightgbm.Dataset(X_FIRST_LEVEL_TRAIN,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 14s, sys: 3.1 s, total: 23min 17s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lg=lightgbm.cv(params,ldata,early_stopping_rounds=5,num_boost_round=int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lg[\"l2-mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdata=lightgbm.Dataset(tester,label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 1.74013\n",
      "Train until valid scores didn't improve in 5 rounds.\n",
      "[2]\tvalid_0's l2: 1.73137\n",
      "[3]\tvalid_0's l2: 1.72281\n",
      "[4]\tvalid_0's l2: 1.71448\n",
      "[5]\tvalid_0's l2: 1.70613\n",
      "[6]\tvalid_0's l2: 1.6982\n",
      "[7]\tvalid_0's l2: 1.69027\n",
      "[8]\tvalid_0's l2: 1.68273\n",
      "[9]\tvalid_0's l2: 1.67518\n",
      "[10]\tvalid_0's l2: 1.66802\n",
      "[11]\tvalid_0's l2: 1.66084\n",
      "[12]\tvalid_0's l2: 1.65405\n",
      "[13]\tvalid_0's l2: 1.64728\n",
      "[14]\tvalid_0's l2: 1.64048\n",
      "[15]\tvalid_0's l2: 1.63398\n",
      "[16]\tvalid_0's l2: 1.62786\n",
      "[17]\tvalid_0's l2: 1.62186\n",
      "[18]\tvalid_0's l2: 1.61539\n",
      "[19]\tvalid_0's l2: 1.60969\n",
      "[20]\tvalid_0's l2: 1.60413\n",
      "[21]\tvalid_0's l2: 1.59831\n",
      "[22]\tvalid_0's l2: 1.59302\n",
      "[23]\tvalid_0's l2: 1.58747\n",
      "[24]\tvalid_0's l2: 1.58234\n",
      "[25]\tvalid_0's l2: 1.57706\n",
      "[26]\tvalid_0's l2: 1.57227\n",
      "[27]\tvalid_0's l2: 1.56756\n",
      "[28]\tvalid_0's l2: 1.56266\n",
      "[29]\tvalid_0's l2: 1.55816\n",
      "[30]\tvalid_0's l2: 1.55359\n",
      "[31]\tvalid_0's l2: 1.54931\n",
      "[32]\tvalid_0's l2: 1.54528\n",
      "[33]\tvalid_0's l2: 1.54106\n",
      "[34]\tvalid_0's l2: 1.53714\n",
      "[35]\tvalid_0's l2: 1.53281\n",
      "[36]\tvalid_0's l2: 1.52909\n",
      "[37]\tvalid_0's l2: 1.52465\n",
      "[38]\tvalid_0's l2: 1.52092\n",
      "[39]\tvalid_0's l2: 1.51664\n",
      "[40]\tvalid_0's l2: 1.51272\n",
      "[41]\tvalid_0's l2: 1.50876\n",
      "[42]\tvalid_0's l2: 1.50498\n",
      "[43]\tvalid_0's l2: 1.50128\n",
      "[44]\tvalid_0's l2: 1.49752\n",
      "[45]\tvalid_0's l2: 1.49402\n",
      "[46]\tvalid_0's l2: 1.49127\n",
      "[47]\tvalid_0's l2: 1.48785\n",
      "[48]\tvalid_0's l2: 1.48523\n",
      "[49]\tvalid_0's l2: 1.48266\n",
      "[50]\tvalid_0's l2: 1.47945\n",
      "[51]\tvalid_0's l2: 1.47642\n",
      "[52]\tvalid_0's l2: 1.47424\n",
      "[53]\tvalid_0's l2: 1.47181\n",
      "[54]\tvalid_0's l2: 1.46893\n",
      "[55]\tvalid_0's l2: 1.46588\n",
      "[56]\tvalid_0's l2: 1.46358\n",
      "[57]\tvalid_0's l2: 1.46134\n",
      "[58]\tvalid_0's l2: 1.45893\n",
      "[59]\tvalid_0's l2: 1.45684\n",
      "[60]\tvalid_0's l2: 1.45476\n",
      "[61]\tvalid_0's l2: 1.45241\n",
      "[62]\tvalid_0's l2: 1.45077\n",
      "[63]\tvalid_0's l2: 1.44907\n",
      "[64]\tvalid_0's l2: 1.44678\n",
      "[65]\tvalid_0's l2: 1.4445\n",
      "[66]\tvalid_0's l2: 1.44268\n",
      "[67]\tvalid_0's l2: 1.44117\n",
      "[68]\tvalid_0's l2: 1.43902\n",
      "[69]\tvalid_0's l2: 1.43703\n",
      "[70]\tvalid_0's l2: 1.43528\n",
      "[71]\tvalid_0's l2: 1.43336\n",
      "[72]\tvalid_0's l2: 1.43194\n",
      "[73]\tvalid_0's l2: 1.43026\n",
      "[74]\tvalid_0's l2: 1.42835\n",
      "[75]\tvalid_0's l2: 1.42645\n",
      "[76]\tvalid_0's l2: 1.42506\n",
      "[77]\tvalid_0's l2: 1.42294\n",
      "[78]\tvalid_0's l2: 1.42027\n",
      "[79]\tvalid_0's l2: 1.41854\n",
      "[80]\tvalid_0's l2: 1.41612\n",
      "[81]\tvalid_0's l2: 1.4148\n",
      "[82]\tvalid_0's l2: 1.41304\n",
      "[83]\tvalid_0's l2: 1.41146\n",
      "[84]\tvalid_0's l2: 1.40958\n",
      "[85]\tvalid_0's l2: 1.40876\n",
      "[86]\tvalid_0's l2: 1.4076\n",
      "[87]\tvalid_0's l2: 1.40617\n",
      "[88]\tvalid_0's l2: 1.40493\n",
      "[89]\tvalid_0's l2: 1.40354\n",
      "[90]\tvalid_0's l2: 1.40226\n",
      "[91]\tvalid_0's l2: 1.40041\n",
      "[92]\tvalid_0's l2: 1.39945\n",
      "[93]\tvalid_0's l2: 1.39824\n",
      "[94]\tvalid_0's l2: 1.39757\n",
      "[95]\tvalid_0's l2: 1.3962\n",
      "[96]\tvalid_0's l2: 1.39453\n",
      "[97]\tvalid_0's l2: 1.39336\n",
      "[98]\tvalid_0's l2: 1.39235\n",
      "[99]\tvalid_0's l2: 1.39084\n",
      "[100]\tvalid_0's l2: 1.39\n",
      "[101]\tvalid_0's l2: 1.38849\n",
      "[102]\tvalid_0's l2: 1.38733\n",
      "[103]\tvalid_0's l2: 1.38615\n",
      "[104]\tvalid_0's l2: 1.38508\n",
      "[105]\tvalid_0's l2: 1.38354\n",
      "[106]\tvalid_0's l2: 1.38222\n",
      "[107]\tvalid_0's l2: 1.38084\n",
      "[108]\tvalid_0's l2: 1.37936\n",
      "[109]\tvalid_0's l2: 1.37812\n",
      "[110]\tvalid_0's l2: 1.37784\n",
      "[111]\tvalid_0's l2: 1.37752\n",
      "[112]\tvalid_0's l2: 1.37624\n",
      "[113]\tvalid_0's l2: 1.3759\n",
      "[114]\tvalid_0's l2: 1.37549\n",
      "[115]\tvalid_0's l2: 1.37416\n",
      "[116]\tvalid_0's l2: 1.37305\n",
      "[117]\tvalid_0's l2: 1.3728\n",
      "[118]\tvalid_0's l2: 1.37169\n",
      "[119]\tvalid_0's l2: 1.37114\n",
      "[120]\tvalid_0's l2: 1.37006\n",
      "[121]\tvalid_0's l2: 1.36933\n",
      "[122]\tvalid_0's l2: 1.36919\n",
      "[123]\tvalid_0's l2: 1.36842\n",
      "[124]\tvalid_0's l2: 1.36768\n",
      "[125]\tvalid_0's l2: 1.36687\n",
      "[126]\tvalid_0's l2: 1.36582\n",
      "[127]\tvalid_0's l2: 1.36525\n",
      "[128]\tvalid_0's l2: 1.36458\n",
      "[129]\tvalid_0's l2: 1.36393\n",
      "[130]\tvalid_0's l2: 1.36324\n",
      "[131]\tvalid_0's l2: 1.36264\n",
      "[132]\tvalid_0's l2: 1.36172\n",
      "[133]\tvalid_0's l2: 1.36153\n",
      "[134]\tvalid_0's l2: 1.36061\n",
      "[135]\tvalid_0's l2: 1.36016\n",
      "[136]\tvalid_0's l2: 1.35954\n",
      "[137]\tvalid_0's l2: 1.35882\n",
      "[138]\tvalid_0's l2: 1.35836\n",
      "[139]\tvalid_0's l2: 1.35782\n",
      "[140]\tvalid_0's l2: 1.35733\n",
      "[141]\tvalid_0's l2: 1.35675\n",
      "[142]\tvalid_0's l2: 1.3563\n",
      "[143]\tvalid_0's l2: 1.35599\n",
      "[144]\tvalid_0's l2: 1.35547\n",
      "[145]\tvalid_0's l2: 1.35462\n",
      "[146]\tvalid_0's l2: 1.35411\n",
      "[147]\tvalid_0's l2: 1.35362\n",
      "[148]\tvalid_0's l2: 1.35321\n",
      "[149]\tvalid_0's l2: 1.35297\n",
      "[150]\tvalid_0's l2: 1.35246\n",
      "[151]\tvalid_0's l2: 1.35177\n",
      "[152]\tvalid_0's l2: 1.35087\n",
      "[153]\tvalid_0's l2: 1.35003\n",
      "[154]\tvalid_0's l2: 1.34972\n",
      "[155]\tvalid_0's l2: 1.34888\n",
      "[156]\tvalid_0's l2: 1.348\n",
      "[157]\tvalid_0's l2: 1.34725\n",
      "[158]\tvalid_0's l2: 1.34681\n",
      "[159]\tvalid_0's l2: 1.34625\n",
      "[160]\tvalid_0's l2: 1.34542\n",
      "[161]\tvalid_0's l2: 1.34468\n",
      "[162]\tvalid_0's l2: 1.3441\n",
      "[163]\tvalid_0's l2: 1.34344\n",
      "[164]\tvalid_0's l2: 1.34292\n",
      "[165]\tvalid_0's l2: 1.34219\n",
      "[166]\tvalid_0's l2: 1.34177\n",
      "[167]\tvalid_0's l2: 1.34124\n",
      "[168]\tvalid_0's l2: 1.34031\n",
      "[169]\tvalid_0's l2: 1.33975\n",
      "[170]\tvalid_0's l2: 1.33918\n",
      "[171]\tvalid_0's l2: 1.33856\n",
      "[172]\tvalid_0's l2: 1.33816\n",
      "[173]\tvalid_0's l2: 1.33724\n",
      "[174]\tvalid_0's l2: 1.33717\n",
      "[175]\tvalid_0's l2: 1.33662\n",
      "[176]\tvalid_0's l2: 1.33626\n",
      "[177]\tvalid_0's l2: 1.3356\n",
      "[178]\tvalid_0's l2: 1.33514\n",
      "[179]\tvalid_0's l2: 1.33459\n",
      "[180]\tvalid_0's l2: 1.33444\n",
      "[181]\tvalid_0's l2: 1.33455\n",
      "[182]\tvalid_0's l2: 1.33377\n",
      "[183]\tvalid_0's l2: 1.33342\n",
      "[184]\tvalid_0's l2: 1.33248\n",
      "[185]\tvalid_0's l2: 1.33215\n",
      "[186]\tvalid_0's l2: 1.33139\n",
      "[187]\tvalid_0's l2: 1.33127\n",
      "[188]\tvalid_0's l2: 1.33095\n",
      "[189]\tvalid_0's l2: 1.33017\n",
      "[190]\tvalid_0's l2: 1.32981\n",
      "[191]\tvalid_0's l2: 1.32921\n",
      "[192]\tvalid_0's l2: 1.32939\n",
      "[193]\tvalid_0's l2: 1.32902\n",
      "[194]\tvalid_0's l2: 1.3282\n",
      "[195]\tvalid_0's l2: 1.32753\n",
      "[196]\tvalid_0's l2: 1.32722\n",
      "[197]\tvalid_0's l2: 1.32647\n",
      "[198]\tvalid_0's l2: 1.32615\n",
      "[199]\tvalid_0's l2: 1.32613\n",
      "[200]\tvalid_0's l2: 1.32541\n",
      "[201]\tvalid_0's l2: 1.32472\n",
      "[202]\tvalid_0's l2: 1.32452\n",
      "[203]\tvalid_0's l2: 1.32424\n",
      "[204]\tvalid_0's l2: 1.32364\n",
      "[205]\tvalid_0's l2: 1.32332\n",
      "[206]\tvalid_0's l2: 1.32292\n",
      "[207]\tvalid_0's l2: 1.32273\n",
      "[208]\tvalid_0's l2: 1.32262\n",
      "[209]\tvalid_0's l2: 1.32254\n",
      "[210]\tvalid_0's l2: 1.32233\n",
      "[211]\tvalid_0's l2: 1.32207\n",
      "[212]\tvalid_0's l2: 1.32184\n",
      "[213]\tvalid_0's l2: 1.32163\n",
      "[214]\tvalid_0's l2: 1.3215\n",
      "[215]\tvalid_0's l2: 1.32115\n",
      "[216]\tvalid_0's l2: 1.32118\n",
      "[217]\tvalid_0's l2: 1.32045\n",
      "[218]\tvalid_0's l2: 1.32013\n",
      "[219]\tvalid_0's l2: 1.3201\n",
      "[220]\tvalid_0's l2: 1.31982\n",
      "[221]\tvalid_0's l2: 1.31958\n",
      "[222]\tvalid_0's l2: 1.31889\n",
      "[223]\tvalid_0's l2: 1.3187\n",
      "[224]\tvalid_0's l2: 1.31847\n",
      "[225]\tvalid_0's l2: 1.31827\n",
      "[226]\tvalid_0's l2: 1.31831\n",
      "[227]\tvalid_0's l2: 1.31819\n",
      "[228]\tvalid_0's l2: 1.31746\n",
      "[229]\tvalid_0's l2: 1.31715\n",
      "[230]\tvalid_0's l2: 1.31698\n",
      "[231]\tvalid_0's l2: 1.3167\n",
      "[232]\tvalid_0's l2: 1.31648\n",
      "[233]\tvalid_0's l2: 1.31591\n",
      "[234]\tvalid_0's l2: 1.31559\n",
      "[235]\tvalid_0's l2: 1.31532\n",
      "[236]\tvalid_0's l2: 1.3149\n",
      "[237]\tvalid_0's l2: 1.31466\n",
      "[238]\tvalid_0's l2: 1.31445\n",
      "[239]\tvalid_0's l2: 1.31373\n",
      "[240]\tvalid_0's l2: 1.31355\n",
      "[241]\tvalid_0's l2: 1.31314\n",
      "[242]\tvalid_0's l2: 1.31245\n",
      "[243]\tvalid_0's l2: 1.3118\n",
      "[244]\tvalid_0's l2: 1.3116\n",
      "[245]\tvalid_0's l2: 1.31048\n",
      "[246]\tvalid_0's l2: 1.30978\n",
      "[247]\tvalid_0's l2: 1.30902\n",
      "[248]\tvalid_0's l2: 1.30867\n",
      "[249]\tvalid_0's l2: 1.30798\n",
      "[250]\tvalid_0's l2: 1.30777\n",
      "[251]\tvalid_0's l2: 1.30715\n",
      "[252]\tvalid_0's l2: 1.30686\n",
      "[253]\tvalid_0's l2: 1.30614\n",
      "[254]\tvalid_0's l2: 1.30547\n",
      "[255]\tvalid_0's l2: 1.30482\n",
      "[256]\tvalid_0's l2: 1.30455\n",
      "[257]\tvalid_0's l2: 1.3043\n",
      "[258]\tvalid_0's l2: 1.30368\n",
      "[259]\tvalid_0's l2: 1.30349\n",
      "[260]\tvalid_0's l2: 1.30262\n",
      "[261]\tvalid_0's l2: 1.30212\n",
      "[262]\tvalid_0's l2: 1.30187\n",
      "[263]\tvalid_0's l2: 1.30146\n",
      "[264]\tvalid_0's l2: 1.30083\n",
      "[265]\tvalid_0's l2: 1.30062\n",
      "[266]\tvalid_0's l2: 1.30048\n",
      "[267]\tvalid_0's l2: 1.29983\n",
      "[268]\tvalid_0's l2: 1.29966\n",
      "[269]\tvalid_0's l2: 1.29941\n",
      "[270]\tvalid_0's l2: 1.29872\n",
      "[271]\tvalid_0's l2: 1.29814\n",
      "[272]\tvalid_0's l2: 1.29746\n",
      "[273]\tvalid_0's l2: 1.29729\n",
      "[274]\tvalid_0's l2: 1.29712\n",
      "[275]\tvalid_0's l2: 1.2966\n",
      "[276]\tvalid_0's l2: 1.29648\n",
      "[277]\tvalid_0's l2: 1.29618\n",
      "[278]\tvalid_0's l2: 1.29564\n",
      "[279]\tvalid_0's l2: 1.29519\n",
      "[280]\tvalid_0's l2: 1.29466\n",
      "[281]\tvalid_0's l2: 1.29438\n",
      "[282]\tvalid_0's l2: 1.29373\n",
      "[283]\tvalid_0's l2: 1.29297\n",
      "[284]\tvalid_0's l2: 1.29248\n",
      "[285]\tvalid_0's l2: 1.29185\n",
      "[286]\tvalid_0's l2: 1.29145\n",
      "[287]\tvalid_0's l2: 1.29131\n",
      "[288]\tvalid_0's l2: 1.29073\n",
      "[289]\tvalid_0's l2: 1.29021\n",
      "[290]\tvalid_0's l2: 1.29005\n",
      "[291]\tvalid_0's l2: 1.28955\n",
      "[292]\tvalid_0's l2: 1.28926\n",
      "[293]\tvalid_0's l2: 1.28876\n",
      "[294]\tvalid_0's l2: 1.2886\n",
      "[295]\tvalid_0's l2: 1.28805\n",
      "[296]\tvalid_0's l2: 1.28768\n",
      "[297]\tvalid_0's l2: 1.28766\n",
      "[298]\tvalid_0's l2: 1.2871\n",
      "[299]\tvalid_0's l2: 1.28666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's l2: 1.28611\n",
      "[301]\tvalid_0's l2: 1.28575\n",
      "[302]\tvalid_0's l2: 1.28521\n",
      "[303]\tvalid_0's l2: 1.28511\n",
      "[304]\tvalid_0's l2: 1.28466\n",
      "[305]\tvalid_0's l2: 1.28428\n",
      "[306]\tvalid_0's l2: 1.28386\n",
      "[307]\tvalid_0's l2: 1.28356\n",
      "[308]\tvalid_0's l2: 1.28346\n",
      "[309]\tvalid_0's l2: 1.28304\n",
      "[310]\tvalid_0's l2: 1.28254\n",
      "[311]\tvalid_0's l2: 1.28206\n",
      "[312]\tvalid_0's l2: 1.2817\n",
      "[313]\tvalid_0's l2: 1.28143\n",
      "[314]\tvalid_0's l2: 1.28104\n",
      "[315]\tvalid_0's l2: 1.28084\n",
      "[316]\tvalid_0's l2: 1.2804\n",
      "[317]\tvalid_0's l2: 1.28003\n",
      "[318]\tvalid_0's l2: 1.27961\n",
      "[319]\tvalid_0's l2: 1.27921\n",
      "[320]\tvalid_0's l2: 1.27872\n",
      "[321]\tvalid_0's l2: 1.27826\n",
      "[322]\tvalid_0's l2: 1.27789\n",
      "[323]\tvalid_0's l2: 1.27762\n",
      "[324]\tvalid_0's l2: 1.27719\n",
      "[325]\tvalid_0's l2: 1.27693\n",
      "[326]\tvalid_0's l2: 1.27658\n",
      "[327]\tvalid_0's l2: 1.2762\n",
      "[328]\tvalid_0's l2: 1.27579\n",
      "[329]\tvalid_0's l2: 1.27538\n",
      "[330]\tvalid_0's l2: 1.27487\n",
      "[331]\tvalid_0's l2: 1.27458\n",
      "[332]\tvalid_0's l2: 1.27429\n",
      "[333]\tvalid_0's l2: 1.27406\n",
      "[334]\tvalid_0's l2: 1.27388\n",
      "[335]\tvalid_0's l2: 1.27349\n",
      "[336]\tvalid_0's l2: 1.27298\n",
      "[337]\tvalid_0's l2: 1.27288\n",
      "[338]\tvalid_0's l2: 1.27243\n",
      "[339]\tvalid_0's l2: 1.27207\n",
      "[340]\tvalid_0's l2: 1.27177\n",
      "[341]\tvalid_0's l2: 1.27167\n",
      "[342]\tvalid_0's l2: 1.27138\n",
      "[343]\tvalid_0's l2: 1.27123\n",
      "[344]\tvalid_0's l2: 1.27094\n",
      "[345]\tvalid_0's l2: 1.27043\n",
      "[346]\tvalid_0's l2: 1.27\n",
      "[347]\tvalid_0's l2: 1.26973\n",
      "[348]\tvalid_0's l2: 1.26956\n",
      "[349]\tvalid_0's l2: 1.26902\n",
      "[350]\tvalid_0's l2: 1.26856\n",
      "[351]\tvalid_0's l2: 1.26844\n",
      "[352]\tvalid_0's l2: 1.26801\n",
      "[353]\tvalid_0's l2: 1.26785\n",
      "[354]\tvalid_0's l2: 1.2675\n",
      "[355]\tvalid_0's l2: 1.26723\n",
      "[356]\tvalid_0's l2: 1.26718\n",
      "[357]\tvalid_0's l2: 1.2666\n",
      "[358]\tvalid_0's l2: 1.26626\n",
      "[359]\tvalid_0's l2: 1.26623\n",
      "[360]\tvalid_0's l2: 1.26609\n",
      "[361]\tvalid_0's l2: 1.26575\n",
      "[362]\tvalid_0's l2: 1.26526\n",
      "[363]\tvalid_0's l2: 1.26517\n",
      "[364]\tvalid_0's l2: 1.26482\n",
      "[365]\tvalid_0's l2: 1.26426\n",
      "[366]\tvalid_0's l2: 1.26409\n",
      "[367]\tvalid_0's l2: 1.26372\n",
      "[368]\tvalid_0's l2: 1.26334\n",
      "[369]\tvalid_0's l2: 1.26276\n",
      "[370]\tvalid_0's l2: 1.26276\n",
      "[371]\tvalid_0's l2: 1.26266\n",
      "[372]\tvalid_0's l2: 1.26238\n",
      "[373]\tvalid_0's l2: 1.26219\n",
      "[374]\tvalid_0's l2: 1.26159\n",
      "[375]\tvalid_0's l2: 1.2614\n",
      "[376]\tvalid_0's l2: 1.26127\n",
      "[377]\tvalid_0's l2: 1.26098\n",
      "[378]\tvalid_0's l2: 1.26069\n",
      "[379]\tvalid_0's l2: 1.26024\n",
      "[380]\tvalid_0's l2: 1.25975\n",
      "[381]\tvalid_0's l2: 1.25948\n",
      "[382]\tvalid_0's l2: 1.25929\n",
      "[383]\tvalid_0's l2: 1.25925\n",
      "[384]\tvalid_0's l2: 1.25888\n",
      "[385]\tvalid_0's l2: 1.25865\n",
      "[386]\tvalid_0's l2: 1.25855\n",
      "[387]\tvalid_0's l2: 1.25831\n",
      "[388]\tvalid_0's l2: 1.25812\n",
      "[389]\tvalid_0's l2: 1.25806\n",
      "[390]\tvalid_0's l2: 1.25799\n",
      "[391]\tvalid_0's l2: 1.25748\n",
      "[392]\tvalid_0's l2: 1.25721\n",
      "[393]\tvalid_0's l2: 1.25718\n",
      "[394]\tvalid_0's l2: 1.25696\n",
      "[395]\tvalid_0's l2: 1.2568\n",
      "[396]\tvalid_0's l2: 1.25648\n",
      "[397]\tvalid_0's l2: 1.25638\n",
      "[398]\tvalid_0's l2: 1.25611\n",
      "[399]\tvalid_0's l2: 1.25583\n",
      "[400]\tvalid_0's l2: 1.25556\n",
      "[401]\tvalid_0's l2: 1.25537\n",
      "[402]\tvalid_0's l2: 1.25501\n",
      "[403]\tvalid_0's l2: 1.25489\n",
      "[404]\tvalid_0's l2: 1.25475\n",
      "[405]\tvalid_0's l2: 1.2546\n",
      "[406]\tvalid_0's l2: 1.25441\n",
      "[407]\tvalid_0's l2: 1.25419\n",
      "[408]\tvalid_0's l2: 1.25398\n",
      "[409]\tvalid_0's l2: 1.25363\n",
      "[410]\tvalid_0's l2: 1.25332\n",
      "[411]\tvalid_0's l2: 1.25314\n",
      "[412]\tvalid_0's l2: 1.25274\n",
      "[413]\tvalid_0's l2: 1.25241\n",
      "[414]\tvalid_0's l2: 1.25222\n",
      "[415]\tvalid_0's l2: 1.25209\n",
      "[416]\tvalid_0's l2: 1.25179\n",
      "[417]\tvalid_0's l2: 1.25156\n",
      "[418]\tvalid_0's l2: 1.25123\n",
      "[419]\tvalid_0's l2: 1.25099\n",
      "[420]\tvalid_0's l2: 1.25068\n",
      "[421]\tvalid_0's l2: 1.25051\n",
      "[422]\tvalid_0's l2: 1.25022\n",
      "[423]\tvalid_0's l2: 1.24992\n",
      "[424]\tvalid_0's l2: 1.24956\n",
      "[425]\tvalid_0's l2: 1.24928\n",
      "[426]\tvalid_0's l2: 1.24921\n",
      "[427]\tvalid_0's l2: 1.24891\n",
      "[428]\tvalid_0's l2: 1.24853\n",
      "[429]\tvalid_0's l2: 1.24848\n",
      "[430]\tvalid_0's l2: 1.24815\n",
      "[431]\tvalid_0's l2: 1.24802\n",
      "[432]\tvalid_0's l2: 1.24771\n",
      "[433]\tvalid_0's l2: 1.24757\n",
      "[434]\tvalid_0's l2: 1.24753\n",
      "[435]\tvalid_0's l2: 1.24736\n",
      "[436]\tvalid_0's l2: 1.24704\n",
      "[437]\tvalid_0's l2: 1.24679\n",
      "[438]\tvalid_0's l2: 1.24652\n",
      "[439]\tvalid_0's l2: 1.24614\n",
      "[440]\tvalid_0's l2: 1.24598\n",
      "[441]\tvalid_0's l2: 1.24585\n",
      "[442]\tvalid_0's l2: 1.24572\n",
      "[443]\tvalid_0's l2: 1.24541\n",
      "[444]\tvalid_0's l2: 1.24519\n",
      "[445]\tvalid_0's l2: 1.24512\n",
      "[446]\tvalid_0's l2: 1.24495\n",
      "[447]\tvalid_0's l2: 1.24483\n",
      "[448]\tvalid_0's l2: 1.24458\n",
      "[449]\tvalid_0's l2: 1.24438\n",
      "[450]\tvalid_0's l2: 1.24397\n",
      "[451]\tvalid_0's l2: 1.24354\n",
      "[452]\tvalid_0's l2: 1.24344\n",
      "[453]\tvalid_0's l2: 1.24341\n",
      "[454]\tvalid_0's l2: 1.24312\n",
      "[455]\tvalid_0's l2: 1.24306\n",
      "[456]\tvalid_0's l2: 1.24296\n",
      "[457]\tvalid_0's l2: 1.243\n",
      "[458]\tvalid_0's l2: 1.24276\n",
      "[459]\tvalid_0's l2: 1.24269\n",
      "[460]\tvalid_0's l2: 1.24253\n",
      "[461]\tvalid_0's l2: 1.24229\n",
      "[462]\tvalid_0's l2: 1.24199\n",
      "[463]\tvalid_0's l2: 1.24192\n",
      "[464]\tvalid_0's l2: 1.24191\n",
      "[465]\tvalid_0's l2: 1.24184\n",
      "[466]\tvalid_0's l2: 1.24167\n",
      "[467]\tvalid_0's l2: 1.24134\n",
      "[468]\tvalid_0's l2: 1.241\n",
      "[469]\tvalid_0's l2: 1.24083\n",
      "[470]\tvalid_0's l2: 1.24045\n",
      "[471]\tvalid_0's l2: 1.24031\n",
      "[472]\tvalid_0's l2: 1.24034\n",
      "[473]\tvalid_0's l2: 1.24004\n",
      "[474]\tvalid_0's l2: 1.23977\n",
      "[475]\tvalid_0's l2: 1.23968\n",
      "[476]\tvalid_0's l2: 1.23961\n",
      "[477]\tvalid_0's l2: 1.23937\n",
      "[478]\tvalid_0's l2: 1.23921\n",
      "[479]\tvalid_0's l2: 1.23908\n",
      "[480]\tvalid_0's l2: 1.23882\n",
      "[481]\tvalid_0's l2: 1.23864\n",
      "[482]\tvalid_0's l2: 1.23852\n",
      "[483]\tvalid_0's l2: 1.23829\n",
      "[484]\tvalid_0's l2: 1.23829\n",
      "[485]\tvalid_0's l2: 1.23815\n",
      "[486]\tvalid_0's l2: 1.23796\n",
      "[487]\tvalid_0's l2: 1.23769\n",
      "[488]\tvalid_0's l2: 1.23751\n",
      "[489]\tvalid_0's l2: 1.23725\n",
      "[490]\tvalid_0's l2: 1.23708\n",
      "[491]\tvalid_0's l2: 1.2371\n",
      "[492]\tvalid_0's l2: 1.23706\n",
      "[493]\tvalid_0's l2: 1.23685\n",
      "[494]\tvalid_0's l2: 1.23668\n",
      "[495]\tvalid_0's l2: 1.23648\n",
      "[496]\tvalid_0's l2: 1.23623\n",
      "[497]\tvalid_0's l2: 1.23602\n",
      "[498]\tvalid_0's l2: 1.23591\n",
      "[499]\tvalid_0's l2: 1.23576\n",
      "[500]\tvalid_0's l2: 1.23551\n",
      "[501]\tvalid_0's l2: 1.23539\n",
      "[502]\tvalid_0's l2: 1.23518\n",
      "[503]\tvalid_0's l2: 1.23493\n",
      "[504]\tvalid_0's l2: 1.23469\n",
      "[505]\tvalid_0's l2: 1.23458\n",
      "[506]\tvalid_0's l2: 1.23444\n",
      "[507]\tvalid_0's l2: 1.23421\n",
      "[508]\tvalid_0's l2: 1.23413\n",
      "[509]\tvalid_0's l2: 1.23399\n",
      "[510]\tvalid_0's l2: 1.23398\n",
      "[511]\tvalid_0's l2: 1.23387\n",
      "[512]\tvalid_0's l2: 1.23361\n",
      "[513]\tvalid_0's l2: 1.23354\n",
      "[514]\tvalid_0's l2: 1.23348\n",
      "[515]\tvalid_0's l2: 1.23326\n",
      "[516]\tvalid_0's l2: 1.23303\n",
      "[517]\tvalid_0's l2: 1.23297\n",
      "[518]\tvalid_0's l2: 1.23287\n",
      "[519]\tvalid_0's l2: 1.2327\n",
      "[520]\tvalid_0's l2: 1.23254\n",
      "[521]\tvalid_0's l2: 1.23245\n",
      "[522]\tvalid_0's l2: 1.23242\n",
      "[523]\tvalid_0's l2: 1.23231\n",
      "[524]\tvalid_0's l2: 1.2321\n",
      "[525]\tvalid_0's l2: 1.23205\n",
      "[526]\tvalid_0's l2: 1.23194\n",
      "[527]\tvalid_0's l2: 1.23184\n",
      "[528]\tvalid_0's l2: 1.23173\n",
      "[529]\tvalid_0's l2: 1.23166\n",
      "[530]\tvalid_0's l2: 1.23155\n",
      "[531]\tvalid_0's l2: 1.2315\n",
      "[532]\tvalid_0's l2: 1.2314\n",
      "[533]\tvalid_0's l2: 1.23113\n",
      "[534]\tvalid_0's l2: 1.2311\n",
      "[535]\tvalid_0's l2: 1.23093\n",
      "[536]\tvalid_0's l2: 1.23073\n",
      "[537]\tvalid_0's l2: 1.23059\n",
      "[538]\tvalid_0's l2: 1.23047\n",
      "[539]\tvalid_0's l2: 1.2304\n",
      "[540]\tvalid_0's l2: 1.2303\n",
      "[541]\tvalid_0's l2: 1.23009\n",
      "[542]\tvalid_0's l2: 1.2299\n",
      "[543]\tvalid_0's l2: 1.22982\n",
      "[544]\tvalid_0's l2: 1.22977\n",
      "[545]\tvalid_0's l2: 1.22967\n",
      "[546]\tvalid_0's l2: 1.22952\n",
      "[547]\tvalid_0's l2: 1.22935\n",
      "[548]\tvalid_0's l2: 1.22915\n",
      "[549]\tvalid_0's l2: 1.22902\n",
      "[550]\tvalid_0's l2: 1.22892\n",
      "[551]\tvalid_0's l2: 1.22873\n",
      "[552]\tvalid_0's l2: 1.2286\n",
      "[553]\tvalid_0's l2: 1.22841\n",
      "[554]\tvalid_0's l2: 1.22831\n",
      "[555]\tvalid_0's l2: 1.2282\n",
      "[556]\tvalid_0's l2: 1.22801\n",
      "[557]\tvalid_0's l2: 1.22792\n",
      "[558]\tvalid_0's l2: 1.22773\n",
      "[559]\tvalid_0's l2: 1.22768\n",
      "[560]\tvalid_0's l2: 1.22762\n",
      "[561]\tvalid_0's l2: 1.22745\n",
      "[562]\tvalid_0's l2: 1.22726\n",
      "[563]\tvalid_0's l2: 1.22714\n",
      "[564]\tvalid_0's l2: 1.22685\n",
      "[565]\tvalid_0's l2: 1.22677\n",
      "[566]\tvalid_0's l2: 1.22679\n",
      "[567]\tvalid_0's l2: 1.22673\n",
      "[568]\tvalid_0's l2: 1.22666\n",
      "[569]\tvalid_0's l2: 1.22669\n",
      "[570]\tvalid_0's l2: 1.22633\n",
      "[571]\tvalid_0's l2: 1.22619\n",
      "[572]\tvalid_0's l2: 1.22596\n",
      "[573]\tvalid_0's l2: 1.22597\n",
      "[574]\tvalid_0's l2: 1.22593\n",
      "[575]\tvalid_0's l2: 1.22592\n",
      "[576]\tvalid_0's l2: 1.22584\n",
      "[577]\tvalid_0's l2: 1.2258\n",
      "[578]\tvalid_0's l2: 1.22586\n",
      "[579]\tvalid_0's l2: 1.22574\n",
      "[580]\tvalid_0's l2: 1.22549\n",
      "[581]\tvalid_0's l2: 1.22542\n",
      "[582]\tvalid_0's l2: 1.22525\n",
      "[583]\tvalid_0's l2: 1.22515\n",
      "[584]\tvalid_0's l2: 1.22512\n",
      "[585]\tvalid_0's l2: 1.22481\n",
      "[586]\tvalid_0's l2: 1.22477\n",
      "[587]\tvalid_0's l2: 1.22448\n",
      "[588]\tvalid_0's l2: 1.22444\n",
      "[589]\tvalid_0's l2: 1.22436\n",
      "[590]\tvalid_0's l2: 1.22432\n",
      "[591]\tvalid_0's l2: 1.22438\n",
      "[592]\tvalid_0's l2: 1.22431\n",
      "[593]\tvalid_0's l2: 1.22407\n",
      "[594]\tvalid_0's l2: 1.2239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[595]\tvalid_0's l2: 1.22359\n",
      "[596]\tvalid_0's l2: 1.2235\n",
      "[597]\tvalid_0's l2: 1.22349\n",
      "[598]\tvalid_0's l2: 1.22329\n",
      "[599]\tvalid_0's l2: 1.22317\n",
      "[600]\tvalid_0's l2: 1.22309\n",
      "[601]\tvalid_0's l2: 1.22296\n",
      "[602]\tvalid_0's l2: 1.22275\n",
      "[603]\tvalid_0's l2: 1.22258\n",
      "[604]\tvalid_0's l2: 1.22254\n",
      "[605]\tvalid_0's l2: 1.22244\n",
      "[606]\tvalid_0's l2: 1.22236\n",
      "[607]\tvalid_0's l2: 1.22214\n",
      "[608]\tvalid_0's l2: 1.22216\n",
      "[609]\tvalid_0's l2: 1.22194\n",
      "[610]\tvalid_0's l2: 1.22189\n",
      "[611]\tvalid_0's l2: 1.22177\n",
      "[612]\tvalid_0's l2: 1.22166\n",
      "[613]\tvalid_0's l2: 1.2217\n",
      "[614]\tvalid_0's l2: 1.22161\n",
      "[615]\tvalid_0's l2: 1.22146\n",
      "[616]\tvalid_0's l2: 1.22128\n",
      "[617]\tvalid_0's l2: 1.22127\n",
      "[618]\tvalid_0's l2: 1.22122\n",
      "[619]\tvalid_0's l2: 1.22122\n",
      "[620]\tvalid_0's l2: 1.22112\n",
      "[621]\tvalid_0's l2: 1.22104\n",
      "[622]\tvalid_0's l2: 1.22092\n",
      "[623]\tvalid_0's l2: 1.22075\n",
      "[624]\tvalid_0's l2: 1.22077\n",
      "[625]\tvalid_0's l2: 1.22064\n",
      "[626]\tvalid_0's l2: 1.22037\n",
      "[627]\tvalid_0's l2: 1.22029\n",
      "[628]\tvalid_0's l2: 1.22025\n",
      "[629]\tvalid_0's l2: 1.22023\n",
      "[630]\tvalid_0's l2: 1.22025\n",
      "[631]\tvalid_0's l2: 1.2202\n",
      "[632]\tvalid_0's l2: 1.22008\n",
      "[633]\tvalid_0's l2: 1.21993\n",
      "[634]\tvalid_0's l2: 1.21975\n",
      "[635]\tvalid_0's l2: 1.21963\n",
      "[636]\tvalid_0's l2: 1.21948\n",
      "[637]\tvalid_0's l2: 1.21951\n",
      "[638]\tvalid_0's l2: 1.21932\n",
      "[639]\tvalid_0's l2: 1.21918\n",
      "[640]\tvalid_0's l2: 1.21918\n",
      "[641]\tvalid_0's l2: 1.21921\n",
      "[642]\tvalid_0's l2: 1.2191\n",
      "[643]\tvalid_0's l2: 1.21904\n",
      "[644]\tvalid_0's l2: 1.21898\n",
      "[645]\tvalid_0's l2: 1.21881\n",
      "[646]\tvalid_0's l2: 1.21863\n",
      "[647]\tvalid_0's l2: 1.21859\n",
      "[648]\tvalid_0's l2: 1.21856\n",
      "[649]\tvalid_0's l2: 1.21854\n",
      "[650]\tvalid_0's l2: 1.21839\n",
      "[651]\tvalid_0's l2: 1.21838\n",
      "[652]\tvalid_0's l2: 1.21829\n",
      "[653]\tvalid_0's l2: 1.21827\n",
      "[654]\tvalid_0's l2: 1.21824\n",
      "[655]\tvalid_0's l2: 1.21816\n",
      "[656]\tvalid_0's l2: 1.21804\n",
      "[657]\tvalid_0's l2: 1.21796\n",
      "[658]\tvalid_0's l2: 1.21791\n",
      "[659]\tvalid_0's l2: 1.2179\n",
      "[660]\tvalid_0's l2: 1.2178\n",
      "[661]\tvalid_0's l2: 1.21773\n",
      "[662]\tvalid_0's l2: 1.21756\n",
      "[663]\tvalid_0's l2: 1.21742\n",
      "[664]\tvalid_0's l2: 1.21725\n",
      "[665]\tvalid_0's l2: 1.21705\n",
      "[666]\tvalid_0's l2: 1.21687\n",
      "[667]\tvalid_0's l2: 1.21675\n",
      "[668]\tvalid_0's l2: 1.21667\n",
      "[669]\tvalid_0's l2: 1.21649\n",
      "[670]\tvalid_0's l2: 1.2164\n",
      "[671]\tvalid_0's l2: 1.21635\n",
      "[672]\tvalid_0's l2: 1.21618\n",
      "[673]\tvalid_0's l2: 1.21618\n",
      "[674]\tvalid_0's l2: 1.21614\n",
      "[675]\tvalid_0's l2: 1.216\n",
      "[676]\tvalid_0's l2: 1.21594\n",
      "[677]\tvalid_0's l2: 1.21578\n",
      "[678]\tvalid_0's l2: 1.21573\n",
      "[679]\tvalid_0's l2: 1.21579\n",
      "[680]\tvalid_0's l2: 1.21562\n",
      "[681]\tvalid_0's l2: 1.21547\n",
      "[682]\tvalid_0's l2: 1.21545\n",
      "[683]\tvalid_0's l2: 1.21529\n",
      "[684]\tvalid_0's l2: 1.21513\n",
      "[685]\tvalid_0's l2: 1.21504\n",
      "[686]\tvalid_0's l2: 1.21497\n",
      "[687]\tvalid_0's l2: 1.21497\n",
      "[688]\tvalid_0's l2: 1.21499\n",
      "[689]\tvalid_0's l2: 1.21495\n",
      "[690]\tvalid_0's l2: 1.21481\n",
      "[691]\tvalid_0's l2: 1.21463\n",
      "[692]\tvalid_0's l2: 1.21444\n",
      "[693]\tvalid_0's l2: 1.21448\n",
      "[694]\tvalid_0's l2: 1.21426\n",
      "[695]\tvalid_0's l2: 1.21425\n",
      "[696]\tvalid_0's l2: 1.2141\n",
      "[697]\tvalid_0's l2: 1.21408\n",
      "[698]\tvalid_0's l2: 1.21402\n",
      "[699]\tvalid_0's l2: 1.21391\n",
      "[700]\tvalid_0's l2: 1.21376\n",
      "[701]\tvalid_0's l2: 1.21361\n",
      "[702]\tvalid_0's l2: 1.21362\n",
      "[703]\tvalid_0's l2: 1.21356\n",
      "[704]\tvalid_0's l2: 1.21355\n",
      "[705]\tvalid_0's l2: 1.21343\n",
      "[706]\tvalid_0's l2: 1.21322\n",
      "[707]\tvalid_0's l2: 1.21305\n",
      "[708]\tvalid_0's l2: 1.21282\n",
      "[709]\tvalid_0's l2: 1.21276\n",
      "[710]\tvalid_0's l2: 1.21272\n",
      "[711]\tvalid_0's l2: 1.2127\n",
      "[712]\tvalid_0's l2: 1.21261\n",
      "[713]\tvalid_0's l2: 1.21253\n",
      "[714]\tvalid_0's l2: 1.21257\n",
      "[715]\tvalid_0's l2: 1.21246\n",
      "[716]\tvalid_0's l2: 1.21233\n",
      "[717]\tvalid_0's l2: 1.21231\n",
      "[718]\tvalid_0's l2: 1.21219\n",
      "[719]\tvalid_0's l2: 1.21219\n",
      "[720]\tvalid_0's l2: 1.21217\n",
      "[721]\tvalid_0's l2: 1.21216\n",
      "[722]\tvalid_0's l2: 1.21207\n",
      "[723]\tvalid_0's l2: 1.21195\n",
      "[724]\tvalid_0's l2: 1.21175\n",
      "[725]\tvalid_0's l2: 1.21173\n",
      "[726]\tvalid_0's l2: 1.21172\n",
      "[727]\tvalid_0's l2: 1.2116\n",
      "[728]\tvalid_0's l2: 1.21137\n",
      "[729]\tvalid_0's l2: 1.21137\n",
      "[730]\tvalid_0's l2: 1.21133\n",
      "[731]\tvalid_0's l2: 1.21137\n",
      "[732]\tvalid_0's l2: 1.21123\n",
      "[733]\tvalid_0's l2: 1.21093\n",
      "[734]\tvalid_0's l2: 1.21086\n",
      "[735]\tvalid_0's l2: 1.21074\n",
      "[736]\tvalid_0's l2: 1.21066\n",
      "[737]\tvalid_0's l2: 1.21067\n",
      "[738]\tvalid_0's l2: 1.2106\n",
      "[739]\tvalid_0's l2: 1.21052\n",
      "[740]\tvalid_0's l2: 1.21028\n",
      "[741]\tvalid_0's l2: 1.21007\n",
      "[742]\tvalid_0's l2: 1.20984\n",
      "[743]\tvalid_0's l2: 1.20982\n",
      "[744]\tvalid_0's l2: 1.20979\n",
      "[745]\tvalid_0's l2: 1.20971\n",
      "[746]\tvalid_0's l2: 1.20972\n",
      "[747]\tvalid_0's l2: 1.20968\n",
      "[748]\tvalid_0's l2: 1.20973\n",
      "[749]\tvalid_0's l2: 1.20961\n",
      "[750]\tvalid_0's l2: 1.20952\n",
      "[751]\tvalid_0's l2: 1.20935\n",
      "[752]\tvalid_0's l2: 1.20926\n",
      "[753]\tvalid_0's l2: 1.20911\n",
      "[754]\tvalid_0's l2: 1.2091\n",
      "[755]\tvalid_0's l2: 1.20902\n",
      "[756]\tvalid_0's l2: 1.2089\n",
      "[757]\tvalid_0's l2: 1.20881\n",
      "[758]\tvalid_0's l2: 1.20879\n",
      "[759]\tvalid_0's l2: 1.20873\n",
      "[760]\tvalid_0's l2: 1.20863\n",
      "[761]\tvalid_0's l2: 1.20854\n",
      "[762]\tvalid_0's l2: 1.20851\n",
      "[763]\tvalid_0's l2: 1.20843\n",
      "[764]\tvalid_0's l2: 1.20841\n",
      "[765]\tvalid_0's l2: 1.20838\n",
      "[766]\tvalid_0's l2: 1.20835\n",
      "[767]\tvalid_0's l2: 1.20827\n",
      "[768]\tvalid_0's l2: 1.20813\n",
      "[769]\tvalid_0's l2: 1.208\n",
      "[770]\tvalid_0's l2: 1.20796\n",
      "[771]\tvalid_0's l2: 1.20795\n",
      "[772]\tvalid_0's l2: 1.20794\n",
      "[773]\tvalid_0's l2: 1.20787\n",
      "[774]\tvalid_0's l2: 1.20777\n",
      "[775]\tvalid_0's l2: 1.20767\n",
      "[776]\tvalid_0's l2: 1.20762\n",
      "[777]\tvalid_0's l2: 1.20754\n",
      "[778]\tvalid_0's l2: 1.20746\n",
      "[779]\tvalid_0's l2: 1.20738\n",
      "[780]\tvalid_0's l2: 1.20734\n",
      "[781]\tvalid_0's l2: 1.20722\n",
      "[782]\tvalid_0's l2: 1.20711\n",
      "[783]\tvalid_0's l2: 1.20707\n",
      "[784]\tvalid_0's l2: 1.20709\n",
      "[785]\tvalid_0's l2: 1.207\n",
      "[786]\tvalid_0's l2: 1.20693\n",
      "[787]\tvalid_0's l2: 1.2069\n",
      "[788]\tvalid_0's l2: 1.20687\n",
      "[789]\tvalid_0's l2: 1.2068\n",
      "[790]\tvalid_0's l2: 1.20672\n",
      "[791]\tvalid_0's l2: 1.2067\n",
      "[792]\tvalid_0's l2: 1.20658\n",
      "[793]\tvalid_0's l2: 1.20651\n",
      "[794]\tvalid_0's l2: 1.20636\n",
      "[795]\tvalid_0's l2: 1.20625\n",
      "[796]\tvalid_0's l2: 1.20606\n",
      "[797]\tvalid_0's l2: 1.20602\n",
      "[798]\tvalid_0's l2: 1.20594\n",
      "[799]\tvalid_0's l2: 1.20576\n",
      "[800]\tvalid_0's l2: 1.20574\n",
      "[801]\tvalid_0's l2: 1.2058\n",
      "[802]\tvalid_0's l2: 1.20575\n",
      "[803]\tvalid_0's l2: 1.20547\n",
      "[804]\tvalid_0's l2: 1.20538\n",
      "[805]\tvalid_0's l2: 1.20519\n",
      "[806]\tvalid_0's l2: 1.20518\n",
      "[807]\tvalid_0's l2: 1.20497\n",
      "[808]\tvalid_0's l2: 1.20489\n",
      "[809]\tvalid_0's l2: 1.20468\n",
      "[810]\tvalid_0's l2: 1.20464\n",
      "[811]\tvalid_0's l2: 1.20456\n",
      "[812]\tvalid_0's l2: 1.20442\n",
      "[813]\tvalid_0's l2: 1.20434\n",
      "[814]\tvalid_0's l2: 1.20419\n",
      "[815]\tvalid_0's l2: 1.204\n",
      "[816]\tvalid_0's l2: 1.20382\n",
      "[817]\tvalid_0's l2: 1.20367\n",
      "[818]\tvalid_0's l2: 1.20338\n",
      "[819]\tvalid_0's l2: 1.20319\n",
      "[820]\tvalid_0's l2: 1.20306\n",
      "[821]\tvalid_0's l2: 1.20303\n",
      "[822]\tvalid_0's l2: 1.20286\n",
      "[823]\tvalid_0's l2: 1.20277\n",
      "[824]\tvalid_0's l2: 1.20269\n",
      "[825]\tvalid_0's l2: 1.20264\n",
      "[826]\tvalid_0's l2: 1.20261\n",
      "[827]\tvalid_0's l2: 1.20254\n",
      "[828]\tvalid_0's l2: 1.20242\n",
      "[829]\tvalid_0's l2: 1.20228\n",
      "[830]\tvalid_0's l2: 1.20218\n",
      "[831]\tvalid_0's l2: 1.20217\n",
      "[832]\tvalid_0's l2: 1.20197\n",
      "[833]\tvalid_0's l2: 1.20186\n",
      "[834]\tvalid_0's l2: 1.20175\n",
      "[835]\tvalid_0's l2: 1.20174\n",
      "[836]\tvalid_0's l2: 1.20158\n",
      "[837]\tvalid_0's l2: 1.2015\n",
      "[838]\tvalid_0's l2: 1.2014\n",
      "[839]\tvalid_0's l2: 1.20128\n",
      "[840]\tvalid_0's l2: 1.20124\n",
      "[841]\tvalid_0's l2: 1.20113\n",
      "[842]\tvalid_0's l2: 1.20102\n",
      "[843]\tvalid_0's l2: 1.20096\n",
      "[844]\tvalid_0's l2: 1.20083\n",
      "[845]\tvalid_0's l2: 1.20074\n",
      "[846]\tvalid_0's l2: 1.20046\n",
      "[847]\tvalid_0's l2: 1.20032\n",
      "[848]\tvalid_0's l2: 1.20041\n",
      "[849]\tvalid_0's l2: 1.20038\n",
      "[850]\tvalid_0's l2: 1.20028\n",
      "[851]\tvalid_0's l2: 1.20023\n",
      "[852]\tvalid_0's l2: 1.20006\n",
      "[853]\tvalid_0's l2: 1.2\n",
      "[854]\tvalid_0's l2: 1.19988\n",
      "[855]\tvalid_0's l2: 1.19989\n",
      "[856]\tvalid_0's l2: 1.19986\n",
      "[857]\tvalid_0's l2: 1.19981\n",
      "[858]\tvalid_0's l2: 1.19989\n",
      "[859]\tvalid_0's l2: 1.19993\n",
      "[860]\tvalid_0's l2: 1.19992\n",
      "[861]\tvalid_0's l2: 1.19977\n",
      "[862]\tvalid_0's l2: 1.19957\n",
      "[863]\tvalid_0's l2: 1.19949\n",
      "[864]\tvalid_0's l2: 1.19934\n",
      "[865]\tvalid_0's l2: 1.19934\n",
      "[866]\tvalid_0's l2: 1.19927\n",
      "[867]\tvalid_0's l2: 1.19915\n",
      "[868]\tvalid_0's l2: 1.19892\n",
      "[869]\tvalid_0's l2: 1.19893\n",
      "[870]\tvalid_0's l2: 1.19882\n",
      "[871]\tvalid_0's l2: 1.19878\n",
      "[872]\tvalid_0's l2: 1.19866\n",
      "[873]\tvalid_0's l2: 1.19861\n",
      "[874]\tvalid_0's l2: 1.19859\n",
      "[875]\tvalid_0's l2: 1.19848\n",
      "[876]\tvalid_0's l2: 1.19847\n",
      "[877]\tvalid_0's l2: 1.19851\n",
      "[878]\tvalid_0's l2: 1.19843\n",
      "[879]\tvalid_0's l2: 1.19834\n",
      "[880]\tvalid_0's l2: 1.19829\n",
      "[881]\tvalid_0's l2: 1.19817\n",
      "[882]\tvalid_0's l2: 1.19808\n",
      "[883]\tvalid_0's l2: 1.19785\n",
      "[884]\tvalid_0's l2: 1.19776\n",
      "[885]\tvalid_0's l2: 1.19759\n",
      "[886]\tvalid_0's l2: 1.19765\n",
      "[887]\tvalid_0's l2: 1.19757\n",
      "[888]\tvalid_0's l2: 1.19754\n",
      "[889]\tvalid_0's l2: 1.19756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[890]\tvalid_0's l2: 1.19749\n",
      "[891]\tvalid_0's l2: 1.19753\n",
      "[892]\tvalid_0's l2: 1.19752\n",
      "[893]\tvalid_0's l2: 1.19738\n",
      "[894]\tvalid_0's l2: 1.19736\n",
      "[895]\tvalid_0's l2: 1.19724\n",
      "[896]\tvalid_0's l2: 1.19716\n",
      "[897]\tvalid_0's l2: 1.19723\n",
      "[898]\tvalid_0's l2: 1.19708\n",
      "[899]\tvalid_0's l2: 1.19699\n",
      "[900]\tvalid_0's l2: 1.19693\n",
      "[901]\tvalid_0's l2: 1.19693\n",
      "[902]\tvalid_0's l2: 1.19674\n",
      "[903]\tvalid_0's l2: 1.1968\n",
      "[904]\tvalid_0's l2: 1.19677\n",
      "[905]\tvalid_0's l2: 1.19679\n",
      "[906]\tvalid_0's l2: 1.19678\n",
      "[907]\tvalid_0's l2: 1.19681\n",
      "Early stopping, best iteration is:\n",
      "[902]\tvalid_0's l2: 1.19674\n"
     ]
    }
   ],
   "source": [
    "lc=lightgbm.train(params,ldata,num_boost_round=10000,early_stopping_rounds=5,valid_sets=tdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'valid_0': {'l2': 1.1967373599770301}})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.    ,  2.    ,  1.    , ...,  0.    ,  0.    ,  0.    ],\n",
       "       [ 5.    ,  5.    ,  3.    , ...,  3.    ,  5.    ,  5.    ],\n",
       "       [ 3.    ,  4.    ,  5.    , ...,  4.    ,  5.    ,  5.    ],\n",
       "       ..., \n",
       "       [ 3.24  ,  4.0184,  3.8112, ...,  3.4592,  4.3496,  4.5688],\n",
       "       [ 5.    ,  5.    ,  3.    , ...,  5.    ,  4.    ,  5.    ],\n",
       "       [ 5.    ,  3.    ,  5.    , ...,  5.    ,  4.    ,  5.    ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tester=np.hstack((X_test_ww,stack_test.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1921321425670626"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(y_test,lc.predict(tester))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xdata=xgboost.DMatrix(X_FIRST_LEVEL_TRAIN,label=y_train)\n",
    "xtdata=xgboost.DMatrix(tester,label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params={\"eta\":0.1,\n",
    "        \"metrics\":\"rmse\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-0f027a17a3b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    405\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 827\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    828\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xd=xgboost.cv(params,xdata,num_boost_round=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist  = [(xtdata,'eval'), (xdata,'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "\n",
    "    cv_result = xgboost.cv(params, xgtrain, num_boost_round=200, nfold=5,\n",
    "             seed=random_state,\n",
    "             callbacks=[xgboost.callback.early_stop(5)])\n",
    "\n",
    "    return -cv_result['test-rmse-mean'].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_rounds = 3000\n",
    "random_state = 42\n",
    "num_iter = 300\n",
    "init_points = 25\n",
    "params = {\n",
    "        'eta': 0.1,\n",
    "        'silent': 1,\n",
    "        'eval_metric': 'rmse',\n",
    "        'verbose_eval': True,\n",
    "        'min_child_weight': 11.2527,\n",
    "        'colsample_bytree': 0.5840,\n",
    "        'max_depth': 12,\n",
    "        'subsample': 0.9554,\n",
    "        'gamma':  0.1783 ,\n",
    "        'alpha': 2.0978,\n",
    "        'seed': random_state\n",
    "    \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbBO = bayes_opt.BayesianOptimization(xgb_evaluate, {'min_child_weight': (1, 20),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'max_depth': (5, 15),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'gamma': (0, 10),\n",
    "                                                'alpha': (0, 10),\n",
    "                                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[127]\ttrain-rmse:0.513395+0.00415347\ttest-rmse:0.965234+0.00912206\n",
      "\n",
      "    1 | 02m42s | \u001b[35m  -0.96523\u001b[0m | \u001b[32m   1.6933\u001b[0m | \u001b[32m            0.8589\u001b[0m | \u001b[32m   5.7365\u001b[0m | \u001b[32m    12.2686\u001b[0m | \u001b[32m            2.7906\u001b[0m | \u001b[32m     0.8007\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[88]\ttrain-rmse:0.579709+0.00155446\ttest-rmse:0.953699+0.00884863\n",
      "\n",
      "    2 | 02m12s | \u001b[35m  -0.95370\u001b[0m | \u001b[32m   8.3199\u001b[0m | \u001b[32m            0.5329\u001b[0m | \u001b[32m   4.4481\u001b[0m | \u001b[32m    12.0786\u001b[0m | \u001b[32m           13.0416\u001b[0m | \u001b[32m     0.9369\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[83]\ttrain-rmse:0.744375+0.00257607\ttest-rmse:0.955535+0.00868269\n",
      "\n",
      "    3 | 00m42s |   -0.95554 |    5.7185 |             0.2854 |    6.6849 |      6.5330 |             6.4410 |      0.5599 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[71]\ttrain-rmse:0.649697+0.00154352\ttest-rmse:0.957602+0.0109492\n",
      "\n",
      "    4 | 01m10s |   -0.95760 |    5.8389 |             0.8456 |    6.2992 |     14.1475 |            15.5206 |      0.7255 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[113]\ttrain-rmse:0.662063+0.00237738\ttest-rmse:0.949496+0.00793884\n",
      "\n",
      "    5 | 00m57s | \u001b[35m  -0.94950\u001b[0m | \u001b[32m   2.0978\u001b[0m | \u001b[32m            0.5840\u001b[0m | \u001b[32m   0.1783\u001b[0m | \u001b[32m     5.6441\u001b[0m | \u001b[32m           11.2527\u001b[0m | \u001b[32m     0.9554\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-rmse:0.709412+0.00224087\ttest-rmse:0.954274+0.0120495\n",
      "\n",
      "    6 | 00m44s |   -0.95427 |    0.7411 |             0.2377 |    5.4116 |      5.5504 |             3.4517 |      0.9072 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[82]\ttrain-rmse:0.633668+0.00262922\ttest-rmse:0.953864+0.00769991\n",
      "\n",
      "    7 | 00m43s |   -0.95386 |    4.6472 |             0.5550 |    0.8849 |      6.8735 |            11.0039 |      0.7598 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n",
      "Stopping. Best iteration:\n",
      "[93]\ttrain-rmse:0.262585+0.000691581\ttest-rmse:0.970856+0.00990197\n",
      "\n",
      "    8 | 01m51s |   -0.97086 |    6.1561 |             0.4719 |    0.2638 |     14.0946 |             8.5190 |      0.8858 | \n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 5 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-9566b33ca0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgbBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, init_points)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0my_init\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-bc2388eda7ce>\u001b[0m in \u001b[0;36mxgb_evaluate\u001b[0;34m(min_child_weight, colsample_bytree, max_depth, subsample, gamma, alpha)\u001b[0m\n\u001b[1;32m     16\u001b[0m     cv_result = xgboost.cv(params, xgtrain, num_boost_round=200, nfold=5,\n\u001b[1;32m     17\u001b[0m              \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m              callbacks=[xgboost.callback.early_stop(5)])\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test-rmse-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    405\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 827\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    828\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgtrain=xdata\n",
    "xgbBO.maximize(init_points=100, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:3.46138\ttrain-rmse:3.4899\n",
      "Multiple eval metrics have been passed: 'train-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmse hasn't improved in 10 rounds.\n",
      "[1]\teval-rmse:3.15253\ttrain-rmse:3.17054\n",
      "[2]\teval-rmse:2.84725\ttrain-rmse:2.88048\n",
      "[3]\teval-rmse:2.57189\ttrain-rmse:2.6209\n",
      "[4]\teval-rmse:2.33177\ttrain-rmse:2.38804\n",
      "[5]\teval-rmse:2.1183\ttrain-rmse:2.18082\n",
      "[6]\teval-rmse:1.93344\ttrain-rmse:1.9941\n",
      "[7]\teval-rmse:1.78998\ttrain-rmse:1.82849\n",
      "[8]\teval-rmse:1.66393\ttrain-rmse:1.68082\n",
      "[9]\teval-rmse:1.5501\ttrain-rmse:1.54749\n",
      "[10]\teval-rmse:1.45103\ttrain-rmse:1.42943\n",
      "[11]\teval-rmse:1.36836\ttrain-rmse:1.32463\n",
      "[12]\teval-rmse:1.30648\ttrain-rmse:1.23062\n",
      "[13]\teval-rmse:1.2529\ttrain-rmse:1.14656\n",
      "[14]\teval-rmse:1.2104\ttrain-rmse:1.07223\n",
      "[15]\teval-rmse:1.17496\ttrain-rmse:1.0047\n",
      "[16]\teval-rmse:1.14641\ttrain-rmse:0.946322\n",
      "[17]\teval-rmse:1.12282\ttrain-rmse:0.894358\n",
      "[18]\teval-rmse:1.10412\ttrain-rmse:0.848827\n",
      "[19]\teval-rmse:1.09252\ttrain-rmse:0.809093\n",
      "[20]\teval-rmse:1.08259\ttrain-rmse:0.772146\n",
      "[21]\teval-rmse:1.07489\ttrain-rmse:0.739803\n",
      "[22]\teval-rmse:1.07041\ttrain-rmse:0.710242\n",
      "[23]\teval-rmse:1.06567\ttrain-rmse:0.681937\n",
      "[24]\teval-rmse:1.06241\ttrain-rmse:0.65802\n",
      "[25]\teval-rmse:1.06101\ttrain-rmse:0.635477\n",
      "[26]\teval-rmse:1.06\ttrain-rmse:0.614071\n",
      "[27]\teval-rmse:1.05907\ttrain-rmse:0.595293\n",
      "[28]\teval-rmse:1.05893\ttrain-rmse:0.578471\n",
      "[29]\teval-rmse:1.05962\ttrain-rmse:0.563752\n",
      "[30]\teval-rmse:1.06\ttrain-rmse:0.548818\n",
      "[31]\teval-rmse:1.06052\ttrain-rmse:0.536207\n",
      "[32]\teval-rmse:1.06078\ttrain-rmse:0.523873\n",
      "[33]\teval-rmse:1.06156\ttrain-rmse:0.511174\n",
      "[34]\teval-rmse:1.06223\ttrain-rmse:0.499263\n",
      "[35]\teval-rmse:1.0619\ttrain-rmse:0.486704\n",
      "[36]\teval-rmse:1.0618\ttrain-rmse:0.476728\n",
      "[37]\teval-rmse:1.06258\ttrain-rmse:0.469097\n",
      "[38]\teval-rmse:1.06335\ttrain-rmse:0.457879\n",
      "[39]\teval-rmse:1.06314\ttrain-rmse:0.447981\n",
      "[40]\teval-rmse:1.06384\ttrain-rmse:0.439029\n",
      "[41]\teval-rmse:1.06421\ttrain-rmse:0.429415\n",
      "[42]\teval-rmse:1.06436\ttrain-rmse:0.420829\n",
      "[43]\teval-rmse:1.06452\ttrain-rmse:0.413583\n",
      "[44]\teval-rmse:1.06425\ttrain-rmse:0.404971\n",
      "[45]\teval-rmse:1.06452\ttrain-rmse:0.397991\n",
      "[46]\teval-rmse:1.06365\ttrain-rmse:0.390594\n",
      "[47]\teval-rmse:1.06379\ttrain-rmse:0.383812\n",
      "[48]\teval-rmse:1.06413\ttrain-rmse:0.380341\n",
      "[49]\teval-rmse:1.06429\ttrain-rmse:0.373367\n",
      "[50]\teval-rmse:1.06443\ttrain-rmse:0.368833\n",
      "[51]\teval-rmse:1.06424\ttrain-rmse:0.362497\n",
      "[52]\teval-rmse:1.06421\ttrain-rmse:0.356225\n",
      "[53]\teval-rmse:1.06357\ttrain-rmse:0.349472\n",
      "[54]\teval-rmse:1.063\ttrain-rmse:0.343483\n",
      "[55]\teval-rmse:1.06298\ttrain-rmse:0.337563\n",
      "[56]\teval-rmse:1.06292\ttrain-rmse:0.332851\n",
      "[57]\teval-rmse:1.0622\ttrain-rmse:0.325951\n",
      "[58]\teval-rmse:1.06255\ttrain-rmse:0.321573\n",
      "[59]\teval-rmse:1.06241\ttrain-rmse:0.31534\n",
      "[60]\teval-rmse:1.06205\ttrain-rmse:0.311397\n",
      "[61]\teval-rmse:1.06206\ttrain-rmse:0.307653\n",
      "[62]\teval-rmse:1.06212\ttrain-rmse:0.302918\n",
      "[63]\teval-rmse:1.06141\ttrain-rmse:0.297345\n",
      "[64]\teval-rmse:1.06134\ttrain-rmse:0.292382\n",
      "[65]\teval-rmse:1.06041\ttrain-rmse:0.286472\n",
      "[66]\teval-rmse:1.06024\ttrain-rmse:0.282852\n",
      "[67]\teval-rmse:1.06032\ttrain-rmse:0.278772\n",
      "[68]\teval-rmse:1.06019\ttrain-rmse:0.274091\n",
      "[69]\teval-rmse:1.06024\ttrain-rmse:0.26985\n",
      "[70]\teval-rmse:1.06006\ttrain-rmse:0.265725\n",
      "[71]\teval-rmse:1.05932\ttrain-rmse:0.261778\n",
      "[72]\teval-rmse:1.05875\ttrain-rmse:0.257316\n",
      "[73]\teval-rmse:1.0585\ttrain-rmse:0.253753\n",
      "[74]\teval-rmse:1.05824\ttrain-rmse:0.251908\n",
      "[75]\teval-rmse:1.05767\ttrain-rmse:0.2476\n",
      "[76]\teval-rmse:1.05746\ttrain-rmse:0.245011\n",
      "[77]\teval-rmse:1.05703\ttrain-rmse:0.241439\n",
      "[78]\teval-rmse:1.05663\ttrain-rmse:0.237674\n",
      "[79]\teval-rmse:1.05635\ttrain-rmse:0.234946\n",
      "[80]\teval-rmse:1.05587\ttrain-rmse:0.23192\n",
      "[81]\teval-rmse:1.05594\ttrain-rmse:0.229661\n",
      "[82]\teval-rmse:1.05571\ttrain-rmse:0.226526\n",
      "[83]\teval-rmse:1.05533\ttrain-rmse:0.223608\n",
      "[84]\teval-rmse:1.05468\ttrain-rmse:0.221039\n",
      "[85]\teval-rmse:1.0547\ttrain-rmse:0.218583\n",
      "[86]\teval-rmse:1.05451\ttrain-rmse:0.216291\n",
      "[87]\teval-rmse:1.0547\ttrain-rmse:0.213746\n",
      "[88]\teval-rmse:1.05444\ttrain-rmse:0.211016\n",
      "[89]\teval-rmse:1.05451\ttrain-rmse:0.208533\n",
      "[90]\teval-rmse:1.05415\ttrain-rmse:0.206354\n",
      "[91]\teval-rmse:1.05417\ttrain-rmse:0.204359\n",
      "[92]\teval-rmse:1.05385\ttrain-rmse:0.20219\n",
      "[93]\teval-rmse:1.05379\ttrain-rmse:0.199854\n",
      "[94]\teval-rmse:1.05375\ttrain-rmse:0.198728\n",
      "[95]\teval-rmse:1.05367\ttrain-rmse:0.196423\n",
      "[96]\teval-rmse:1.05366\ttrain-rmse:0.195088\n",
      "[97]\teval-rmse:1.05348\ttrain-rmse:0.1931\n",
      "[98]\teval-rmse:1.05344\ttrain-rmse:0.191336\n",
      "[99]\teval-rmse:1.05331\ttrain-rmse:0.189943\n",
      "[100]\teval-rmse:1.05316\ttrain-rmse:0.188315\n",
      "[101]\teval-rmse:1.05305\ttrain-rmse:0.186776\n",
      "[102]\teval-rmse:1.05289\ttrain-rmse:0.185413\n",
      "[103]\teval-rmse:1.05295\ttrain-rmse:0.183969\n",
      "[104]\teval-rmse:1.05295\ttrain-rmse:0.18284\n",
      "[105]\teval-rmse:1.05272\ttrain-rmse:0.181081\n",
      "[106]\teval-rmse:1.05268\ttrain-rmse:0.179657\n",
      "[107]\teval-rmse:1.05265\ttrain-rmse:0.178395\n",
      "[108]\teval-rmse:1.05268\ttrain-rmse:0.177194\n",
      "[109]\teval-rmse:1.05257\ttrain-rmse:0.175854\n",
      "[110]\teval-rmse:1.05264\ttrain-rmse:0.174526\n",
      "[111]\teval-rmse:1.05261\ttrain-rmse:0.173199\n",
      "[112]\teval-rmse:1.05251\ttrain-rmse:0.172108\n",
      "[113]\teval-rmse:1.05242\ttrain-rmse:0.170913\n",
      "[114]\teval-rmse:1.05235\ttrain-rmse:0.169767\n",
      "[115]\teval-rmse:1.0523\ttrain-rmse:0.168799\n",
      "[116]\teval-rmse:1.05225\ttrain-rmse:0.167731\n",
      "[117]\teval-rmse:1.05217\ttrain-rmse:0.166689\n",
      "[118]\teval-rmse:1.05192\ttrain-rmse:0.16562\n",
      "[119]\teval-rmse:1.05191\ttrain-rmse:0.164675\n",
      "[120]\teval-rmse:1.0519\ttrain-rmse:0.163617\n",
      "[121]\teval-rmse:1.05167\ttrain-rmse:0.162669\n",
      "[122]\teval-rmse:1.05154\ttrain-rmse:0.161656\n",
      "[123]\teval-rmse:1.05147\ttrain-rmse:0.160591\n",
      "[124]\teval-rmse:1.05151\ttrain-rmse:0.159804\n",
      "[125]\teval-rmse:1.05157\ttrain-rmse:0.15876\n",
      "[126]\teval-rmse:1.05154\ttrain-rmse:0.157935\n",
      "[127]\teval-rmse:1.05151\ttrain-rmse:0.156952\n",
      "[128]\teval-rmse:1.05154\ttrain-rmse:0.15607\n",
      "[129]\teval-rmse:1.05146\ttrain-rmse:0.155349\n",
      "[130]\teval-rmse:1.05141\ttrain-rmse:0.154673\n",
      "[131]\teval-rmse:1.05139\ttrain-rmse:0.153826\n",
      "[132]\teval-rmse:1.05136\ttrain-rmse:0.153221\n",
      "[133]\teval-rmse:1.0513\ttrain-rmse:0.152831\n",
      "[134]\teval-rmse:1.05123\ttrain-rmse:0.152115\n",
      "[135]\teval-rmse:1.05115\ttrain-rmse:0.151522\n",
      "[136]\teval-rmse:1.05113\ttrain-rmse:0.150861\n",
      "[137]\teval-rmse:1.05102\ttrain-rmse:0.150323\n",
      "[138]\teval-rmse:1.05104\ttrain-rmse:0.149857\n",
      "[139]\teval-rmse:1.05105\ttrain-rmse:0.149287\n",
      "[140]\teval-rmse:1.05105\ttrain-rmse:0.149095\n",
      "[141]\teval-rmse:1.05105\ttrain-rmse:0.148467\n",
      "[142]\teval-rmse:1.0509\ttrain-rmse:0.147912\n",
      "[143]\teval-rmse:1.05091\ttrain-rmse:0.147646\n",
      "[144]\teval-rmse:1.05079\ttrain-rmse:0.147306\n",
      "[145]\teval-rmse:1.05078\ttrain-rmse:0.146907\n",
      "[146]\teval-rmse:1.05078\ttrain-rmse:0.146499\n",
      "[147]\teval-rmse:1.05069\ttrain-rmse:0.146022\n",
      "[148]\teval-rmse:1.05054\ttrain-rmse:0.145675\n",
      "[149]\teval-rmse:1.05051\ttrain-rmse:0.145298\n",
      "[150]\teval-rmse:1.0504\ttrain-rmse:0.144824\n",
      "[151]\teval-rmse:1.05037\ttrain-rmse:0.144491\n",
      "[152]\teval-rmse:1.05034\ttrain-rmse:0.143932\n",
      "[153]\teval-rmse:1.0503\ttrain-rmse:0.14363\n",
      "[154]\teval-rmse:1.0503\ttrain-rmse:0.143139\n",
      "[155]\teval-rmse:1.05028\ttrain-rmse:0.142885\n",
      "[156]\teval-rmse:1.05028\ttrain-rmse:0.142535\n",
      "[157]\teval-rmse:1.05022\ttrain-rmse:0.142125\n",
      "[158]\teval-rmse:1.05026\ttrain-rmse:0.141889\n",
      "[159]\teval-rmse:1.05023\ttrain-rmse:0.141457\n",
      "[160]\teval-rmse:1.05018\ttrain-rmse:0.141136\n",
      "[161]\teval-rmse:1.0502\ttrain-rmse:0.140733\n",
      "[162]\teval-rmse:1.05018\ttrain-rmse:0.140506\n",
      "[163]\teval-rmse:1.05026\ttrain-rmse:0.140189\n",
      "[164]\teval-rmse:1.05019\ttrain-rmse:0.139855\n",
      "[165]\teval-rmse:1.05017\ttrain-rmse:0.139661\n",
      "[166]\teval-rmse:1.05018\ttrain-rmse:0.139367\n",
      "[167]\teval-rmse:1.05014\ttrain-rmse:0.139146\n",
      "[168]\teval-rmse:1.05011\ttrain-rmse:0.138956\n",
      "[169]\teval-rmse:1.05007\ttrain-rmse:0.138717\n",
      "[170]\teval-rmse:1.05008\ttrain-rmse:0.138394\n",
      "[171]\teval-rmse:1.05003\ttrain-rmse:0.138156\n",
      "[172]\teval-rmse:1.05006\ttrain-rmse:0.138008\n",
      "[173]\teval-rmse:1.05009\ttrain-rmse:0.137679\n",
      "[174]\teval-rmse:1.05\ttrain-rmse:0.137334\n",
      "[175]\teval-rmse:1.05001\ttrain-rmse:0.137163\n",
      "[176]\teval-rmse:1.05001\ttrain-rmse:0.136857\n",
      "[177]\teval-rmse:1.05001\ttrain-rmse:0.136663\n",
      "[178]\teval-rmse:1.05\ttrain-rmse:0.136257\n",
      "[179]\teval-rmse:1.05005\ttrain-rmse:0.136015\n",
      "[180]\teval-rmse:1.05007\ttrain-rmse:0.135859\n",
      "[181]\teval-rmse:1.05006\ttrain-rmse:0.135663\n",
      "[182]\teval-rmse:1.05005\ttrain-rmse:0.135586\n",
      "[183]\teval-rmse:1.05001\ttrain-rmse:0.135396\n",
      "[184]\teval-rmse:1.05001\ttrain-rmse:0.135231\n",
      "[185]\teval-rmse:1.05002\ttrain-rmse:0.135073\n",
      "[186]\teval-rmse:1.05008\ttrain-rmse:0.13488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[187]\teval-rmse:1.05007\ttrain-rmse:0.134592\n",
      "[188]\teval-rmse:1.05002\ttrain-rmse:0.134496\n",
      "[189]\teval-rmse:1.05002\ttrain-rmse:0.134338\n",
      "[190]\teval-rmse:1.0499\ttrain-rmse:0.134231\n",
      "[191]\teval-rmse:1.04988\ttrain-rmse:0.134\n",
      "[192]\teval-rmse:1.04994\ttrain-rmse:0.133718\n",
      "[193]\teval-rmse:1.04996\ttrain-rmse:0.133536\n",
      "[194]\teval-rmse:1.04996\ttrain-rmse:0.133413\n",
      "[195]\teval-rmse:1.04999\ttrain-rmse:0.133359\n",
      "[196]\teval-rmse:1.04998\ttrain-rmse:0.133315\n",
      "[197]\teval-rmse:1.04999\ttrain-rmse:0.133138\n",
      "[198]\teval-rmse:1.04998\ttrain-rmse:0.13298\n",
      "[199]\teval-rmse:1.04997\ttrain-rmse:0.132918\n",
      "[200]\teval-rmse:1.04996\ttrain-rmse:0.132685\n",
      "[201]\teval-rmse:1.05\ttrain-rmse:0.132573\n",
      "[202]\teval-rmse:1.05003\ttrain-rmse:0.132441\n",
      "[203]\teval-rmse:1.05\ttrain-rmse:0.132294\n",
      "[204]\teval-rmse:1.05002\ttrain-rmse:0.132109\n",
      "[205]\teval-rmse:1.04999\ttrain-rmse:0.131936\n",
      "[206]\teval-rmse:1.04991\ttrain-rmse:0.131808\n",
      "[207]\teval-rmse:1.04988\ttrain-rmse:0.131722\n",
      "[208]\teval-rmse:1.04991\ttrain-rmse:0.13159\n",
      "[209]\teval-rmse:1.04991\ttrain-rmse:0.131476\n",
      "[210]\teval-rmse:1.04985\ttrain-rmse:0.131214\n",
      "[211]\teval-rmse:1.04983\ttrain-rmse:0.131146\n",
      "[212]\teval-rmse:1.04987\ttrain-rmse:0.130986\n",
      "[213]\teval-rmse:1.04984\ttrain-rmse:0.130822\n",
      "[214]\teval-rmse:1.04989\ttrain-rmse:0.130717\n",
      "[215]\teval-rmse:1.04992\ttrain-rmse:0.130678\n",
      "[216]\teval-rmse:1.04991\ttrain-rmse:0.130555\n",
      "[217]\teval-rmse:1.04991\ttrain-rmse:0.130555\n",
      "[218]\teval-rmse:1.04996\ttrain-rmse:0.130473\n",
      "[219]\teval-rmse:1.04997\ttrain-rmse:0.130435\n",
      "[220]\teval-rmse:1.04997\ttrain-rmse:0.130372\n",
      "[221]\teval-rmse:1.04992\ttrain-rmse:0.130315\n",
      "[222]\teval-rmse:1.04991\ttrain-rmse:0.130246\n",
      "[223]\teval-rmse:1.04991\ttrain-rmse:0.130113\n",
      "[224]\teval-rmse:1.0499\ttrain-rmse:0.130057\n",
      "[225]\teval-rmse:1.04989\ttrain-rmse:0.129857\n",
      "[226]\teval-rmse:1.04989\ttrain-rmse:0.129797\n",
      "[227]\teval-rmse:1.04989\ttrain-rmse:0.129739\n",
      "[228]\teval-rmse:1.04991\ttrain-rmse:0.129683\n",
      "[229]\teval-rmse:1.04994\ttrain-rmse:0.129607\n",
      "[230]\teval-rmse:1.04993\ttrain-rmse:0.129453\n",
      "[231]\teval-rmse:1.04994\ttrain-rmse:0.129388\n",
      "[232]\teval-rmse:1.04991\ttrain-rmse:0.129257\n",
      "[233]\teval-rmse:1.04992\ttrain-rmse:0.129191\n",
      "[234]\teval-rmse:1.04992\ttrain-rmse:0.129067\n",
      "[235]\teval-rmse:1.04992\ttrain-rmse:0.129067\n",
      "[236]\teval-rmse:1.04986\ttrain-rmse:0.128956\n",
      "[237]\teval-rmse:1.0499\ttrain-rmse:0.128812\n",
      "[238]\teval-rmse:1.04992\ttrain-rmse:0.128645\n",
      "[239]\teval-rmse:1.04989\ttrain-rmse:0.1285\n",
      "[240]\teval-rmse:1.04986\ttrain-rmse:0.128384\n",
      "[241]\teval-rmse:1.04989\ttrain-rmse:0.128238\n",
      "[242]\teval-rmse:1.04989\ttrain-rmse:0.128238\n",
      "[243]\teval-rmse:1.04987\ttrain-rmse:0.128178\n",
      "[244]\teval-rmse:1.04987\ttrain-rmse:0.128107\n",
      "[245]\teval-rmse:1.04987\ttrain-rmse:0.128107\n",
      "[246]\teval-rmse:1.04978\ttrain-rmse:0.127981\n",
      "[247]\teval-rmse:1.04984\ttrain-rmse:0.127919\n",
      "[248]\teval-rmse:1.04981\ttrain-rmse:0.127895\n",
      "[249]\teval-rmse:1.04983\ttrain-rmse:0.127789\n",
      "[250]\teval-rmse:1.04981\ttrain-rmse:0.127711\n",
      "[251]\teval-rmse:1.04981\ttrain-rmse:0.127711\n",
      "[252]\teval-rmse:1.04978\ttrain-rmse:0.127658\n",
      "[253]\teval-rmse:1.04975\ttrain-rmse:0.127578\n",
      "[254]\teval-rmse:1.04976\ttrain-rmse:0.127464\n",
      "[255]\teval-rmse:1.04976\ttrain-rmse:0.127464\n",
      "[256]\teval-rmse:1.04972\ttrain-rmse:0.127378\n",
      "[257]\teval-rmse:1.04974\ttrain-rmse:0.127312\n",
      "[258]\teval-rmse:1.04973\ttrain-rmse:0.12727\n",
      "[259]\teval-rmse:1.04973\ttrain-rmse:0.12727\n",
      "[260]\teval-rmse:1.04972\ttrain-rmse:0.127212\n",
      "[261]\teval-rmse:1.04972\ttrain-rmse:0.127212\n",
      "[262]\teval-rmse:1.04973\ttrain-rmse:0.127164\n",
      "[263]\teval-rmse:1.04973\ttrain-rmse:0.127115\n",
      "[264]\teval-rmse:1.04973\ttrain-rmse:0.12702\n",
      "[265]\teval-rmse:1.04982\ttrain-rmse:0.126863\n",
      "[266]\teval-rmse:1.04982\ttrain-rmse:0.126774\n",
      "[267]\teval-rmse:1.04982\ttrain-rmse:0.126774\n",
      "[268]\teval-rmse:1.04974\ttrain-rmse:0.126722\n",
      "[269]\teval-rmse:1.04973\ttrain-rmse:0.126658\n",
      "[270]\teval-rmse:1.04974\ttrain-rmse:0.126557\n",
      "[271]\teval-rmse:1.04971\ttrain-rmse:0.126387\n",
      "[272]\teval-rmse:1.04972\ttrain-rmse:0.126387\n",
      "[273]\teval-rmse:1.04974\ttrain-rmse:0.126387\n",
      "[274]\teval-rmse:1.04975\ttrain-rmse:0.126283\n",
      "[275]\teval-rmse:1.04976\ttrain-rmse:0.126283\n",
      "[276]\teval-rmse:1.04975\ttrain-rmse:0.126231\n",
      "[277]\teval-rmse:1.04973\ttrain-rmse:0.126156\n",
      "[278]\teval-rmse:1.0497\ttrain-rmse:0.126045\n",
      "[279]\teval-rmse:1.04974\ttrain-rmse:0.125983\n",
      "[280]\teval-rmse:1.04974\ttrain-rmse:0.125846\n",
      "[281]\teval-rmse:1.04973\ttrain-rmse:0.125805\n",
      "[282]\teval-rmse:1.04972\ttrain-rmse:0.125758\n",
      "[283]\teval-rmse:1.04969\ttrain-rmse:0.125718\n",
      "[284]\teval-rmse:1.04967\ttrain-rmse:0.125539\n",
      "[285]\teval-rmse:1.04954\ttrain-rmse:0.125379\n",
      "[286]\teval-rmse:1.04956\ttrain-rmse:0.125238\n",
      "[287]\teval-rmse:1.04955\ttrain-rmse:0.125116\n",
      "[288]\teval-rmse:1.04956\ttrain-rmse:0.124897\n",
      "[289]\teval-rmse:1.04955\ttrain-rmse:0.124804\n",
      "[290]\teval-rmse:1.04958\ttrain-rmse:0.124751\n",
      "[291]\teval-rmse:1.04958\ttrain-rmse:0.124751\n",
      "[292]\teval-rmse:1.04958\ttrain-rmse:0.124628\n",
      "[293]\teval-rmse:1.04959\ttrain-rmse:0.124628\n",
      "[294]\teval-rmse:1.0496\ttrain-rmse:0.124521\n",
      "[295]\teval-rmse:1.04955\ttrain-rmse:0.124481\n",
      "[296]\teval-rmse:1.04952\ttrain-rmse:0.124376\n",
      "[297]\teval-rmse:1.04953\ttrain-rmse:0.12434\n",
      "[298]\teval-rmse:1.04952\ttrain-rmse:0.124156\n",
      "[299]\teval-rmse:1.04955\ttrain-rmse:0.124094\n",
      "[300]\teval-rmse:1.04956\ttrain-rmse:0.124094\n",
      "[301]\teval-rmse:1.04956\ttrain-rmse:0.124094\n",
      "[302]\teval-rmse:1.04956\ttrain-rmse:0.124094\n",
      "[303]\teval-rmse:1.0496\ttrain-rmse:0.12399\n",
      "[304]\teval-rmse:1.0496\ttrain-rmse:0.12399\n",
      "[305]\teval-rmse:1.0496\ttrain-rmse:0.12399\n",
      "[306]\teval-rmse:1.04962\ttrain-rmse:0.12399\n",
      "[307]\teval-rmse:1.04962\ttrain-rmse:0.123989\n",
      "[308]\teval-rmse:1.04966\ttrain-rmse:0.123931\n",
      "[309]\teval-rmse:1.04967\ttrain-rmse:0.123843\n",
      "[310]\teval-rmse:1.04966\ttrain-rmse:0.123796\n",
      "[311]\teval-rmse:1.04966\ttrain-rmse:0.123796\n",
      "[312]\teval-rmse:1.04968\ttrain-rmse:0.123769\n",
      "[313]\teval-rmse:1.04968\ttrain-rmse:0.123769\n",
      "[314]\teval-rmse:1.04968\ttrain-rmse:0.123769\n",
      "[315]\teval-rmse:1.04969\ttrain-rmse:0.123769\n",
      "[316]\teval-rmse:1.04966\ttrain-rmse:0.123692\n",
      "[317]\teval-rmse:1.04966\ttrain-rmse:0.123653\n",
      "[318]\teval-rmse:1.04961\ttrain-rmse:0.123549\n",
      "[319]\teval-rmse:1.04961\ttrain-rmse:0.123549\n",
      "[320]\teval-rmse:1.04963\ttrain-rmse:0.123462\n",
      "[321]\teval-rmse:1.04963\ttrain-rmse:0.123462\n",
      "[322]\teval-rmse:1.04962\ttrain-rmse:0.123384\n",
      "[323]\teval-rmse:1.04962\ttrain-rmse:0.123384\n",
      "[324]\teval-rmse:1.04961\ttrain-rmse:0.123313\n",
      "[325]\teval-rmse:1.04962\ttrain-rmse:0.12323\n",
      "[326]\teval-rmse:1.04963\ttrain-rmse:0.12323\n",
      "[327]\teval-rmse:1.04963\ttrain-rmse:0.12323\n",
      "[328]\teval-rmse:1.04963\ttrain-rmse:0.12323\n",
      "[329]\teval-rmse:1.04962\ttrain-rmse:0.12323\n",
      "[330]\teval-rmse:1.04959\ttrain-rmse:0.123122\n",
      "[331]\teval-rmse:1.04958\ttrain-rmse:0.123069\n",
      "[332]\teval-rmse:1.04958\ttrain-rmse:0.123069\n",
      "[333]\teval-rmse:1.04958\ttrain-rmse:0.123069\n",
      "[334]\teval-rmse:1.04958\ttrain-rmse:0.123069\n",
      "[335]\teval-rmse:1.04956\ttrain-rmse:0.123033\n",
      "[336]\teval-rmse:1.04955\ttrain-rmse:0.123033\n",
      "[337]\teval-rmse:1.04955\ttrain-rmse:0.123033\n",
      "[338]\teval-rmse:1.04955\ttrain-rmse:0.123033\n",
      "[339]\teval-rmse:1.04955\ttrain-rmse:0.122962\n",
      "[340]\teval-rmse:1.04958\ttrain-rmse:0.12292\n",
      "[341]\teval-rmse:1.04958\ttrain-rmse:0.12292\n",
      "[342]\teval-rmse:1.04957\ttrain-rmse:0.122812\n",
      "[343]\teval-rmse:1.04957\ttrain-rmse:0.122812\n",
      "[344]\teval-rmse:1.04957\ttrain-rmse:0.122812\n",
      "[345]\teval-rmse:1.04957\ttrain-rmse:0.122812\n",
      "[346]\teval-rmse:1.04957\ttrain-rmse:0.122812\n",
      "[347]\teval-rmse:1.04957\ttrain-rmse:0.122686\n",
      "[348]\teval-rmse:1.04957\ttrain-rmse:0.122686\n",
      "[349]\teval-rmse:1.04955\ttrain-rmse:0.122654\n",
      "[350]\teval-rmse:1.04955\ttrain-rmse:0.122654\n",
      "[351]\teval-rmse:1.04958\ttrain-rmse:0.12258\n",
      "[352]\teval-rmse:1.04955\ttrain-rmse:0.122499\n",
      "[353]\teval-rmse:1.04955\ttrain-rmse:0.122499\n",
      "[354]\teval-rmse:1.04955\ttrain-rmse:0.122499\n",
      "[355]\teval-rmse:1.04955\ttrain-rmse:0.122499\n",
      "[356]\teval-rmse:1.04956\ttrain-rmse:0.122499\n",
      "[357]\teval-rmse:1.04954\ttrain-rmse:0.122415\n",
      "[358]\teval-rmse:1.04955\ttrain-rmse:0.122415\n",
      "[359]\teval-rmse:1.04954\ttrain-rmse:0.122369\n",
      "[360]\teval-rmse:1.04955\ttrain-rmse:0.122369\n",
      "[361]\teval-rmse:1.04953\ttrain-rmse:0.122241\n",
      "[362]\teval-rmse:1.04957\ttrain-rmse:0.12216\n",
      "[363]\teval-rmse:1.04958\ttrain-rmse:0.122098\n",
      "[364]\teval-rmse:1.04958\ttrain-rmse:0.122055\n",
      "[365]\teval-rmse:1.04958\ttrain-rmse:0.122055\n",
      "[366]\teval-rmse:1.04953\ttrain-rmse:0.121978\n",
      "[367]\teval-rmse:1.04953\ttrain-rmse:0.121978\n",
      "[368]\teval-rmse:1.04953\ttrain-rmse:0.121978\n",
      "[369]\teval-rmse:1.0495\ttrain-rmse:0.121867\n",
      "[370]\teval-rmse:1.0495\ttrain-rmse:0.121867\n",
      "[371]\teval-rmse:1.04949\ttrain-rmse:0.121867\n",
      "[372]\teval-rmse:1.04949\ttrain-rmse:0.121867\n",
      "[373]\teval-rmse:1.04949\ttrain-rmse:0.121867\n",
      "[374]\teval-rmse:1.04949\ttrain-rmse:0.121867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[375]\teval-rmse:1.0495\ttrain-rmse:0.121867\n",
      "[376]\teval-rmse:1.04954\ttrain-rmse:0.121813\n",
      "[377]\teval-rmse:1.04954\ttrain-rmse:0.121813\n",
      "[378]\teval-rmse:1.04957\ttrain-rmse:0.121773\n",
      "[379]\teval-rmse:1.04959\ttrain-rmse:0.121721\n",
      "[380]\teval-rmse:1.04959\ttrain-rmse:0.121721\n",
      "[381]\teval-rmse:1.04959\ttrain-rmse:0.121721\n",
      "[382]\teval-rmse:1.04957\ttrain-rmse:0.121688\n",
      "[383]\teval-rmse:1.04957\ttrain-rmse:0.121688\n",
      "[384]\teval-rmse:1.04957\ttrain-rmse:0.121671\n",
      "[385]\teval-rmse:1.04959\ttrain-rmse:0.121634\n",
      "[386]\teval-rmse:1.04959\ttrain-rmse:0.121634\n",
      "[387]\teval-rmse:1.04959\ttrain-rmse:0.121634\n",
      "[388]\teval-rmse:1.0496\ttrain-rmse:0.121566\n",
      "[389]\teval-rmse:1.04957\ttrain-rmse:0.121532\n",
      "[390]\teval-rmse:1.04958\ttrain-rmse:0.121532\n",
      "[391]\teval-rmse:1.04957\ttrain-rmse:0.12148\n",
      "[392]\teval-rmse:1.04957\ttrain-rmse:0.12148\n",
      "[393]\teval-rmse:1.04958\ttrain-rmse:0.12148\n",
      "[394]\teval-rmse:1.04957\ttrain-rmse:0.121437\n",
      "[395]\teval-rmse:1.04957\ttrain-rmse:0.121437\n",
      "[396]\teval-rmse:1.04957\ttrain-rmse:0.121437\n",
      "[397]\teval-rmse:1.04957\ttrain-rmse:0.121437\n",
      "[398]\teval-rmse:1.04953\ttrain-rmse:0.121342\n",
      "[399]\teval-rmse:1.04953\ttrain-rmse:0.121342\n",
      "[400]\teval-rmse:1.04958\ttrain-rmse:0.121265\n",
      "[401]\teval-rmse:1.04958\ttrain-rmse:0.121265\n",
      "[402]\teval-rmse:1.04958\ttrain-rmse:0.121265\n",
      "[403]\teval-rmse:1.04958\ttrain-rmse:0.121265\n",
      "[404]\teval-rmse:1.04958\ttrain-rmse:0.121265\n",
      "[405]\teval-rmse:1.04958\ttrain-rmse:0.121265\n",
      "[406]\teval-rmse:1.04958\ttrain-rmse:0.121265\n",
      "[407]\teval-rmse:1.04958\ttrain-rmse:0.121226\n",
      "[408]\teval-rmse:1.04958\ttrain-rmse:0.121226\n",
      "[409]\teval-rmse:1.04958\ttrain-rmse:0.121226\n",
      "[410]\teval-rmse:1.04958\ttrain-rmse:0.121193\n",
      "[411]\teval-rmse:1.04958\ttrain-rmse:0.121119\n",
      "[412]\teval-rmse:1.04958\ttrain-rmse:0.121119\n",
      "[413]\teval-rmse:1.04958\ttrain-rmse:0.121119\n",
      "[414]\teval-rmse:1.04958\ttrain-rmse:0.121119\n",
      "[415]\teval-rmse:1.04958\ttrain-rmse:0.121119\n",
      "[416]\teval-rmse:1.04961\ttrain-rmse:0.121045\n",
      "[417]\teval-rmse:1.04961\ttrain-rmse:0.121045\n",
      "[418]\teval-rmse:1.04959\ttrain-rmse:0.120983\n",
      "[419]\teval-rmse:1.04957\ttrain-rmse:0.120896\n",
      "[420]\teval-rmse:1.04966\ttrain-rmse:0.120844\n",
      "[421]\teval-rmse:1.04969\ttrain-rmse:0.12077\n",
      "[422]\teval-rmse:1.0497\ttrain-rmse:0.12069\n",
      "[423]\teval-rmse:1.04971\ttrain-rmse:0.12069\n",
      "[424]\teval-rmse:1.04971\ttrain-rmse:0.12069\n",
      "[425]\teval-rmse:1.04971\ttrain-rmse:0.12069\n",
      "[426]\teval-rmse:1.04972\ttrain-rmse:0.12069\n",
      "[427]\teval-rmse:1.04973\ttrain-rmse:0.12069\n",
      "[428]\teval-rmse:1.04973\ttrain-rmse:0.120597\n",
      "[429]\teval-rmse:1.04971\ttrain-rmse:0.12055\n",
      "[430]\teval-rmse:1.04971\ttrain-rmse:0.12055\n",
      "[431]\teval-rmse:1.04974\ttrain-rmse:0.120513\n",
      "[432]\teval-rmse:1.04974\ttrain-rmse:0.120513\n",
      "[433]\teval-rmse:1.04974\ttrain-rmse:0.120513\n",
      "[434]\teval-rmse:1.04974\ttrain-rmse:0.120513\n",
      "[435]\teval-rmse:1.04974\ttrain-rmse:0.120513\n",
      "[436]\teval-rmse:1.04969\ttrain-rmse:0.120442\n",
      "[437]\teval-rmse:1.04969\ttrain-rmse:0.120442\n",
      "[438]\teval-rmse:1.04971\ttrain-rmse:0.120397\n",
      "[439]\teval-rmse:1.04971\ttrain-rmse:0.120356\n",
      "[440]\teval-rmse:1.04971\ttrain-rmse:0.120356\n",
      "[441]\teval-rmse:1.04971\ttrain-rmse:0.120356\n",
      "[442]\teval-rmse:1.04971\ttrain-rmse:0.120356\n",
      "[443]\teval-rmse:1.04971\ttrain-rmse:0.120356\n",
      "[444]\teval-rmse:1.04973\ttrain-rmse:0.120317\n",
      "[445]\teval-rmse:1.04973\ttrain-rmse:0.120255\n",
      "[446]\teval-rmse:1.04974\ttrain-rmse:0.120255\n",
      "[447]\teval-rmse:1.04974\ttrain-rmse:0.120255\n",
      "[448]\teval-rmse:1.04975\ttrain-rmse:0.120125\n",
      "[449]\teval-rmse:1.04972\ttrain-rmse:0.120096\n",
      "[450]\teval-rmse:1.04972\ttrain-rmse:0.120096\n",
      "[451]\teval-rmse:1.04973\ttrain-rmse:0.120031\n",
      "[452]\teval-rmse:1.04973\ttrain-rmse:0.120031\n",
      "[453]\teval-rmse:1.04973\ttrain-rmse:0.120031\n",
      "[454]\teval-rmse:1.04973\ttrain-rmse:0.120031\n",
      "[455]\teval-rmse:1.04973\ttrain-rmse:0.120031\n",
      "[456]\teval-rmse:1.04973\ttrain-rmse:0.120031\n",
      "[457]\teval-rmse:1.04972\ttrain-rmse:0.120031\n",
      "[458]\teval-rmse:1.04972\ttrain-rmse:0.120031\n",
      "[459]\teval-rmse:1.04972\ttrain-rmse:0.120031\n",
      "[460]\teval-rmse:1.04972\ttrain-rmse:0.119891\n",
      "[461]\teval-rmse:1.04973\ttrain-rmse:0.119891\n",
      "[462]\teval-rmse:1.04974\ttrain-rmse:0.119891\n",
      "[463]\teval-rmse:1.04974\ttrain-rmse:0.119891\n",
      "[464]\teval-rmse:1.04974\ttrain-rmse:0.119891\n",
      "[465]\teval-rmse:1.04974\ttrain-rmse:0.119891\n",
      "[466]\teval-rmse:1.04974\ttrain-rmse:0.119891\n",
      "[467]\teval-rmse:1.04974\ttrain-rmse:0.119891\n",
      "[468]\teval-rmse:1.04974\ttrain-rmse:0.119891\n",
      "[469]\teval-rmse:1.04975\ttrain-rmse:0.119891\n",
      "[470]\teval-rmse:1.04974\ttrain-rmse:0.119822\n",
      "[471]\teval-rmse:1.04974\ttrain-rmse:0.119822\n",
      "[472]\teval-rmse:1.04974\ttrain-rmse:0.119822\n",
      "[473]\teval-rmse:1.04974\ttrain-rmse:0.119822\n",
      "[474]\teval-rmse:1.04974\ttrain-rmse:0.119822\n",
      "[475]\teval-rmse:1.04974\ttrain-rmse:0.119822\n",
      "[476]\teval-rmse:1.04974\ttrain-rmse:0.119822\n",
      "[477]\teval-rmse:1.04974\ttrain-rmse:0.119822\n",
      "[478]\teval-rmse:1.04974\ttrain-rmse:0.119691\n",
      "[479]\teval-rmse:1.0497\ttrain-rmse:0.11964\n",
      "[480]\teval-rmse:1.0497\ttrain-rmse:0.11964\n",
      "[481]\teval-rmse:1.0497\ttrain-rmse:0.11964\n",
      "[482]\teval-rmse:1.0497\ttrain-rmse:0.11964\n",
      "[483]\teval-rmse:1.04964\ttrain-rmse:0.119483\n",
      "[484]\teval-rmse:1.04964\ttrain-rmse:0.119483\n",
      "[485]\teval-rmse:1.04963\ttrain-rmse:0.119483\n",
      "[486]\teval-rmse:1.04963\ttrain-rmse:0.119483\n",
      "[487]\teval-rmse:1.04963\ttrain-rmse:0.119483\n",
      "[488]\teval-rmse:1.04963\ttrain-rmse:0.119483\n",
      "[489]\teval-rmse:1.04964\ttrain-rmse:0.119483\n",
      "[490]\teval-rmse:1.04964\ttrain-rmse:0.119483\n",
      "[491]\teval-rmse:1.04964\ttrain-rmse:0.119483\n",
      "[492]\teval-rmse:1.04964\ttrain-rmse:0.119483\n",
      "[493]\teval-rmse:1.04966\ttrain-rmse:0.119429\n",
      "[494]\teval-rmse:1.04966\ttrain-rmse:0.119429\n",
      "[495]\teval-rmse:1.04965\ttrain-rmse:0.119429\n",
      "[496]\teval-rmse:1.04965\ttrain-rmse:0.119429\n",
      "[497]\teval-rmse:1.04961\ttrain-rmse:0.119327\n",
      "[498]\teval-rmse:1.04961\ttrain-rmse:0.119327\n",
      "[499]\teval-rmse:1.04963\ttrain-rmse:0.11926\n",
      "[500]\teval-rmse:1.04964\ttrain-rmse:0.11926\n",
      "[501]\teval-rmse:1.04964\ttrain-rmse:0.11926\n",
      "[502]\teval-rmse:1.04964\ttrain-rmse:0.11926\n",
      "[503]\teval-rmse:1.04965\ttrain-rmse:0.119169\n",
      "[504]\teval-rmse:1.04965\ttrain-rmse:0.119169\n",
      "[505]\teval-rmse:1.04965\ttrain-rmse:0.119169\n",
      "[506]\teval-rmse:1.04965\ttrain-rmse:0.119169\n",
      "[507]\teval-rmse:1.04965\ttrain-rmse:0.119169\n",
      "[508]\teval-rmse:1.04965\ttrain-rmse:0.119169\n",
      "[509]\teval-rmse:1.04965\ttrain-rmse:0.119169\n",
      "[510]\teval-rmse:1.04966\ttrain-rmse:0.119169\n",
      "[511]\teval-rmse:1.04966\ttrain-rmse:0.119169\n",
      "[512]\teval-rmse:1.04953\ttrain-rmse:0.119088\n",
      "[513]\teval-rmse:1.04953\ttrain-rmse:0.118992\n",
      "[514]\teval-rmse:1.04953\ttrain-rmse:0.118992\n",
      "[515]\teval-rmse:1.04953\ttrain-rmse:0.118992\n",
      "[516]\teval-rmse:1.04953\ttrain-rmse:0.118992\n",
      "[517]\teval-rmse:1.04949\ttrain-rmse:0.11892\n",
      "[518]\teval-rmse:1.04949\ttrain-rmse:0.11892\n",
      "[519]\teval-rmse:1.04949\ttrain-rmse:0.11892\n",
      "[520]\teval-rmse:1.04949\ttrain-rmse:0.11892\n",
      "[521]\teval-rmse:1.04949\ttrain-rmse:0.11892\n",
      "[522]\teval-rmse:1.04951\ttrain-rmse:0.118877\n",
      "[523]\teval-rmse:1.04951\ttrain-rmse:0.118877\n",
      "[524]\teval-rmse:1.04948\ttrain-rmse:0.118821\n",
      "[525]\teval-rmse:1.04948\ttrain-rmse:0.118821\n",
      "[526]\teval-rmse:1.04948\ttrain-rmse:0.118821\n",
      "[527]\teval-rmse:1.04945\ttrain-rmse:0.118762\n",
      "[528]\teval-rmse:1.04943\ttrain-rmse:0.118693\n",
      "[529]\teval-rmse:1.04943\ttrain-rmse:0.118693\n",
      "[530]\teval-rmse:1.04943\ttrain-rmse:0.118693\n",
      "[531]\teval-rmse:1.04943\ttrain-rmse:0.118605\n",
      "[532]\teval-rmse:1.04943\ttrain-rmse:0.118605\n",
      "[533]\teval-rmse:1.04943\ttrain-rmse:0.118605\n",
      "[534]\teval-rmse:1.04944\ttrain-rmse:0.118605\n",
      "[535]\teval-rmse:1.04944\ttrain-rmse:0.118605\n",
      "[536]\teval-rmse:1.04945\ttrain-rmse:0.118569\n",
      "[537]\teval-rmse:1.04945\ttrain-rmse:0.118569\n",
      "[538]\teval-rmse:1.04945\ttrain-rmse:0.118569\n",
      "[539]\teval-rmse:1.04945\ttrain-rmse:0.118568\n",
      "[540]\teval-rmse:1.04943\ttrain-rmse:0.118505\n",
      "[541]\teval-rmse:1.04943\ttrain-rmse:0.118505\n",
      "[542]\teval-rmse:1.04943\ttrain-rmse:0.118505\n",
      "[543]\teval-rmse:1.04943\ttrain-rmse:0.118505\n",
      "[544]\teval-rmse:1.04943\ttrain-rmse:0.118505\n",
      "[545]\teval-rmse:1.04943\ttrain-rmse:0.118505\n",
      "[546]\teval-rmse:1.04943\ttrain-rmse:0.118505\n",
      "[547]\teval-rmse:1.04943\ttrain-rmse:0.118505\n",
      "[548]\teval-rmse:1.04943\ttrain-rmse:0.118505\n",
      "[549]\teval-rmse:1.04944\ttrain-rmse:0.118505\n",
      "[550]\teval-rmse:1.04944\ttrain-rmse:0.118505\n",
      "Stopping. Best iteration:\n",
      "[540]\teval-rmse:1.04943\ttrain-rmse:0.118505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etser=xgboost.train(params,xdata,num_boost_round=10000,evals=watchlist,early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "etser.save_model(\"./xgb_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
