# mvideo

Делал решение достаточно долго, и под конец вылезла куча проблем, так что я не успл красиво оформить код, уж простите. Краткое описание решения:
Разбивал на трейн и тест стратифицированно, в отношении 4:1
Текстовые данные я преобразовывал:
1) word2vec-ом на этих данных тренированном 
2) word2vec-ом который у меня дома завалялся с поисковых запросов
3) tf-idf-ом

На 1-ом и 2-ом преобразованиях я обучил 8 моделей, 3 их которых свел к классификации
На 3-ем преобразовании я обучил еще 5

Ну и поверх всех метапризнаков и w2v обучал xgboost и lgbm, которые ранее тюнил Баесовой оптимизацией. 
На тесте лучше себя показал xgboost, его и оставил

Для запуска нужен python 3,gensim,numpy,pandas,sklearn,scipy,lightgbm,xgboost,bayes_opt,seaborn
Все доп фалы тут https://drive.google.com/open?id=0BxG9I9tB3U7xeWllY2RKRThINDA
